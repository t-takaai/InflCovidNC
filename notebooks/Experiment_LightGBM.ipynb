{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e5da8f9-ec22-42d9-8ede-50394ded5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import random\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, BaseCrossValidator, cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import lightgbm as lgb\n",
    "\n",
    "import sys\n",
    "sys.path.append('../tools')\n",
    "import kentai\n",
    "import lgbmtools\n",
    "import calc_3class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2f91b6-95a4-4c46-a50a-703f268cf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = os.environ['PROJECT_DIR']         # Project directory\n",
    "projectdir = Path(projectdir)\n",
    "datadir = projectdir / 'data'                  # Data directory\n",
    "pulsedir = datadir / 'pulse'                   # Pulse directory\n",
    "Infldir = pulsedir / 'Infl20230106'            # Influenza pulse directory\n",
    "Coviddir = pulsedir / 'SARS-CoV-2'             # Covid pulse directory\n",
    "NCdir = pulsedir / 'NC'                        # NC directory\n",
    "featuredir = datadir / 'feature'               # Feature directory\n",
    "resultdir = datadir / 'result'                 # Result directory\n",
    "featurepath = featuredir / 'features.csv'      # Path to features file\n",
    "idlabelspath = featuredir / 'idlabels.csv'     # Path to idlabels file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20263d41-8b46-48cb-899f-a2ed580511e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kentai = kentai.Kentai(featurepath, idlabelspath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00842bc6-6a1b-4883-aafe-fdc8515e4fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>pulse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>40</td>\n",
       "      <td>45742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infl</th>\n",
       "      <td>59</td>\n",
       "      <td>55449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc</th>\n",
       "      <td>106</td>\n",
       "      <td>70815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pid  pulse\n",
       "label            \n",
       "covid   40  45742\n",
       "infl    59  55449\n",
       "nc     106  70815"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kentai.count_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10eeb661-ca87-44cb-944a-e743286e3c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16709, number of negative: 16708\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 33417, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.524401\n",
      "[LightGBM] [Info] Number of positive: 16325, number of negative: 16324\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 32649, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000061\n",
      "[LightGBM] [Info] Start training from score 0.000061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's binary_logloss: 0.538724\n",
      "[LightGBM] [Info] Number of positive: 16608, number of negative: 16608\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116503\n",
      "[LightGBM] [Info] Number of data points in the train set: 33216, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.476611\n",
      "[LightGBM] [Info] Number of positive: 20198, number of negative: 20198\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116470\n",
      "[LightGBM] [Info] Number of data points in the train set: 40396, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.509449\n",
      "[LightGBM] [Info] Number of positive: 16906, number of negative: 16905\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 33811, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.49573\n",
      "[LightGBM] [Info] Number of positive: 14908, number of negative: 14908\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116255\n",
      "[LightGBM] [Info] Number of data points in the train set: 29816, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.511285\n",
      "[LightGBM] [Info] Number of positive: 12914, number of negative: 12913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 25827, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000077\n",
      "[LightGBM] [Info] Start training from score 0.000077\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.514333\n",
      "[LightGBM] [Info] Number of positive: 17031, number of negative: 17031\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 34062, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's binary_logloss: 0.46239\n",
      "[LightGBM] [Info] Number of positive: 17542, number of negative: 17542\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116404\n",
      "[LightGBM] [Info] Number of data points in the train set: 35084, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.533739\n",
      "[LightGBM] [Info] Number of positive: 15519, number of negative: 15519\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116343\n",
      "[LightGBM] [Info] Number of data points in the train set: 31038, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.474952\n",
      "[LightGBM] [Info] Number of positive: 14606, number of negative: 14605\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116257\n",
      "[LightGBM] [Info] Number of data points in the train set: 29211, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.498506\n",
      "[LightGBM] [Info] Number of positive: 16380, number of negative: 16380\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116259\n",
      "[LightGBM] [Info] Number of data points in the train set: 32760, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.543003\n",
      "[LightGBM] [Info] Number of positive: 12484, number of negative: 12484\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 24968, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.496955\n",
      "[LightGBM] [Info] Number of positive: 15933, number of negative: 15932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116345\n",
      "[LightGBM] [Info] Number of data points in the train set: 31865, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.475453\n",
      "[LightGBM] [Info] Number of positive: 17624, number of negative: 17624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116361\n",
      "[LightGBM] [Info] Number of data points in the train set: 35248, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.508606\n",
      "[LightGBM] [Info] Number of positive: 14842, number of negative: 14842\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116251\n",
      "[LightGBM] [Info] Number of data points in the train set: 29684, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.530458\n",
      "[LightGBM] [Info] Number of positive: 14578, number of negative: 14577\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116331\n",
      "[LightGBM] [Info] Number of data points in the train set: 29155, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000069\n",
      "[LightGBM] [Info] Start training from score 0.000069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.468248\n",
      "[LightGBM] [Info] Number of positive: 16499, number of negative: 16499\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116416\n",
      "[LightGBM] [Info] Number of data points in the train set: 32998, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.481998\n",
      "[LightGBM] [Info] Number of positive: 18835, number of negative: 18835\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116432\n",
      "[LightGBM] [Info] Number of data points in the train set: 37670, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's binary_logloss: 0.489523\n",
      "[LightGBM] [Info] Number of positive: 16551, number of negative: 16551\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116433\n",
      "[LightGBM] [Info] Number of data points in the train set: 33102, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.507671\n",
      "[LightGBM] [Info] Number of positive: 18174, number of negative: 18173\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116554\n",
      "[LightGBM] [Info] Number of data points in the train set: 36347, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000055\n",
      "[LightGBM] [Info] Start training from score 0.000055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.509559\n",
      "[LightGBM] [Info] Number of positive: 15825, number of negative: 15824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 31649, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.530019\n",
      "[LightGBM] [Info] Number of positive: 18570, number of negative: 18570\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116395\n",
      "[LightGBM] [Info] Number of data points in the train set: 37140, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.465658\n",
      "[LightGBM] [Info] Number of positive: 19079, number of negative: 19079\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116421\n",
      "[LightGBM] [Info] Number of data points in the train set: 38158, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.502286\n",
      "[LightGBM] [Info] Number of positive: 19739, number of negative: 19739\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116394\n",
      "[LightGBM] [Info] Number of data points in the train set: 39478, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.524278\n",
      "[LightGBM] [Info] Number of positive: 13982, number of negative: 13981\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116329\n",
      "[LightGBM] [Info] Number of data points in the train set: 27963, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.522805\n",
      "[LightGBM] [Info] Number of positive: 14182, number of negative: 14181\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116214\n",
      "[LightGBM] [Info] Number of data points in the train set: 28363, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.537558\n",
      "[LightGBM] [Info] Number of positive: 18606, number of negative: 18605\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116496\n",
      "[LightGBM] [Info] Number of data points in the train set: 37211, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's binary_logloss: 0.462964\n",
      "[LightGBM] [Info] Number of positive: 18192, number of negative: 18192\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116397\n",
      "[LightGBM] [Info] Number of data points in the train set: 36384, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid_0's binary_logloss: 0.442128\n",
      "[LightGBM] [Info] Number of positive: 15297, number of negative: 15296\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 30593, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's binary_logloss: 0.478525\n",
      "[LightGBM] [Info] Number of positive: 15493, number of negative: 15492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116259\n",
      "[LightGBM] [Info] Number of data points in the train set: 30985, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.477092\n",
      "[LightGBM] [Info] Number of positive: 13471, number of negative: 13471\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116200\n",
      "[LightGBM] [Info] Number of data points in the train set: 26942, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.513018\n",
      "[LightGBM] [Info] Number of positive: 16475, number of negative: 16475\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116296\n",
      "[LightGBM] [Info] Number of data points in the train set: 32950, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[391]\tvalid_0's binary_logloss: 0.533504\n",
      "[LightGBM] [Info] Number of positive: 13843, number of negative: 13843\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116290\n",
      "[LightGBM] [Info] Number of data points in the train set: 27686, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's binary_logloss: 0.475349\n",
      "[LightGBM] [Info] Number of positive: 15097, number of negative: 15096\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116212\n",
      "[LightGBM] [Info] Number of data points in the train set: 30193, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's binary_logloss: 0.444917\n",
      "[LightGBM] [Info] Number of positive: 16331, number of negative: 16331\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 32662, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's binary_logloss: 0.475462\n",
      "[LightGBM] [Info] Number of positive: 15426, number of negative: 15426\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116336\n",
      "[LightGBM] [Info] Number of data points in the train set: 30852, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's binary_logloss: 0.472303\n",
      "[LightGBM] [Info] Number of positive: 20727, number of negative: 20727\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116568\n",
      "[LightGBM] [Info] Number of data points in the train set: 41454, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's binary_logloss: 0.470449\n",
      "[LightGBM] [Info] Number of positive: 17950, number of negative: 17950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116367\n",
      "[LightGBM] [Info] Number of data points in the train set: 35900, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[355]\tvalid_0's binary_logloss: 0.493346\n",
      "[LightGBM] [Info] Number of positive: 17406, number of negative: 17405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116347\n",
      "[LightGBM] [Info] Number of data points in the train set: 34811, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's binary_logloss: 0.474927\n",
      "[LightGBM] [Info] Number of positive: 15105, number of negative: 15104\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116376\n",
      "[LightGBM] [Info] Number of data points in the train set: 30209, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.492266\n",
      "[LightGBM] [Info] Number of positive: 16667, number of negative: 16667\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116440\n",
      "[LightGBM] [Info] Number of data points in the train set: 33334, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.543856\n",
      "[LightGBM] [Info] Number of positive: 14627, number of negative: 14627\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116273\n",
      "[LightGBM] [Info] Number of data points in the train set: 29254, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[368]\tvalid_0's binary_logloss: 0.481611\n",
      "[LightGBM] [Info] Number of positive: 13354, number of negative: 13354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116209\n",
      "[LightGBM] [Info] Number of data points in the train set: 26708, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.556331\n",
      "[LightGBM] [Info] Number of positive: 17926, number of negative: 17926\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116379\n",
      "[LightGBM] [Info] Number of data points in the train set: 35852, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's binary_logloss: 0.492435\n",
      "[LightGBM] [Info] Number of positive: 14890, number of negative: 14889\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116411\n",
      "[LightGBM] [Info] Number of data points in the train set: 29779, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.475788\n",
      "[LightGBM] [Info] Number of positive: 17409, number of negative: 17408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116438\n",
      "[LightGBM] [Info] Number of data points in the train set: 34817, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.522401\n",
      "[LightGBM] [Info] Number of positive: 17534, number of negative: 17534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 35068, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's binary_logloss: 0.430594\n",
      "[LightGBM] [Info] Number of positive: 13258, number of negative: 13258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116291\n",
      "[LightGBM] [Info] Number of data points in the train set: 26516, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.514642\n",
      "[LightGBM] [Info] Number of positive: 16830, number of negative: 16830\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116447\n",
      "[LightGBM] [Info] Number of data points in the train set: 33660, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's binary_logloss: 0.432775\n",
      "[LightGBM] [Info] Number of positive: 16271, number of negative: 16271\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 32542, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's binary_logloss: 0.513109\n",
      "[LightGBM] [Info] Number of positive: 14083, number of negative: 14083\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116243\n",
      "[LightGBM] [Info] Number of data points in the train set: 28166, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.50244\n",
      "[LightGBM] [Info] Number of positive: 16724, number of negative: 16724\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116282\n",
      "[LightGBM] [Info] Number of data points in the train set: 33448, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.510891\n",
      "[LightGBM] [Info] Number of positive: 14101, number of negative: 14100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116303\n",
      "[LightGBM] [Info] Number of data points in the train set: 28201, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.496832\n",
      "[LightGBM] [Info] Number of positive: 14750, number of negative: 14749\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116366\n",
      "[LightGBM] [Info] Number of data points in the train set: 29499, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's binary_logloss: 0.509954\n",
      "[LightGBM] [Info] Number of positive: 15346, number of negative: 15346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 30692, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's binary_logloss: 0.460816\n",
      "[LightGBM] [Info] Number of positive: 14266, number of negative: 14266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116252\n",
      "[LightGBM] [Info] Number of data points in the train set: 28532, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.482963\n",
      "[LightGBM] [Info] Number of positive: 17804, number of negative: 17804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116539\n",
      "[LightGBM] [Info] Number of data points in the train set: 35608, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.516196\n",
      "[LightGBM] [Info] Number of positive: 14582, number of negative: 14582\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116385\n",
      "[LightGBM] [Info] Number of data points in the train set: 29164, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.469316\n",
      "[LightGBM] [Info] Number of positive: 16180, number of negative: 16180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116358\n",
      "[LightGBM] [Info] Number of data points in the train set: 32360, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.512646\n",
      "[LightGBM] [Info] Number of positive: 17953, number of negative: 17952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116377\n",
      "[LightGBM] [Info] Number of data points in the train set: 35905, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.516028\n",
      "[LightGBM] [Info] Number of positive: 15671, number of negative: 15671\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116291\n",
      "[LightGBM] [Info] Number of data points in the train set: 31342, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.492468\n",
      "[LightGBM] [Info] Number of positive: 14552, number of negative: 14552\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116292\n",
      "[LightGBM] [Info] Number of data points in the train set: 29104, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's binary_logloss: 0.531941\n",
      "[LightGBM] [Info] Number of positive: 16208, number of negative: 16208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116246\n",
      "[LightGBM] [Info] Number of data points in the train set: 32416, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.476938\n",
      "[LightGBM] [Info] Number of positive: 13646, number of negative: 13645\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116224\n",
      "[LightGBM] [Info] Number of data points in the train set: 27291, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000073\n",
      "[LightGBM] [Info] Start training from score 0.000073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's binary_logloss: 0.527744\n",
      "[LightGBM] [Info] Number of positive: 18710, number of negative: 18710\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116426\n",
      "[LightGBM] [Info] Number of data points in the train set: 37420, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's binary_logloss: 0.474516\n",
      "[LightGBM] [Info] Number of positive: 14542, number of negative: 14541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116260\n",
      "[LightGBM] [Info] Number of data points in the train set: 29083, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000069\n",
      "[LightGBM] [Info] Start training from score 0.000069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.487561\n",
      "[LightGBM] [Info] Number of positive: 19244, number of negative: 19244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116486\n",
      "[LightGBM] [Info] Number of data points in the train set: 38488, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.482159\n",
      "[LightGBM] [Info] Number of positive: 13241, number of negative: 13240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 26481, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.527623\n",
      "[LightGBM] [Info] Number of positive: 15922, number of negative: 15921\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116340\n",
      "[LightGBM] [Info] Number of data points in the train set: 31843, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's binary_logloss: 0.471577\n",
      "[LightGBM] [Info] Number of positive: 14528, number of negative: 14528\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116382\n",
      "[LightGBM] [Info] Number of data points in the train set: 29056, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's binary_logloss: 0.496651\n",
      "[LightGBM] [Info] Number of positive: 17869, number of negative: 17868\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116390\n",
      "[LightGBM] [Info] Number of data points in the train set: 35737, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's binary_logloss: 0.506537\n",
      "[LightGBM] [Info] Number of positive: 16761, number of negative: 16760\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116375\n",
      "[LightGBM] [Info] Number of data points in the train set: 33521, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.558892\n",
      "[LightGBM] [Info] Number of positive: 20610, number of negative: 20610\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116422\n",
      "[LightGBM] [Info] Number of data points in the train set: 41220, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.482544\n",
      "[LightGBM] [Info] Number of positive: 15413, number of negative: 15412\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116227\n",
      "[LightGBM] [Info] Number of data points in the train set: 30825, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.427505\n",
      "[LightGBM] [Info] Number of positive: 18230, number of negative: 18230\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116301\n",
      "[LightGBM] [Info] Number of data points in the train set: 36460, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.514883\n",
      "[LightGBM] [Info] Number of positive: 15194, number of negative: 15193\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116327\n",
      "[LightGBM] [Info] Number of data points in the train set: 30387, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.565788\n",
      "[LightGBM] [Info] Number of positive: 16338, number of negative: 16338\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116424\n",
      "[LightGBM] [Info] Number of data points in the train set: 32676, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's binary_logloss: 0.501298\n",
      "[LightGBM] [Info] Number of positive: 17275, number of negative: 17275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116433\n",
      "[LightGBM] [Info] Number of data points in the train set: 34550, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.468872\n",
      "[LightGBM] [Info] Number of positive: 14973, number of negative: 14972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116287\n",
      "[LightGBM] [Info] Number of data points in the train set: 29945, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.559393\n",
      "[LightGBM] [Info] Number of positive: 16574, number of negative: 16573\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116387\n",
      "[LightGBM] [Info] Number of data points in the train set: 33147, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's binary_logloss: 0.497071\n",
      "[LightGBM] [Info] Number of positive: 16078, number of negative: 16078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116346\n",
      "[LightGBM] [Info] Number of data points in the train set: 32156, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.39853\n",
      "[LightGBM] [Info] Number of positive: 15986, number of negative: 15986\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116370\n",
      "[LightGBM] [Info] Number of data points in the train set: 31972, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's binary_logloss: 0.493655\n",
      "[LightGBM] [Info] Number of positive: 18458, number of negative: 18457\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116493\n",
      "[LightGBM] [Info] Number of data points in the train set: 36915, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's binary_logloss: 0.510267\n",
      "[LightGBM] [Info] Number of positive: 12737, number of negative: 12736\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116233\n",
      "[LightGBM] [Info] Number of data points in the train set: 25473, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000079\n",
      "[LightGBM] [Info] Start training from score 0.000079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.534254\n",
      "[LightGBM] [Info] Number of positive: 13250, number of negative: 13249\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116251\n",
      "[LightGBM] [Info] Number of data points in the train set: 26499, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000075\n",
      "[LightGBM] [Info] Start training from score 0.000075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.504643\n",
      "[LightGBM] [Info] Number of positive: 15729, number of negative: 15728\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 31457, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.500009\n",
      "[LightGBM] [Info] Number of positive: 14567, number of negative: 14567\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116197\n",
      "[LightGBM] [Info] Number of data points in the train set: 29134, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's binary_logloss: 0.497893\n",
      "[LightGBM] [Info] Number of positive: 19932, number of negative: 19932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116450\n",
      "[LightGBM] [Info] Number of data points in the train set: 39864, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.545532\n",
      "[LightGBM] [Info] Number of positive: 14684, number of negative: 14684\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116353\n",
      "[LightGBM] [Info] Number of data points in the train set: 29368, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's binary_logloss: 0.504438\n",
      "[LightGBM] [Info] Number of positive: 14619, number of negative: 14619\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116287\n",
      "[LightGBM] [Info] Number of data points in the train set: 29238, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.492153\n",
      "[LightGBM] [Info] Number of positive: 15717, number of negative: 15716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116318\n",
      "[LightGBM] [Info] Number of data points in the train set: 31433, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.432422\n",
      "[LightGBM] [Info] Number of positive: 17082, number of negative: 17082\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116267\n",
      "[LightGBM] [Info] Number of data points in the train set: 34164, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.533166\n",
      "[LightGBM] [Info] Number of positive: 12289, number of negative: 12288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116142\n",
      "[LightGBM] [Info] Number of data points in the train set: 24577, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000081\n",
      "[LightGBM] [Info] Start training from score 0.000081\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.543996\n",
      "[LightGBM] [Info] Number of positive: 14999, number of negative: 14999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116437\n",
      "[LightGBM] [Info] Number of data points in the train set: 29998, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.531751\n",
      "[LightGBM] [Info] Number of positive: 15229, number of negative: 15228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 30457, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.413655\n",
      "[LightGBM] [Info] Number of positive: 15726, number of negative: 15725\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116265\n",
      "[LightGBM] [Info] Number of data points in the train set: 31451, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's binary_logloss: 0.488501\n",
      "[LightGBM] [Info] Number of positive: 13546, number of negative: 13545\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116168\n",
      "[LightGBM] [Info] Number of data points in the train set: 27091, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.486411\n",
      "[LightGBM] [Info] Number of positive: 14330, number of negative: 14329\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 28659, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's binary_logloss: 0.499978\n",
      "[LightGBM] [Info] Number of positive: 16836, number of negative: 16836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116332\n",
      "[LightGBM] [Info] Number of data points in the train set: 33672, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's binary_logloss: 0.531601\n",
      "[LightGBM] [Info] Number of positive: 14936, number of negative: 14936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116339\n",
      "[LightGBM] [Info] Number of data points in the train set: 29872, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.513227\n",
      "[LightGBM] [Info] Number of positive: 15725, number of negative: 15724\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116302\n",
      "[LightGBM] [Info] Number of data points in the train set: 31449, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's binary_logloss: 0.431339\n",
      "[LightGBM] [Info] Number of positive: 17634, number of negative: 17633\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116409\n",
      "[LightGBM] [Info] Number of data points in the train set: 35267, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.537959\n",
      "[LightGBM] [Info] Number of positive: 17094, number of negative: 17093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116409\n",
      "[LightGBM] [Info] Number of data points in the train set: 34187, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.509931\n",
      "[LightGBM] [Info] Number of positive: 18520, number of negative: 18520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 37040, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's binary_logloss: 0.485387\n",
      "[LightGBM] [Info] Number of positive: 18736, number of negative: 18736\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116421\n",
      "[LightGBM] [Info] Number of data points in the train set: 37472, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's binary_logloss: 0.48583\n",
      "[LightGBM] [Info] Number of positive: 14192, number of negative: 14192\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 28384, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.546645\n",
      "[LightGBM] [Info] Number of positive: 17844, number of negative: 17844\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116421\n",
      "[LightGBM] [Info] Number of data points in the train set: 35688, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's binary_logloss: 0.46611\n",
      "[LightGBM] [Info] Number of positive: 15669, number of negative: 15668\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116414\n",
      "[LightGBM] [Info] Number of data points in the train set: 31337, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.497908\n",
      "[LightGBM] [Info] Number of positive: 17412, number of negative: 17412\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116399\n",
      "[LightGBM] [Info] Number of data points in the train set: 34824, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's binary_logloss: 0.478518\n",
      "[LightGBM] [Info] Number of positive: 14201, number of negative: 14200\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116265\n",
      "[LightGBM] [Info] Number of data points in the train set: 28401, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.504747\n",
      "[LightGBM] [Info] Number of positive: 17578, number of negative: 17577\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116397\n",
      "[LightGBM] [Info] Number of data points in the train set: 35155, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.473747\n",
      "[LightGBM] [Info] Number of positive: 18030, number of negative: 18030\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 36060, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's binary_logloss: 0.50219\n",
      "[LightGBM] [Info] Number of positive: 17588, number of negative: 17588\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116409\n",
      "[LightGBM] [Info] Number of data points in the train set: 35176, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's binary_logloss: 0.503057\n",
      "[LightGBM] [Info] Number of positive: 17901, number of negative: 17900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116365\n",
      "[LightGBM] [Info] Number of data points in the train set: 35801, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.467302\n",
      "[LightGBM] [Info] Number of positive: 17062, number of negative: 17061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116463\n",
      "[LightGBM] [Info] Number of data points in the train set: 34123, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.486564\n",
      "[LightGBM] [Info] Number of positive: 13002, number of negative: 13001\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116293\n",
      "[LightGBM] [Info] Number of data points in the train set: 26003, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000077\n",
      "[LightGBM] [Info] Start training from score 0.000077\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's binary_logloss: 0.469489\n",
      "[LightGBM] [Info] Number of positive: 19622, number of negative: 19622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116458\n",
      "[LightGBM] [Info] Number of data points in the train set: 39244, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's binary_logloss: 0.459602\n",
      "[LightGBM] [Info] Number of positive: 12821, number of negative: 12820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116229\n",
      "[LightGBM] [Info] Number of data points in the train set: 25641, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.527106\n",
      "[LightGBM] [Info] Number of positive: 14227, number of negative: 14227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 28454, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.498299\n",
      "[LightGBM] [Info] Number of positive: 15548, number of negative: 15548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116289\n",
      "[LightGBM] [Info] Number of data points in the train set: 31096, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.513554\n",
      "[LightGBM] [Info] Number of positive: 16443, number of negative: 16443\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116336\n",
      "[LightGBM] [Info] Number of data points in the train set: 32886, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.470926\n",
      "[LightGBM] [Info] Number of positive: 21324, number of negative: 21324\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116419\n",
      "[LightGBM] [Info] Number of data points in the train set: 42648, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.468374\n",
      "[LightGBM] [Info] Number of positive: 17917, number of negative: 17916\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116387\n",
      "[LightGBM] [Info] Number of data points in the train set: 35833, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.501789\n",
      "[LightGBM] [Info] Number of positive: 15997, number of negative: 15996\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116302\n",
      "[LightGBM] [Info] Number of data points in the train set: 31993, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's binary_logloss: 0.473562\n",
      "[LightGBM] [Info] Number of positive: 15642, number of negative: 15642\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116296\n",
      "[LightGBM] [Info] Number of data points in the train set: 31284, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.496256\n",
      "[LightGBM] [Info] Number of positive: 14304, number of negative: 14304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 28608, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's binary_logloss: 0.502172\n",
      "[LightGBM] [Info] Number of positive: 15089, number of negative: 15088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 30177, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's binary_logloss: 0.421364\n",
      "[LightGBM] [Info] Number of positive: 15515, number of negative: 15515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 31030, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's binary_logloss: 0.50931\n",
      "[LightGBM] [Info] Number of positive: 17850, number of negative: 17849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116380\n",
      "[LightGBM] [Info] Number of data points in the train set: 35699, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's binary_logloss: 0.501553\n",
      "[LightGBM] [Info] Number of positive: 16014, number of negative: 16014\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 32028, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.516876\n",
      "[LightGBM] [Info] Number of positive: 16854, number of negative: 16853\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116356\n",
      "[LightGBM] [Info] Number of data points in the train set: 33707, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.50461\n",
      "[LightGBM] [Info] Number of positive: 13265, number of negative: 13264\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116244\n",
      "[LightGBM] [Info] Number of data points in the train set: 26529, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000075\n",
      "[LightGBM] [Info] Start training from score 0.000075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.456654\n",
      "[LightGBM] [Info] Number of positive: 14889, number of negative: 14888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116287\n",
      "[LightGBM] [Info] Number of data points in the train set: 29777, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.512521\n",
      "[LightGBM] [Info] Number of positive: 16901, number of negative: 16900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116377\n",
      "[LightGBM] [Info] Number of data points in the train set: 33801, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's binary_logloss: 0.490268\n",
      "[LightGBM] [Info] Number of positive: 17137, number of negative: 17136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116426\n",
      "[LightGBM] [Info] Number of data points in the train set: 34273, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000058\n",
      "[LightGBM] [Info] Start training from score 0.000058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.471034\n",
      "[LightGBM] [Info] Number of positive: 15007, number of negative: 15007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116292\n",
      "[LightGBM] [Info] Number of data points in the train set: 30014, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's binary_logloss: 0.468232\n",
      "[LightGBM] [Info] Number of positive: 14334, number of negative: 14334\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116371\n",
      "[LightGBM] [Info] Number of data points in the train set: 28668, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.481306\n",
      "[LightGBM] [Info] Number of positive: 15555, number of negative: 15555\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116419\n",
      "[LightGBM] [Info] Number of data points in the train set: 31110, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's binary_logloss: 0.456298\n",
      "[LightGBM] [Info] Number of positive: 16763, number of negative: 16763\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116352\n",
      "[LightGBM] [Info] Number of data points in the train set: 33526, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.526282\n",
      "[LightGBM] [Info] Number of positive: 20163, number of negative: 20163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116428\n",
      "[LightGBM] [Info] Number of data points in the train set: 40326, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's binary_logloss: 0.489576\n",
      "[LightGBM] [Info] Number of positive: 16766, number of negative: 16766\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116477\n",
      "[LightGBM] [Info] Number of data points in the train set: 33532, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.511169\n",
      "[LightGBM] [Info] Number of positive: 18988, number of negative: 18988\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116554\n",
      "[LightGBM] [Info] Number of data points in the train set: 37976, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.486716\n",
      "[LightGBM] [Info] Number of positive: 14140, number of negative: 14140\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116225\n",
      "[LightGBM] [Info] Number of data points in the train set: 28280, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.481372\n",
      "[LightGBM] [Info] Number of positive: 17718, number of negative: 17717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116377\n",
      "[LightGBM] [Info] Number of data points in the train set: 35435, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.510922\n",
      "[LightGBM] [Info] Number of positive: 15378, number of negative: 15377\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116460\n",
      "[LightGBM] [Info] Number of data points in the train set: 30755, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.501762\n",
      "[LightGBM] [Info] Number of positive: 15573, number of negative: 15572\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116224\n",
      "[LightGBM] [Info] Number of data points in the train set: 31145, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.494474\n",
      "[LightGBM] [Info] Number of positive: 14210, number of negative: 14210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 28420, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.486597\n",
      "[LightGBM] [Info] Number of positive: 15954, number of negative: 15954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116338\n",
      "[LightGBM] [Info] Number of data points in the train set: 31908, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.487837\n",
      "[LightGBM] [Info] Number of positive: 15006, number of negative: 15006\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116300\n",
      "[LightGBM] [Info] Number of data points in the train set: 30012, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's binary_logloss: 0.511985\n",
      "[LightGBM] [Info] Number of positive: 20466, number of negative: 20466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116355\n",
      "[LightGBM] [Info] Number of data points in the train set: 40932, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's binary_logloss: 0.497921\n",
      "[LightGBM] [Info] Number of positive: 15092, number of negative: 15092\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116286\n",
      "[LightGBM] [Info] Number of data points in the train set: 30184, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's binary_logloss: 0.494465\n",
      "[LightGBM] [Info] Number of positive: 16366, number of negative: 16366\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116252\n",
      "[LightGBM] [Info] Number of data points in the train set: 32732, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.502086\n",
      "[LightGBM] [Info] Number of positive: 16031, number of negative: 16031\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116397\n",
      "[LightGBM] [Info] Number of data points in the train set: 32062, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.555139\n",
      "[LightGBM] [Info] Number of positive: 19701, number of negative: 19700\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116406\n",
      "[LightGBM] [Info] Number of data points in the train set: 39401, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000051\n",
      "[LightGBM] [Info] Start training from score 0.000051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's binary_logloss: 0.473994\n",
      "[LightGBM] [Info] Number of positive: 17824, number of negative: 17824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116394\n",
      "[LightGBM] [Info] Number of data points in the train set: 35648, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.420289\n",
      "[LightGBM] [Info] Number of positive: 15646, number of negative: 15646\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 31292, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.550463\n",
      "[LightGBM] [Info] Number of positive: 18934, number of negative: 18933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 37867, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.49437\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 16652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116372\n",
      "[LightGBM] [Info] Number of data points in the train set: 33305, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's binary_logloss: 0.486809\n",
      "[LightGBM] [Info] Number of positive: 16206, number of negative: 16205\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116370\n",
      "[LightGBM] [Info] Number of data points in the train set: 32411, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.491813\n",
      "[LightGBM] [Info] Number of positive: 15270, number of negative: 15269\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 30539, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's binary_logloss: 0.489431\n",
      "[LightGBM] [Info] Number of positive: 14324, number of negative: 14324\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116307\n",
      "[LightGBM] [Info] Number of data points in the train set: 28648, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.504425\n",
      "[LightGBM] [Info] Number of positive: 15706, number of negative: 15705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 31411, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.496633\n",
      "[LightGBM] [Info] Number of positive: 16170, number of negative: 16170\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116348\n",
      "[LightGBM] [Info] Number of data points in the train set: 32340, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.507906\n",
      "[LightGBM] [Info] Number of positive: 14125, number of negative: 14124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116251\n",
      "[LightGBM] [Info] Number of data points in the train set: 28249, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.482594\n",
      "[LightGBM] [Info] Number of positive: 20146, number of negative: 20145\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116406\n",
      "[LightGBM] [Info] Number of data points in the train set: 40291, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500012 -> initscore=0.000050\n",
      "[LightGBM] [Info] Start training from score 0.000050\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.47607\n",
      "[LightGBM] [Info] Number of positive: 17094, number of negative: 17093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116323\n",
      "[LightGBM] [Info] Number of data points in the train set: 34187, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.531367\n",
      "[LightGBM] [Info] Number of positive: 18106, number of negative: 18105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116337\n",
      "[LightGBM] [Info] Number of data points in the train set: 36211, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000055\n",
      "[LightGBM] [Info] Start training from score 0.000055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.548439\n",
      "[LightGBM] [Info] Number of positive: 13189, number of negative: 13188\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116363\n",
      "[LightGBM] [Info] Number of data points in the train set: 26377, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.448253\n",
      "[LightGBM] [Info] Number of positive: 16086, number of negative: 16086\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116266\n",
      "[LightGBM] [Info] Number of data points in the train set: 32172, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's binary_logloss: 0.54093\n",
      "[LightGBM] [Info] Number of positive: 15637, number of negative: 15636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116238\n",
      "[LightGBM] [Info] Number of data points in the train set: 31273, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's binary_logloss: 0.542612\n",
      "[LightGBM] [Info] Number of positive: 16798, number of negative: 16798\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116411\n",
      "[LightGBM] [Info] Number of data points in the train set: 33596, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.517374\n",
      "[LightGBM] [Info] Number of positive: 14208, number of negative: 14208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116362\n",
      "[LightGBM] [Info] Number of data points in the train set: 28416, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.463968\n",
      "[LightGBM] [Info] Number of positive: 16835, number of negative: 16835\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116363\n",
      "[LightGBM] [Info] Number of data points in the train set: 33670, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's binary_logloss: 0.482863\n",
      "[LightGBM] [Info] Number of positive: 13379, number of negative: 13379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116292\n",
      "[LightGBM] [Info] Number of data points in the train set: 26758, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.434981\n",
      "[LightGBM] [Info] Number of positive: 19789, number of negative: 19788\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116547\n",
      "[LightGBM] [Info] Number of data points in the train set: 39577, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000051\n",
      "[LightGBM] [Info] Start training from score 0.000051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[367]\tvalid_0's binary_logloss: 0.452509\n",
      "[LightGBM] [Info] Number of positive: 16716, number of negative: 16716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116299\n",
      "[LightGBM] [Info] Number of data points in the train set: 33432, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.477468\n",
      "[LightGBM] [Info] Number of positive: 14871, number of negative: 14871\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116344\n",
      "[LightGBM] [Info] Number of data points in the train set: 29742, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.469228\n",
      "[LightGBM] [Info] Number of positive: 13708, number of negative: 13708\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116300\n",
      "[LightGBM] [Info] Number of data points in the train set: 27416, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.54402\n",
      "[LightGBM] [Info] Number of positive: 15670, number of negative: 15669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116300\n",
      "[LightGBM] [Info] Number of data points in the train set: 31339, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's binary_logloss: 0.480112\n",
      "[LightGBM] [Info] Number of positive: 15627, number of negative: 15627\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 31254, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[414]\tvalid_0's binary_logloss: 0.509526\n",
      "[LightGBM] [Info] Number of positive: 17554, number of negative: 17553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116469\n",
      "[LightGBM] [Info] Number of data points in the train set: 35107, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[287]\tvalid_0's binary_logloss: 0.519036\n",
      "[LightGBM] [Info] Number of positive: 20459, number of negative: 20459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116500\n",
      "[LightGBM] [Info] Number of data points in the train set: 40918, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's binary_logloss: 0.514907\n",
      "[LightGBM] [Info] Number of positive: 16062, number of negative: 16061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116354\n",
      "[LightGBM] [Info] Number of data points in the train set: 32123, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's binary_logloss: 0.507193\n",
      "[LightGBM] [Info] Number of positive: 14544, number of negative: 14544\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 29088, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's binary_logloss: 0.453221\n",
      "[LightGBM] [Info] Number of positive: 15527, number of negative: 15527\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116304\n",
      "[LightGBM] [Info] Number of data points in the train set: 31054, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's binary_logloss: 0.489622\n",
      "[LightGBM] [Info] Number of positive: 14403, number of negative: 14403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116340\n",
      "[LightGBM] [Info] Number of data points in the train set: 28806, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid_0's binary_logloss: 0.459402\n",
      "[LightGBM] [Info] Number of positive: 13922, number of negative: 13922\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 27844, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's binary_logloss: 0.494804\n",
      "[LightGBM] [Info] Number of positive: 16170, number of negative: 16169\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 32339, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's binary_logloss: 0.501257\n",
      "[LightGBM] [Info] Number of positive: 15979, number of negative: 15979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116286\n",
      "[LightGBM] [Info] Number of data points in the train set: 31958, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.530592\n",
      "[LightGBM] [Info] Number of positive: 16722, number of negative: 16722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116324\n",
      "[LightGBM] [Info] Number of data points in the train set: 33444, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's binary_logloss: 0.520012\n",
      "[LightGBM] [Info] Number of positive: 17850, number of negative: 17849\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116455\n",
      "[LightGBM] [Info] Number of data points in the train set: 35699, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.527225\n",
      "[LightGBM] [Info] Number of positive: 16488, number of negative: 16488\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116472\n",
      "[LightGBM] [Info] Number of data points in the train set: 32976, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's binary_logloss: 0.500572\n",
      "[LightGBM] [Info] Number of positive: 13973, number of negative: 13972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116258\n",
      "[LightGBM] [Info] Number of data points in the train set: 27945, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.518898\n",
      "[LightGBM] [Info] Number of positive: 18731, number of negative: 18731\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116444\n",
      "[LightGBM] [Info] Number of data points in the train set: 37462, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's binary_logloss: 0.497418\n",
      "[LightGBM] [Info] Number of positive: 19605, number of negative: 19604\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116388\n",
      "[LightGBM] [Info] Number of data points in the train set: 39209, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000051\n",
      "[LightGBM] [Info] Start training from score 0.000051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.513411\n",
      "[LightGBM] [Info] Number of positive: 15874, number of negative: 15873\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116353\n",
      "[LightGBM] [Info] Number of data points in the train set: 31747, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.478034\n",
      "[LightGBM] [Info] Number of positive: 16674, number of negative: 16673\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116354\n",
      "[LightGBM] [Info] Number of data points in the train set: 33347, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.538713\n",
      "[LightGBM] [Info] Number of positive: 12947, number of negative: 12947\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 25894, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's binary_logloss: 0.48591\n",
      "[LightGBM] [Info] Number of positive: 13214, number of negative: 13214\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116341\n",
      "[LightGBM] [Info] Number of data points in the train set: 26428, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.528978\n",
      "[LightGBM] [Info] Number of positive: 12978, number of negative: 12978\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116271\n",
      "[LightGBM] [Info] Number of data points in the train set: 25956, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.50426\n",
      "[LightGBM] [Info] Number of positive: 14751, number of negative: 14751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116304\n",
      "[LightGBM] [Info] Number of data points in the train set: 29502, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's binary_logloss: 0.466781\n",
      "[LightGBM] [Info] Number of positive: 17842, number of negative: 17841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116504\n",
      "[LightGBM] [Info] Number of data points in the train set: 35683, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's binary_logloss: 0.498532\n",
      "[LightGBM] [Info] Number of positive: 14146, number of negative: 14146\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 28292, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.472869\n",
      "[LightGBM] [Info] Number of positive: 14590, number of negative: 14590\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116292\n",
      "[LightGBM] [Info] Number of data points in the train set: 29180, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.498173\n",
      "[LightGBM] [Info] Number of positive: 16970, number of negative: 16969\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 33939, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's binary_logloss: 0.5043\n",
      "[LightGBM] [Info] Number of positive: 14361, number of negative: 14360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116302\n",
      "[LightGBM] [Info] Number of data points in the train set: 28721, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.528852\n",
      "[LightGBM] [Info] Number of positive: 16107, number of negative: 16107\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116354\n",
      "[LightGBM] [Info] Number of data points in the train set: 32214, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.586289\n",
      "[LightGBM] [Info] Number of positive: 14813, number of negative: 14812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116363\n",
      "[LightGBM] [Info] Number of data points in the train set: 29625, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.552737\n",
      "[LightGBM] [Info] Number of positive: 14338, number of negative: 14338\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 28676, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's binary_logloss: 0.495435\n",
      "[LightGBM] [Info] Number of positive: 18227, number of negative: 18227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116431\n",
      "[LightGBM] [Info] Number of data points in the train set: 36454, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.538394\n",
      "[LightGBM] [Info] Number of positive: 14373, number of negative: 14372\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 28745, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.518867\n",
      "[LightGBM] [Info] Number of positive: 14508, number of negative: 14508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116319\n",
      "[LightGBM] [Info] Number of data points in the train set: 29016, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.493914\n",
      "[LightGBM] [Info] Number of positive: 14178, number of negative: 14177\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116394\n",
      "[LightGBM] [Info] Number of data points in the train set: 28355, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.482283\n",
      "[LightGBM] [Info] Number of positive: 14537, number of negative: 14536\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116419\n",
      "[LightGBM] [Info] Number of data points in the train set: 29073, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000069\n",
      "[LightGBM] [Info] Start training from score 0.000069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's binary_logloss: 0.461847\n",
      "[LightGBM] [Info] Number of positive: 16106, number of negative: 16105\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116355\n",
      "[LightGBM] [Info] Number of data points in the train set: 32211, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.472554\n",
      "[LightGBM] [Info] Number of positive: 15449, number of negative: 15448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116440\n",
      "[LightGBM] [Info] Number of data points in the train set: 30897, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.510689\n",
      "[LightGBM] [Info] Number of positive: 16888, number of negative: 16888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116377\n",
      "[LightGBM] [Info] Number of data points in the train set: 33776, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.46182\n",
      "[LightGBM] [Info] Number of positive: 17295, number of negative: 17295\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116310\n",
      "[LightGBM] [Info] Number of data points in the train set: 34590, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's binary_logloss: 0.479982\n",
      "[LightGBM] [Info] Number of positive: 15230, number of negative: 15230\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116330\n",
      "[LightGBM] [Info] Number of data points in the train set: 30460, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's binary_logloss: 0.476891\n",
      "[LightGBM] [Info] Number of positive: 16386, number of negative: 16386\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116485\n",
      "[LightGBM] [Info] Number of data points in the train set: 32772, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.494405\n",
      "[LightGBM] [Info] Number of positive: 15767, number of negative: 15767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 31534, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.524682\n",
      "[LightGBM] [Info] Number of positive: 17074, number of negative: 17073\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116418\n",
      "[LightGBM] [Info] Number of data points in the train set: 34147, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.543146\n",
      "[LightGBM] [Info] Number of positive: 15136, number of negative: 15136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 30272, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.540699\n",
      "[LightGBM] [Info] Number of positive: 16900, number of negative: 16900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116420\n",
      "[LightGBM] [Info] Number of data points in the train set: 33800, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's binary_logloss: 0.442886\n",
      "[LightGBM] [Info] Number of positive: 14607, number of negative: 14607\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 29214, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.499038\n",
      "[LightGBM] [Info] Number of positive: 14905, number of negative: 14904\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116346\n",
      "[LightGBM] [Info] Number of data points in the train set: 29809, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.553577\n",
      "[LightGBM] [Info] Number of positive: 15841, number of negative: 15840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116333\n",
      "[LightGBM] [Info] Number of data points in the train set: 31681, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.52398\n",
      "[LightGBM] [Info] Number of positive: 15204, number of negative: 15204\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116235\n",
      "[LightGBM] [Info] Number of data points in the train set: 30408, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's binary_logloss: 0.515856\n",
      "[LightGBM] [Info] Number of positive: 16014, number of negative: 16013\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 32027, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.506252\n",
      "[LightGBM] [Info] Number of positive: 14050, number of negative: 14049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116243\n",
      "[LightGBM] [Info] Number of data points in the train set: 28099, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.509668\n",
      "[LightGBM] [Info] Number of positive: 14310, number of negative: 14309\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116193\n",
      "[LightGBM] [Info] Number of data points in the train set: 28619, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.567671\n",
      "[LightGBM] [Info] Number of positive: 15954, number of negative: 15954\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116338\n",
      "[LightGBM] [Info] Number of data points in the train set: 31908, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.477139\n",
      "[LightGBM] [Info] Number of positive: 14616, number of negative: 14616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116229\n",
      "[LightGBM] [Info] Number of data points in the train set: 29232, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.516344\n",
      "[LightGBM] [Info] Number of positive: 18950, number of negative: 18949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116343\n",
      "[LightGBM] [Info] Number of data points in the train set: 37899, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.428325\n",
      "[LightGBM] [Info] Number of positive: 19410, number of negative: 19409\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 38819, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000052\n",
      "[LightGBM] [Info] Start training from score 0.000052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's binary_logloss: 0.478504\n",
      "[LightGBM] [Info] Number of positive: 18407, number of negative: 18407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116383\n",
      "[LightGBM] [Info] Number of data points in the train set: 36814, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.499791\n",
      "[LightGBM] [Info] Number of positive: 15639, number of negative: 15639\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116428\n",
      "[LightGBM] [Info] Number of data points in the train set: 31278, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.546295\n",
      "[LightGBM] [Info] Number of positive: 15220, number of negative: 15220\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116363\n",
      "[LightGBM] [Info] Number of data points in the train set: 30440, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's binary_logloss: 0.482831\n",
      "[LightGBM] [Info] Number of positive: 18084, number of negative: 18084\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116406\n",
      "[LightGBM] [Info] Number of data points in the train set: 36168, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's binary_logloss: 0.456577\n",
      "[LightGBM] [Info] Number of positive: 15209, number of negative: 15208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116271\n",
      "[LightGBM] [Info] Number of data points in the train set: 30417, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.547019\n",
      "[LightGBM] [Info] Number of positive: 12811, number of negative: 12811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 25622, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.532072\n",
      "[LightGBM] [Info] Number of positive: 13592, number of negative: 13592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116290\n",
      "[LightGBM] [Info] Number of data points in the train set: 27184, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.453572\n",
      "[LightGBM] [Info] Number of positive: 16249, number of negative: 16248\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116479\n",
      "[LightGBM] [Info] Number of data points in the train set: 32497, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.4767\n",
      "[LightGBM] [Info] Number of positive: 15623, number of negative: 15623\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 31246, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's binary_logloss: 0.501871\n",
      "[LightGBM] [Info] Number of positive: 15518, number of negative: 15518\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116311\n",
      "[LightGBM] [Info] Number of data points in the train set: 31036, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's binary_logloss: 0.481969\n",
      "[LightGBM] [Info] Number of positive: 14054, number of negative: 14054\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116314\n",
      "[LightGBM] [Info] Number of data points in the train set: 28108, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.485645\n",
      "[LightGBM] [Info] Number of positive: 20378, number of negative: 20378\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116386\n",
      "[LightGBM] [Info] Number of data points in the train set: 40756, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's binary_logloss: 0.507627\n",
      "[LightGBM] [Info] Number of positive: 16334, number of negative: 16333\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116365\n",
      "[LightGBM] [Info] Number of data points in the train set: 32667, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000061\n",
      "[LightGBM] [Info] Start training from score 0.000061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.501341\n",
      "[LightGBM] [Info] Number of positive: 16790, number of negative: 16790\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116375\n",
      "[LightGBM] [Info] Number of data points in the train set: 33580, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's binary_logloss: 0.469257\n",
      "[LightGBM] [Info] Number of positive: 18112, number of negative: 18112\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116397\n",
      "[LightGBM] [Info] Number of data points in the train set: 36224, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.468996\n",
      "[LightGBM] [Info] Number of positive: 16125, number of negative: 16124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116266\n",
      "[LightGBM] [Info] Number of data points in the train set: 32249, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.511868\n",
      "[LightGBM] [Info] Number of positive: 17892, number of negative: 17892\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116393\n",
      "[LightGBM] [Info] Number of data points in the train set: 35784, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's binary_logloss: 0.486743\n",
      "[LightGBM] [Info] Number of positive: 15759, number of negative: 15759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116426\n",
      "[LightGBM] [Info] Number of data points in the train set: 31518, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's binary_logloss: 0.507155\n",
      "[LightGBM] [Info] Number of positive: 17110, number of negative: 17110\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 34220, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.470469\n",
      "[LightGBM] [Info] Number of positive: 15148, number of negative: 15148\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 30296, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's binary_logloss: 0.462765\n",
      "[LightGBM] [Info] Number of positive: 17406, number of negative: 17406\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116232\n",
      "[LightGBM] [Info] Number of data points in the train set: 34812, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.536983\n",
      "[LightGBM] [Info] Number of positive: 17818, number of negative: 17818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 35636, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.463514\n",
      "[LightGBM] [Info] Number of positive: 17038, number of negative: 17038\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116380\n",
      "[LightGBM] [Info] Number of data points in the train set: 34076, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.514671\n",
      "[LightGBM] [Info] Number of positive: 18504, number of negative: 18504\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116371\n",
      "[LightGBM] [Info] Number of data points in the train set: 37008, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's binary_logloss: 0.48354\n",
      "[LightGBM] [Info] Number of positive: 14641, number of negative: 14640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116266\n",
      "[LightGBM] [Info] Number of data points in the train set: 29281, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.458176\n",
      "[LightGBM] [Info] Number of positive: 15458, number of negative: 15458\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 30916, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.512943\n",
      "[LightGBM] [Info] Number of positive: 14590, number of negative: 14590\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116316\n",
      "[LightGBM] [Info] Number of data points in the train set: 29180, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's binary_logloss: 0.501159\n",
      "[LightGBM] [Info] Number of positive: 14510, number of negative: 14510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 29020, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.485403\n",
      "[LightGBM] [Info] Number of positive: 20159, number of negative: 20159\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116439\n",
      "[LightGBM] [Info] Number of data points in the train set: 40318, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.470969\n",
      "[LightGBM] [Info] Number of positive: 16873, number of negative: 16872\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116513\n",
      "[LightGBM] [Info] Number of data points in the train set: 33745, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.523959\n",
      "[LightGBM] [Info] Number of positive: 16774, number of negative: 16773\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116294\n",
      "[LightGBM] [Info] Number of data points in the train set: 33547, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.51778\n",
      "[LightGBM] [Info] Number of positive: 14836, number of negative: 14836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116241\n",
      "[LightGBM] [Info] Number of data points in the train set: 29672, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.502334\n",
      "[LightGBM] [Info] Number of positive: 13710, number of negative: 13709\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116464\n",
      "[LightGBM] [Info] Number of data points in the train set: 27419, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000073\n",
      "[LightGBM] [Info] Start training from score 0.000073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.491233\n",
      "[LightGBM] [Info] Number of positive: 15905, number of negative: 15904\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116449\n",
      "[LightGBM] [Info] Number of data points in the train set: 31809, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's binary_logloss: 0.518361\n",
      "[LightGBM] [Info] Number of positive: 12952, number of negative: 12952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116134\n",
      "[LightGBM] [Info] Number of data points in the train set: 25904, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.542163\n",
      "[LightGBM] [Info] Number of positive: 13614, number of negative: 13614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 27228, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.514136\n",
      "[LightGBM] [Info] Number of positive: 16797, number of negative: 16796\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116365\n",
      "[LightGBM] [Info] Number of data points in the train set: 33593, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's binary_logloss: 0.495817\n",
      "[LightGBM] [Info] Number of positive: 18023, number of negative: 18023\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116439\n",
      "[LightGBM] [Info] Number of data points in the train set: 36046, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.495868\n",
      "[LightGBM] [Info] Number of positive: 14909, number of negative: 14908\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116316\n",
      "[LightGBM] [Info] Number of data points in the train set: 29817, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[283]\tvalid_0's binary_logloss: 0.497939\n",
      "[LightGBM] [Info] Number of positive: 15176, number of negative: 15176\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116304\n",
      "[LightGBM] [Info] Number of data points in the train set: 30352, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.454137\n",
      "[LightGBM] [Info] Number of positive: 12226, number of negative: 12225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116215\n",
      "[LightGBM] [Info] Number of data points in the train set: 24451, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000082\n",
      "[LightGBM] [Info] Start training from score 0.000082\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.528579\n",
      "[LightGBM] [Info] Number of positive: 13760, number of negative: 13760\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116342\n",
      "[LightGBM] [Info] Number of data points in the train set: 27520, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's binary_logloss: 0.496047\n",
      "[LightGBM] [Info] Number of positive: 14570, number of negative: 14569\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116258\n",
      "[LightGBM] [Info] Number of data points in the train set: 29139, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000069\n",
      "[LightGBM] [Info] Start training from score 0.000069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.536718\n",
      "[LightGBM] [Info] Number of positive: 15150, number of negative: 15149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116287\n",
      "[LightGBM] [Info] Number of data points in the train set: 30299, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.484085\n",
      "[LightGBM] [Info] Number of positive: 16117, number of negative: 16116\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116344\n",
      "[LightGBM] [Info] Number of data points in the train set: 32233, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.466076\n",
      "[LightGBM] [Info] Number of positive: 16766, number of negative: 16765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116400\n",
      "[LightGBM] [Info] Number of data points in the train set: 33531, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.523606\n",
      "[LightGBM] [Info] Number of positive: 15379, number of negative: 15379\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 30758, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.495555\n",
      "[LightGBM] [Info] Number of positive: 16098, number of negative: 16097\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 32195, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's binary_logloss: 0.487127\n",
      "[LightGBM] [Info] Number of positive: 15618, number of negative: 15617\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116291\n",
      "[LightGBM] [Info] Number of data points in the train set: 31235, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's binary_logloss: 0.474447\n",
      "[LightGBM] [Info] Number of positive: 17825, number of negative: 17824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116430\n",
      "[LightGBM] [Info] Number of data points in the train set: 35649, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's binary_logloss: 0.535073\n",
      "[LightGBM] [Info] Number of positive: 16869, number of negative: 16868\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116435\n",
      "[LightGBM] [Info] Number of data points in the train set: 33737, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.498527\n",
      "[LightGBM] [Info] Number of positive: 17876, number of negative: 17876\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 35752, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's binary_logloss: 0.509973\n",
      "[LightGBM] [Info] Number of positive: 18742, number of negative: 18742\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116395\n",
      "[LightGBM] [Info] Number of data points in the train set: 37484, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.484861\n",
      "[LightGBM] [Info] Number of positive: 16190, number of negative: 16190\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116405\n",
      "[LightGBM] [Info] Number of data points in the train set: 32380, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.469793\n",
      "[LightGBM] [Info] Number of positive: 14838, number of negative: 14837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116412\n",
      "[LightGBM] [Info] Number of data points in the train set: 29675, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.556196\n",
      "[LightGBM] [Info] Number of positive: 15636, number of negative: 15636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116452\n",
      "[LightGBM] [Info] Number of data points in the train set: 31272, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.517367\n",
      "[LightGBM] [Info] Number of positive: 15479, number of negative: 15479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116393\n",
      "[LightGBM] [Info] Number of data points in the train set: 30958, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's binary_logloss: 0.465403\n",
      "[LightGBM] [Info] Number of positive: 14522, number of negative: 14522\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 29044, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's binary_logloss: 0.474472\n",
      "[LightGBM] [Info] Number of positive: 16130, number of negative: 16129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116366\n",
      "[LightGBM] [Info] Number of data points in the train set: 32259, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's binary_logloss: 0.558672\n",
      "[LightGBM] [Info] Number of positive: 18353, number of negative: 18352\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116401\n",
      "[LightGBM] [Info] Number of data points in the train set: 36705, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.410346\n",
      "[LightGBM] [Info] Number of positive: 15834, number of negative: 15833\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 31667, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.554167\n",
      "[LightGBM] [Info] Number of positive: 17646, number of negative: 17645\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 35291, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[307]\tvalid_0's binary_logloss: 0.506302\n",
      "[LightGBM] [Info] Number of positive: 16061, number of negative: 16060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116290\n",
      "[LightGBM] [Info] Number of data points in the train set: 32121, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's binary_logloss: 0.503727\n",
      "[LightGBM] [Info] Number of positive: 17605, number of negative: 17604\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116347\n",
      "[LightGBM] [Info] Number of data points in the train set: 35209, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's binary_logloss: 0.54058\n",
      "[LightGBM] [Info] Number of positive: 15890, number of negative: 15890\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116294\n",
      "[LightGBM] [Info] Number of data points in the train set: 31780, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.475337\n",
      "[LightGBM] [Info] Number of positive: 18558, number of negative: 18557\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116325\n",
      "[LightGBM] [Info] Number of data points in the train set: 37115, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\tvalid_0's binary_logloss: 0.530495\n",
      "[LightGBM] [Info] Number of positive: 15593, number of negative: 15592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 31185, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.507289\n",
      "[LightGBM] [Info] Number of positive: 15645, number of negative: 15644\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116376\n",
      "[LightGBM] [Info] Number of data points in the train set: 31289, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's binary_logloss: 0.509952\n",
      "[LightGBM] [Info] Number of positive: 14302, number of negative: 14301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116442\n",
      "[LightGBM] [Info] Number of data points in the train set: 28603, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.473394\n",
      "[LightGBM] [Info] Number of positive: 15826, number of negative: 15825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116314\n",
      "[LightGBM] [Info] Number of data points in the train set: 31651, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.500696\n",
      "[LightGBM] [Info] Number of positive: 15647, number of negative: 15647\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116280\n",
      "[LightGBM] [Info] Number of data points in the train set: 31294, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.517744\n",
      "[LightGBM] [Info] Number of positive: 19507, number of negative: 19507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116430\n",
      "[LightGBM] [Info] Number of data points in the train set: 39014, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's binary_logloss: 0.530273\n",
      "[LightGBM] [Info] Number of positive: 15388, number of negative: 15388\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 30776, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.511908\n",
      "[LightGBM] [Info] Number of positive: 14780, number of negative: 14780\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116284\n",
      "[LightGBM] [Info] Number of data points in the train set: 29560, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.515282\n",
      "[LightGBM] [Info] Number of positive: 13588, number of negative: 13588\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116321\n",
      "[LightGBM] [Info] Number of data points in the train set: 27176, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's binary_logloss: 0.51347\n",
      "[LightGBM] [Info] Number of positive: 18546, number of negative: 18545\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116499\n",
      "[LightGBM] [Info] Number of data points in the train set: 37091, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's binary_logloss: 0.513885\n",
      "[LightGBM] [Info] Number of positive: 18085, number of negative: 18084\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116443\n",
      "[LightGBM] [Info] Number of data points in the train set: 36169, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000055\n",
      "[LightGBM] [Info] Start training from score 0.000055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.479796\n",
      "[LightGBM] [Info] Number of positive: 11481, number of negative: 11480\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116176\n",
      "[LightGBM] [Info] Number of data points in the train set: 22961, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000087\n",
      "[LightGBM] [Info] Start training from score 0.000087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's binary_logloss: 0.53279\n",
      "[LightGBM] [Info] Number of positive: 18059, number of negative: 18059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116438\n",
      "[LightGBM] [Info] Number of data points in the train set: 36118, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.482716\n",
      "[LightGBM] [Info] Number of positive: 17633, number of negative: 17632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116387\n",
      "[LightGBM] [Info] Number of data points in the train set: 35265, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.441918\n",
      "[LightGBM] [Info] Number of positive: 13440, number of negative: 13440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116198\n",
      "[LightGBM] [Info] Number of data points in the train set: 26880, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's binary_logloss: 0.510677\n",
      "[LightGBM] [Info] Number of positive: 16842, number of negative: 16842\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116301\n",
      "[LightGBM] [Info] Number of data points in the train set: 33684, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.508051\n",
      "[LightGBM] [Info] Number of positive: 18442, number of negative: 18441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116376\n",
      "[LightGBM] [Info] Number of data points in the train set: 36883, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.484727\n",
      "[LightGBM] [Info] Number of positive: 15711, number of negative: 15711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116312\n",
      "[LightGBM] [Info] Number of data points in the train set: 31422, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.498797\n",
      "[LightGBM] [Info] Number of positive: 16270, number of negative: 16270\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 32540, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's binary_logloss: 0.521007\n",
      "[LightGBM] [Info] Number of positive: 17453, number of negative: 17452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116381\n",
      "[LightGBM] [Info] Number of data points in the train set: 34905, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's binary_logloss: 0.454029\n",
      "[LightGBM] [Info] Number of positive: 16474, number of negative: 16474\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116367\n",
      "[LightGBM] [Info] Number of data points in the train set: 32948, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.510628\n",
      "[LightGBM] [Info] Number of positive: 15822, number of negative: 15822\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116348\n",
      "[LightGBM] [Info] Number of data points in the train set: 31644, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.552302\n",
      "[LightGBM] [Info] Number of positive: 18877, number of negative: 18876\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 37753, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.485771\n",
      "[LightGBM] [Info] Number of positive: 16282, number of negative: 16281\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116316\n",
      "[LightGBM] [Info] Number of data points in the train set: 32563, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000061\n",
      "[LightGBM] [Info] Start training from score 0.000061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.456728\n",
      "[LightGBM] [Info] Number of positive: 16025, number of negative: 16024\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116412\n",
      "[LightGBM] [Info] Number of data points in the train set: 32049, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.500136\n",
      "[LightGBM] [Info] Number of positive: 14842, number of negative: 14841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 29683, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's binary_logloss: 0.481922\n",
      "[LightGBM] [Info] Number of positive: 14902, number of negative: 14901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 29803, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's binary_logloss: 0.490237\n",
      "[LightGBM] [Info] Number of positive: 17438, number of negative: 17438\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116341\n",
      "[LightGBM] [Info] Number of data points in the train set: 34876, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's binary_logloss: 0.512769\n",
      "[LightGBM] [Info] Number of positive: 12956, number of negative: 12956\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116192\n",
      "[LightGBM] [Info] Number of data points in the train set: 25912, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.566073\n",
      "[LightGBM] [Info] Number of positive: 17717, number of negative: 17716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116251\n",
      "[LightGBM] [Info] Number of data points in the train set: 35433, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's binary_logloss: 0.494012\n",
      "[LightGBM] [Info] Number of positive: 16238, number of negative: 16237\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116339\n",
      "[LightGBM] [Info] Number of data points in the train set: 32475, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000062\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's binary_logloss: 0.533558\n",
      "[LightGBM] [Info] Number of positive: 15401, number of negative: 15400\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116313\n",
      "[LightGBM] [Info] Number of data points in the train set: 30801, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.472613\n",
      "[LightGBM] [Info] Number of positive: 14346, number of negative: 14346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 28692, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's binary_logloss: 0.541843\n",
      "[LightGBM] [Info] Number of positive: 17514, number of negative: 17514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116423\n",
      "[LightGBM] [Info] Number of data points in the train set: 35028, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.51893\n",
      "[LightGBM] [Info] Number of positive: 18912, number of negative: 18912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116412\n",
      "[LightGBM] [Info] Number of data points in the train set: 37824, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's binary_logloss: 0.526383\n",
      "[LightGBM] [Info] Number of positive: 15836, number of negative: 15836\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116377\n",
      "[LightGBM] [Info] Number of data points in the train set: 31672, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.449185\n",
      "[LightGBM] [Info] Number of positive: 15516, number of negative: 15516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116256\n",
      "[LightGBM] [Info] Number of data points in the train set: 31032, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.477859\n",
      "[LightGBM] [Info] Number of positive: 16525, number of negative: 16524\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116412\n",
      "[LightGBM] [Info] Number of data points in the train set: 33049, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000061\n",
      "[LightGBM] [Info] Start training from score 0.000061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.508462\n",
      "[LightGBM] [Info] Number of positive: 15957, number of negative: 15956\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116336\n",
      "[LightGBM] [Info] Number of data points in the train set: 31913, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's binary_logloss: 0.51722\n",
      "[LightGBM] [Info] Number of positive: 17325, number of negative: 17324\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116344\n",
      "[LightGBM] [Info] Number of data points in the train set: 34649, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000058\n",
      "[LightGBM] [Info] Start training from score 0.000058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's binary_logloss: 0.459798\n",
      "[LightGBM] [Info] Number of positive: 13374, number of negative: 13374\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 26748, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's binary_logloss: 0.500478\n",
      "[LightGBM] [Info] Number of positive: 17441, number of negative: 17440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116465\n",
      "[LightGBM] [Info] Number of data points in the train set: 34881, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's binary_logloss: 0.541561\n",
      "[LightGBM] [Info] Number of positive: 19316, number of negative: 19316\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116389\n",
      "[LightGBM] [Info] Number of data points in the train set: 38632, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's binary_logloss: 0.454553\n",
      "[LightGBM] [Info] Number of positive: 18626, number of negative: 18625\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116386\n",
      "[LightGBM] [Info] Number of data points in the train set: 37251, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's binary_logloss: 0.485644\n",
      "[LightGBM] [Info] Number of positive: 16768, number of negative: 16768\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116498\n",
      "[LightGBM] [Info] Number of data points in the train set: 33536, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's binary_logloss: 0.492447\n",
      "[LightGBM] [Info] Number of positive: 15432, number of negative: 15432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 30864, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's binary_logloss: 0.513642\n",
      "[LightGBM] [Info] Number of positive: 17062, number of negative: 17061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116363\n",
      "[LightGBM] [Info] Number of data points in the train set: 34123, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's binary_logloss: 0.466186\n",
      "[LightGBM] [Info] Number of positive: 14951, number of negative: 14951\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116319\n",
      "[LightGBM] [Info] Number of data points in the train set: 29902, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.503313\n",
      "[LightGBM] [Info] Number of positive: 18776, number of negative: 18776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116440\n",
      "[LightGBM] [Info] Number of data points in the train set: 37552, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's binary_logloss: 0.468269\n",
      "[LightGBM] [Info] Number of positive: 19348, number of negative: 19348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116323\n",
      "[LightGBM] [Info] Number of data points in the train set: 38696, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's binary_logloss: 0.459948\n",
      "[LightGBM] [Info] Number of positive: 17462, number of negative: 17462\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116396\n",
      "[LightGBM] [Info] Number of data points in the train set: 34924, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.50186\n",
      "[LightGBM] [Info] Number of positive: 16072, number of negative: 16072\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 32144, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's binary_logloss: 0.459014\n",
      "[LightGBM] [Info] Number of positive: 13454, number of negative: 13454\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116197\n",
      "[LightGBM] [Info] Number of data points in the train set: 26908, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.506361\n",
      "[LightGBM] [Info] Number of positive: 17626, number of negative: 17626\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116503\n",
      "[LightGBM] [Info] Number of data points in the train set: 35252, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.441993\n",
      "[LightGBM] [Info] Number of positive: 15400, number of negative: 15400\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116351\n",
      "[LightGBM] [Info] Number of data points in the train set: 30800, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.518823\n",
      "[LightGBM] [Info] Number of positive: 17375, number of negative: 17375\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116427\n",
      "[LightGBM] [Info] Number of data points in the train set: 34750, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's binary_logloss: 0.537904\n",
      "[LightGBM] [Info] Number of positive: 14479, number of negative: 14479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116223\n",
      "[LightGBM] [Info] Number of data points in the train set: 28958, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.449807\n",
      "[LightGBM] [Info] Number of positive: 17722, number of negative: 17721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 35443, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.549158\n",
      "[LightGBM] [Info] Number of positive: 15924, number of negative: 15924\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 31848, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.503361\n",
      "[LightGBM] [Info] Number of positive: 17022, number of negative: 17021\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116357\n",
      "[LightGBM] [Info] Number of data points in the train set: 34043, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.495254\n",
      "[LightGBM] [Info] Number of positive: 15512, number of negative: 15512\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 31024, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.498779\n",
      "[LightGBM] [Info] Number of positive: 15974, number of negative: 15973\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116323\n",
      "[LightGBM] [Info] Number of data points in the train set: 31947, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.497554\n",
      "[LightGBM] [Info] Number of positive: 16961, number of negative: 16960\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 33921, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's binary_logloss: 0.508119\n",
      "[LightGBM] [Info] Number of positive: 15066, number of negative: 15065\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116294\n",
      "[LightGBM] [Info] Number of data points in the train set: 30131, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.535408\n",
      "[LightGBM] [Info] Number of positive: 16652, number of negative: 16652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116357\n",
      "[LightGBM] [Info] Number of data points in the train set: 33304, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's binary_logloss: 0.437202\n",
      "[LightGBM] [Info] Number of positive: 14568, number of negative: 14568\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116336\n",
      "[LightGBM] [Info] Number of data points in the train set: 29136, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's binary_logloss: 0.485742\n",
      "[LightGBM] [Info] Number of positive: 15489, number of negative: 15488\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116327\n",
      "[LightGBM] [Info] Number of data points in the train set: 30977, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.527022\n",
      "[LightGBM] [Info] Number of positive: 19007, number of negative: 19007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116383\n",
      "[LightGBM] [Info] Number of data points in the train set: 38014, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's binary_logloss: 0.44348\n",
      "[LightGBM] [Info] Number of positive: 15990, number of negative: 15989\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116412\n",
      "[LightGBM] [Info] Number of data points in the train set: 31979, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.535117\n",
      "[LightGBM] [Info] Number of positive: 16862, number of negative: 16862\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116393\n",
      "[LightGBM] [Info] Number of data points in the train set: 33724, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.524143\n",
      "[LightGBM] [Info] Number of positive: 19138, number of negative: 19138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116415\n",
      "[LightGBM] [Info] Number of data points in the train set: 38276, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's binary_logloss: 0.498306\n",
      "[LightGBM] [Info] Number of positive: 16294, number of negative: 16294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116349\n",
      "[LightGBM] [Info] Number of data points in the train set: 32588, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.423496\n",
      "[LightGBM] [Info] Number of positive: 14618, number of negative: 14618\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116303\n",
      "[LightGBM] [Info] Number of data points in the train set: 29236, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's binary_logloss: 0.48946\n",
      "[LightGBM] [Info] Number of positive: 16196, number of negative: 16196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 32392, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.517316\n",
      "[LightGBM] [Info] Number of positive: 13877, number of negative: 13876\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116296\n",
      "[LightGBM] [Info] Number of data points in the train set: 27753, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.497987\n",
      "[LightGBM] [Info] Number of positive: 15264, number of negative: 15264\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116241\n",
      "[LightGBM] [Info] Number of data points in the train set: 30528, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's binary_logloss: 0.505982\n",
      "[LightGBM] [Info] Number of positive: 18376, number of negative: 18376\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116321\n",
      "[LightGBM] [Info] Number of data points in the train set: 36752, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.510183\n",
      "[LightGBM] [Info] Number of positive: 17942, number of negative: 17942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116312\n",
      "[LightGBM] [Info] Number of data points in the train set: 35884, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's binary_logloss: 0.50066\n",
      "[LightGBM] [Info] Number of positive: 13215, number of negative: 13215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116267\n",
      "[LightGBM] [Info] Number of data points in the train set: 26430, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's binary_logloss: 0.502087\n",
      "[LightGBM] [Info] Number of positive: 14382, number of negative: 14381\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 28763, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's binary_logloss: 0.547529\n",
      "[LightGBM] [Info] Number of positive: 17949, number of negative: 17948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116431\n",
      "[LightGBM] [Info] Number of data points in the train set: 35897, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's binary_logloss: 0.505463\n",
      "[LightGBM] [Info] Number of positive: 13520, number of negative: 13520\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116399\n",
      "[LightGBM] [Info] Number of data points in the train set: 27040, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.535044\n",
      "[LightGBM] [Info] Number of positive: 16234, number of negative: 16234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 32468, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.493205\n",
      "[LightGBM] [Info] Number of positive: 19034, number of negative: 19034\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116414\n",
      "[LightGBM] [Info] Number of data points in the train set: 38068, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's binary_logloss: 0.506011\n",
      "[LightGBM] [Info] Number of positive: 16446, number of negative: 16446\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116384\n",
      "[LightGBM] [Info] Number of data points in the train set: 32892, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[295]\tvalid_0's binary_logloss: 0.456978\n",
      "[LightGBM] [Info] Number of positive: 16452, number of negative: 16452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 32904, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.538316\n",
      "[LightGBM] [Info] Number of positive: 13276, number of negative: 13276\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116151\n",
      "[LightGBM] [Info] Number of data points in the train set: 26552, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.521419\n",
      "[LightGBM] [Info] Number of positive: 12862, number of negative: 12861\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116273\n",
      "[LightGBM] [Info] Number of data points in the train set: 25723, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's binary_logloss: 0.454764\n",
      "[LightGBM] [Info] Number of positive: 17969, number of negative: 17968\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116527\n",
      "[LightGBM] [Info] Number of data points in the train set: 35937, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.507112\n",
      "[LightGBM] [Info] Number of positive: 13415, number of negative: 13415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 26830, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.527335\n",
      "[LightGBM] [Info] Number of positive: 15030, number of negative: 15030\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116304\n",
      "[LightGBM] [Info] Number of data points in the train set: 30060, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.540034\n",
      "[LightGBM] [Info] Number of positive: 17450, number of negative: 17450\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116366\n",
      "[LightGBM] [Info] Number of data points in the train set: 34900, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's binary_logloss: 0.516509\n",
      "[LightGBM] [Info] Number of positive: 14609, number of negative: 14608\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116203\n",
      "[LightGBM] [Info] Number of data points in the train set: 29217, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's binary_logloss: 0.455862\n",
      "[LightGBM] [Info] Number of positive: 15275, number of negative: 15275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 30550, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's binary_logloss: 0.548516\n",
      "[LightGBM] [Info] Number of positive: 13853, number of negative: 13852\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116360\n",
      "[LightGBM] [Info] Number of data points in the train set: 27705, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[293]\tvalid_0's binary_logloss: 0.501468\n",
      "[LightGBM] [Info] Number of positive: 14016, number of negative: 14016\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 28032, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.536223\n",
      "[LightGBM] [Info] Number of positive: 14653, number of negative: 14652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116321\n",
      "[LightGBM] [Info] Number of data points in the train set: 29305, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[286]\tvalid_0's binary_logloss: 0.459837\n",
      "[LightGBM] [Info] Number of positive: 18114, number of negative: 18113\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116318\n",
      "[LightGBM] [Info] Number of data points in the train set: 36227, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000055\n",
      "[LightGBM] [Info] Start training from score 0.000055\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.509904\n",
      "[LightGBM] [Info] Number of positive: 14148, number of negative: 14148\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116332\n",
      "[LightGBM] [Info] Number of data points in the train set: 28296, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.505066\n",
      "[LightGBM] [Info] Number of positive: 13326, number of negative: 13325\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116291\n",
      "[LightGBM] [Info] Number of data points in the train set: 26651, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000075\n",
      "[LightGBM] [Info] Start training from score 0.000075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.496842\n",
      "[LightGBM] [Info] Number of positive: 16991, number of negative: 16991\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116405\n",
      "[LightGBM] [Info] Number of data points in the train set: 33982, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.511447\n",
      "[LightGBM] [Info] Number of positive: 17551, number of negative: 17551\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116379\n",
      "[LightGBM] [Info] Number of data points in the train set: 35102, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.572381\n",
      "[LightGBM] [Info] Number of positive: 17184, number of negative: 17184\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 34368, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.520873\n",
      "[LightGBM] [Info] Number of positive: 15678, number of negative: 15678\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116273\n",
      "[LightGBM] [Info] Number of data points in the train set: 31356, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's binary_logloss: 0.521818\n",
      "[LightGBM] [Info] Number of positive: 14580, number of negative: 14580\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116280\n",
      "[LightGBM] [Info] Number of data points in the train set: 29160, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.433077\n",
      "[LightGBM] [Info] Number of positive: 17826, number of negative: 17826\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116274\n",
      "[LightGBM] [Info] Number of data points in the train set: 35652, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's binary_logloss: 0.514656\n",
      "[LightGBM] [Info] Number of positive: 17758, number of negative: 17757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116356\n",
      "[LightGBM] [Info] Number of data points in the train set: 35515, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000056\n",
      "[LightGBM] [Info] Start training from score 0.000056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's binary_logloss: 0.510626\n",
      "[LightGBM] [Info] Number of positive: 13384, number of negative: 13384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116219\n",
      "[LightGBM] [Info] Number of data points in the train set: 26768, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's binary_logloss: 0.497082\n",
      "[LightGBM] [Info] Number of positive: 16656, number of negative: 16656\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 33312, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's binary_logloss: 0.530872\n",
      "[LightGBM] [Info] Number of positive: 16390, number of negative: 16390\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 32780, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.518103\n",
      "[LightGBM] [Info] Number of positive: 14041, number of negative: 14040\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116271\n",
      "[LightGBM] [Info] Number of data points in the train set: 28081, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.539736\n",
      "[LightGBM] [Info] Number of positive: 16026, number of negative: 16026\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 32052, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.518122\n",
      "[LightGBM] [Info] Number of positive: 16501, number of negative: 16500\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116442\n",
      "[LightGBM] [Info] Number of data points in the train set: 33001, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000061\n",
      "[LightGBM] [Info] Start training from score 0.000061\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's binary_logloss: 0.506572\n",
      "[LightGBM] [Info] Number of positive: 19063, number of negative: 19063\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116462\n",
      "[LightGBM] [Info] Number of data points in the train set: 38126, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.502529\n",
      "[LightGBM] [Info] Number of positive: 16175, number of negative: 16175\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116311\n",
      "[LightGBM] [Info] Number of data points in the train set: 32350, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.533419\n",
      "[LightGBM] [Info] Number of positive: 16790, number of negative: 16789\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116458\n",
      "[LightGBM] [Info] Number of data points in the train set: 33579, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.507346\n",
      "[LightGBM] [Info] Number of positive: 14163, number of negative: 14163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116270\n",
      "[LightGBM] [Info] Number of data points in the train set: 28326, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.470982\n",
      "[LightGBM] [Info] Number of positive: 15755, number of negative: 15755\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116300\n",
      "[LightGBM] [Info] Number of data points in the train set: 31510, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's binary_logloss: 0.510725\n",
      "[LightGBM] [Info] Number of positive: 17512, number of negative: 17512\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116465\n",
      "[LightGBM] [Info] Number of data points in the train set: 35024, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.517363\n",
      "[LightGBM] [Info] Number of positive: 17831, number of negative: 17831\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 35662, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.552163\n",
      "[LightGBM] [Info] Number of positive: 14107, number of negative: 14107\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116257\n",
      "[LightGBM] [Info] Number of data points in the train set: 28214, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.496192\n",
      "[LightGBM] [Info] Number of positive: 15076, number of negative: 15076\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116299\n",
      "[LightGBM] [Info] Number of data points in the train set: 30152, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's binary_logloss: 0.46687\n",
      "[LightGBM] [Info] Number of positive: 13153, number of negative: 13152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116259\n",
      "[LightGBM] [Info] Number of data points in the train set: 26305, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.555212\n",
      "[LightGBM] [Info] Number of positive: 14071, number of negative: 14071\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116295\n",
      "[LightGBM] [Info] Number of data points in the train set: 28142, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's binary_logloss: 0.535109\n",
      "[LightGBM] [Info] Number of positive: 16002, number of negative: 16002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116236\n",
      "[LightGBM] [Info] Number of data points in the train set: 32004, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's binary_logloss: 0.529024\n",
      "[LightGBM] [Info] Number of positive: 15233, number of negative: 15232\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116281\n",
      "[LightGBM] [Info] Number of data points in the train set: 30465, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's binary_logloss: 0.519227\n",
      "[LightGBM] [Info] Number of positive: 14125, number of negative: 14124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116175\n",
      "[LightGBM] [Info] Number of data points in the train set: 28249, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's binary_logloss: 0.52168\n",
      "[LightGBM] [Info] Number of positive: 17434, number of negative: 17433\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116401\n",
      "[LightGBM] [Info] Number of data points in the train set: 34867, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's binary_logloss: 0.481183\n",
      "[LightGBM] [Info] Number of positive: 15891, number of negative: 15891\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116413\n",
      "[LightGBM] [Info] Number of data points in the train set: 31782, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.492006\n",
      "[LightGBM] [Info] Number of positive: 15136, number of negative: 15136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116333\n",
      "[LightGBM] [Info] Number of data points in the train set: 30272, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.503522\n",
      "[LightGBM] [Info] Number of positive: 14118, number of negative: 14118\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116271\n",
      "[LightGBM] [Info] Number of data points in the train set: 28236, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.490631\n",
      "[LightGBM] [Info] Number of positive: 17625, number of negative: 17624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116412\n",
      "[LightGBM] [Info] Number of data points in the train set: 35249, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000057\n",
      "[LightGBM] [Info] Start training from score 0.000057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.482416\n",
      "[LightGBM] [Info] Number of positive: 16905, number of negative: 16904\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116374\n",
      "[LightGBM] [Info] Number of data points in the train set: 33809, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.476245\n",
      "[LightGBM] [Info] Number of positive: 16818, number of negative: 16817\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 33635, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000059\n",
      "[LightGBM] [Info] Start training from score 0.000059\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.515552\n",
      "[LightGBM] [Info] Number of positive: 14226, number of negative: 14225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116351\n",
      "[LightGBM] [Info] Number of data points in the train set: 28451, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.442705\n",
      "[LightGBM] [Info] Number of positive: 13028, number of negative: 13028\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116407\n",
      "[LightGBM] [Info] Number of data points in the train set: 26056, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.478394\n",
      "[LightGBM] [Info] Number of positive: 15476, number of negative: 15476\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116275\n",
      "[LightGBM] [Info] Number of data points in the train set: 30952, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's binary_logloss: 0.490569\n",
      "[LightGBM] [Info] Number of positive: 14519, number of negative: 14519\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116262\n",
      "[LightGBM] [Info] Number of data points in the train set: 29038, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's binary_logloss: 0.518052\n",
      "[LightGBM] [Info] Number of positive: 14638, number of negative: 14637\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 29275, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.51793\n",
      "[LightGBM] [Info] Number of positive: 19245, number of negative: 19244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116384\n",
      "[LightGBM] [Info] Number of data points in the train set: 38489, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000052\n",
      "[LightGBM] [Info] Start training from score 0.000052\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.500647\n",
      "[LightGBM] [Info] Number of positive: 16754, number of negative: 16753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116289\n",
      "[LightGBM] [Info] Number of data points in the train set: 33507, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's binary_logloss: 0.517833\n",
      "[LightGBM] [Info] Number of positive: 17926, number of negative: 17926\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116373\n",
      "[LightGBM] [Info] Number of data points in the train set: 35852, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.524079\n",
      "[LightGBM] [Info] Number of positive: 15835, number of negative: 15835\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116350\n",
      "[LightGBM] [Info] Number of data points in the train set: 31670, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's binary_logloss: 0.480954\n",
      "[LightGBM] [Info] Number of positive: 15582, number of negative: 15581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116386\n",
      "[LightGBM] [Info] Number of data points in the train set: 31163, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's binary_logloss: 0.418376\n",
      "[LightGBM] [Info] Number of positive: 16743, number of negative: 16743\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116363\n",
      "[LightGBM] [Info] Number of data points in the train set: 33486, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's binary_logloss: 0.526862\n",
      "[LightGBM] [Info] Number of positive: 15592, number of negative: 15592\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 31184, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's binary_logloss: 0.500963\n",
      "[LightGBM] [Info] Number of positive: 18035, number of negative: 18035\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116404\n",
      "[LightGBM] [Info] Number of data points in the train set: 36070, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's binary_logloss: 0.485353\n",
      "[LightGBM] [Info] Number of positive: 17299, number of negative: 17299\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116353\n",
      "[LightGBM] [Info] Number of data points in the train set: 34598, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.463381\n",
      "[LightGBM] [Info] Number of positive: 16171, number of negative: 16171\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116302\n",
      "[LightGBM] [Info] Number of data points in the train set: 32342, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's binary_logloss: 0.546433\n",
      "[LightGBM] [Info] Number of positive: 17840, number of negative: 17840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116351\n",
      "[LightGBM] [Info] Number of data points in the train set: 35680, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.511333\n",
      "[LightGBM] [Info] Number of positive: 15385, number of negative: 15384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116282\n",
      "[LightGBM] [Info] Number of data points in the train set: 30769, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\tvalid_0's binary_logloss: 0.504358\n",
      "[LightGBM] [Info] Number of positive: 18457, number of negative: 18456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116307\n",
      "[LightGBM] [Info] Number of data points in the train set: 36913, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000054\n",
      "[LightGBM] [Info] Start training from score 0.000054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.56523\n",
      "[LightGBM] [Info] Number of positive: 17416, number of negative: 17416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116371\n",
      "[LightGBM] [Info] Number of data points in the train set: 34832, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.467424\n",
      "[LightGBM] [Info] Number of positive: 16716, number of negative: 16716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116345\n",
      "[LightGBM] [Info] Number of data points in the train set: 33432, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.509904\n",
      "[LightGBM] [Info] Number of positive: 15214, number of negative: 15213\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116271\n",
      "[LightGBM] [Info] Number of data points in the train set: 30427, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000066\n",
      "[LightGBM] [Info] Start training from score 0.000066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.546607\n",
      "[LightGBM] [Info] Number of positive: 15266, number of negative: 15266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116341\n",
      "[LightGBM] [Info] Number of data points in the train set: 30532, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.464029\n",
      "[LightGBM] [Info] Number of positive: 18784, number of negative: 18784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116378\n",
      "[LightGBM] [Info] Number of data points in the train set: 37568, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's binary_logloss: 0.49682\n",
      "[LightGBM] [Info] Number of positive: 14572, number of negative: 14572\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 29144, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's binary_logloss: 0.483449\n",
      "[LightGBM] [Info] Number of positive: 14599, number of negative: 14599\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116294\n",
      "[LightGBM] [Info] Number of data points in the train set: 29198, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's binary_logloss: 0.452971\n",
      "[LightGBM] [Info] Number of positive: 13966, number of negative: 13965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116434\n",
      "[LightGBM] [Info] Number of data points in the train set: 27931, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's binary_logloss: 0.520461\n",
      "[LightGBM] [Info] Number of positive: 15842, number of negative: 15841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116326\n",
      "[LightGBM] [Info] Number of data points in the train set: 31683, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000063\n",
      "[LightGBM] [Info] Start training from score 0.000063\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.547802\n",
      "[LightGBM] [Info] Number of positive: 14942, number of negative: 14941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 29883, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000067\n",
      "[LightGBM] [Info] Start training from score 0.000067\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.494621\n",
      "[LightGBM] [Info] Number of positive: 17366, number of negative: 17366\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116415\n",
      "[LightGBM] [Info] Number of data points in the train set: 34732, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's binary_logloss: 0.539461\n",
      "[LightGBM] [Info] Number of positive: 16641, number of negative: 16640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 33281, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.489227\n",
      "[LightGBM] [Info] Number of positive: 17178, number of negative: 17177\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116382\n",
      "[LightGBM] [Info] Number of data points in the train set: 34355, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000058\n",
      "[LightGBM] [Info] Start training from score 0.000058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.435827\n",
      "[LightGBM] [Info] Number of positive: 14439, number of negative: 14439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116238\n",
      "[LightGBM] [Info] Number of data points in the train set: 28878, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.516594\n",
      "[LightGBM] [Info] Number of positive: 16640, number of negative: 16640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116388\n",
      "[LightGBM] [Info] Number of data points in the train set: 33280, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's binary_logloss: 0.506124\n",
      "[LightGBM] [Info] Number of positive: 12398, number of negative: 12397\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116278\n",
      "[LightGBM] [Info] Number of data points in the train set: 24795, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000081\n",
      "[LightGBM] [Info] Start training from score 0.000081\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.477023\n",
      "[LightGBM] [Info] Number of positive: 14763, number of negative: 14763\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116250\n",
      "[LightGBM] [Info] Number of data points in the train set: 29526, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.485058\n",
      "[LightGBM] [Info] Number of positive: 13720, number of negative: 13720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116238\n",
      "[LightGBM] [Info] Number of data points in the train set: 27440, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's binary_logloss: 0.485033\n",
      "[LightGBM] [Info] Number of positive: 15288, number of negative: 15288\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116319\n",
      "[LightGBM] [Info] Number of data points in the train set: 30576, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.486325\n",
      "[LightGBM] [Info] Number of positive: 14619, number of negative: 14619\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 29238, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's binary_logloss: 0.493928\n",
      "[LightGBM] [Info] Number of positive: 15968, number of negative: 15968\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116274\n",
      "[LightGBM] [Info] Number of data points in the train set: 31936, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.491685\n",
      "[LightGBM] [Info] Number of positive: 15661, number of negative: 15660\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116282\n",
      "[LightGBM] [Info] Number of data points in the train set: 31321, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000064\n",
      "[LightGBM] [Info] Start training from score 0.000064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.45672\n",
      "[LightGBM] [Info] Number of positive: 15407, number of negative: 15407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116319\n",
      "[LightGBM] [Info] Number of data points in the train set: 30814, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's binary_logloss: 0.48557\n",
      "[LightGBM] [Info] Number of positive: 16330, number of negative: 16330\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116423\n",
      "[LightGBM] [Info] Number of data points in the train set: 32660, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's binary_logloss: 0.497727\n",
      "[LightGBM] [Info] Number of positive: 17496, number of negative: 17496\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116337\n",
      "[LightGBM] [Info] Number of data points in the train set: 34992, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's binary_logloss: 0.525068\n",
      "[LightGBM] [Info] Number of positive: 15726, number of negative: 15726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 31452, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's binary_logloss: 0.519845\n",
      "[LightGBM] [Info] Number of positive: 14207, number of negative: 14207\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 28414, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.472711\n",
      "[LightGBM] [Info] Number of positive: 16804, number of negative: 16804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116373\n",
      "[LightGBM] [Info] Number of data points in the train set: 33608, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's binary_logloss: 0.483093\n",
      "[LightGBM] [Info] Number of positive: 17516, number of negative: 17516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 35032, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.506428\n",
      "[LightGBM] [Info] Number of positive: 17848, number of negative: 17848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116395\n",
      "[LightGBM] [Info] Number of data points in the train set: 35696, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's binary_logloss: 0.474018\n",
      "[LightGBM] [Info] Number of positive: 14812, number of negative: 14812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116270\n",
      "[LightGBM] [Info] Number of data points in the train set: 29624, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.51421\n",
      "[LightGBM] [Info] Number of positive: 20282, number of negative: 20282\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116393\n",
      "[LightGBM] [Info] Number of data points in the train set: 40564, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[376]\tvalid_0's binary_logloss: 0.47551\n",
      "[LightGBM] [Info] Number of positive: 17134, number of negative: 17133\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116270\n",
      "[LightGBM] [Info] Number of data points in the train set: 34267, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000058\n",
      "[LightGBM] [Info] Start training from score 0.000058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.525036\n",
      "[LightGBM] [Info] Number of positive: 17269, number of negative: 17268\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116335\n",
      "[LightGBM] [Info] Number of data points in the train set: 34537, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500014 -> initscore=0.000058\n",
      "[LightGBM] [Info] Start training from score 0.000058\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.476138\n",
      "[LightGBM] [Info] Number of positive: 16617, number of negative: 16616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116396\n",
      "[LightGBM] [Info] Number of data points in the train set: 33233, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500015 -> initscore=0.000060\n",
      "[LightGBM] [Info] Start training from score 0.000060\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.464749\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 16472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116416\n",
      "[LightGBM] [Info] Number of data points in the train set: 32944, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's binary_logloss: 0.498382\n",
      "[LightGBM] [Info] Number of positive: 16354, number of negative: 16354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116545\n",
      "[LightGBM] [Info] Number of data points in the train set: 32708, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[332]\tvalid_0's binary_logloss: 0.470995\n",
      "[LightGBM] [Info] Number of positive: 15802, number of negative: 15802\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116388\n",
      "[LightGBM] [Info] Number of data points in the train set: 31604, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.547819\n",
      "[LightGBM] [Info] Number of positive: 13525, number of negative: 13524\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116335\n",
      "[LightGBM] [Info] Number of data points in the train set: 27049, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.47291\n",
      "[LightGBM] [Info] Number of positive: 15441, number of negative: 15440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116348\n",
      "[LightGBM] [Info] Number of data points in the train set: 30881, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500016 -> initscore=0.000065\n",
      "[LightGBM] [Info] Start training from score 0.000065\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.540124\n",
      "[LightGBM] [Info] Number of positive: 17979, number of negative: 17979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116391\n",
      "[LightGBM] [Info] Number of data points in the train set: 35958, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's binary_logloss: 0.48584\n",
      "[LightGBM] [Info] Number of positive: 11881, number of negative: 11880\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116215\n",
      "[LightGBM] [Info] Number of data points in the train set: 23761, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000084\n",
      "[LightGBM] [Info] Start training from score 0.000084\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.509476\n",
      "[LightGBM] [Info] Number of positive: 13866, number of negative: 13865\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 27731, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's binary_logloss: 0.515069\n",
      "[LightGBM] [Info] Number of positive: 14254, number of negative: 14254\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116254\n",
      "[LightGBM] [Info] Number of data points in the train set: 28508, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.540935\n",
      "[LightGBM] [Info] Number of positive: 14801, number of negative: 14800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116312\n",
      "[LightGBM] [Info] Number of data points in the train set: 29601, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500017 -> initscore=0.000068\n",
      "[LightGBM] [Info] Start training from score 0.000068\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.438089\n",
      "[LightGBM] [Info] Number of positive: 18770, number of negative: 18769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116462\n",
      "[LightGBM] [Info] Number of data points in the train set: 37539, number of used features: 477\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500013 -> initscore=0.000053\n",
      "[LightGBM] [Info] Start training from score 0.000053\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.450937\n"
     ]
    }
   ],
   "source": [
    "experiment_base_name = 'Tsfresh_InflCovidNC'\n",
    "experiment_name = 'InflNC'\n",
    "experiment_dir = resultdir / experiment_base_name / experiment_name\n",
    "os.makedirs(experiment_dir, exist_ok=True) \n",
    "\n",
    "pid_random_states = range(0, 500)  # 500 random states for PID sampling\n",
    "us_random_state = 0  # Random state for under-sampling\n",
    "tv_random_state = 0  # Random state for train/validation split\n",
    "evalfunc = partial(f1_score, average='macro')  # Evaluation function\n",
    "n_pid_split_dict = {'infl': [29, 30], 'nc': [30, 30]}  # Number of train/test samples per class\n",
    "labels = list(n_pid_split_dict.keys())  # Class labels\n",
    "num_class = len(n_pid_split_dict)  # Number of classes\n",
    "le = LabelEncoder()  # Label encoder\n",
    "le.fit(labels)\n",
    "label_column = 'label'\n",
    "\n",
    "for i, (df_X, df_y, splitted_pids, splitted_pidlabels) \\\n",
    "    in enumerate(kentai.generate_dfxypidspidlabels(\n",
    "            n_pid_split_dict, random_states=pid_random_states, label_column=label_column)):\n",
    "\n",
    "    outputdirname = 'ex-division' + str(i).zfill(2)  # Name of the directory where results will be saved\n",
    "    outputdir = experiment_dir / outputdirname  # Directory where results will be saved\n",
    "    os.makedirs(outputdir, exist_ok=True)  # Create it if it does not exist\n",
    "\n",
    "    # Save PIDs used in the experiment\n",
    "    splitted_pidsfilepath = outputdir / 'splitted_pids.csv'\n",
    "    with open(splitted_pidsfilepath, mode='w') as f:\n",
    "        for pids in splitted_pids:\n",
    "            # Without reshape, they would be written line by line instead of comma-separated\n",
    "            np.savetxt(f, np.array(pids).reshape(1, -1), delimiter=',', fmt='%d')\n",
    "\n",
    "    # Save PID labels used in the experiment\n",
    "    splitted_pidlabelsfilepath = outputdir / 'splitted_pidlabels.csv'  # File to store PIDs used in the experiment\n",
    "    with open(splitted_pidlabelsfilepath, mode='w') as f:\n",
    "        for pidlabels in splitted_pidlabels:\n",
    "            # Without reshape, they would be written line by line instead of comma-separated\n",
    "            np.savetxt(f, np.array(pidlabels).reshape(1, -1), delimiter=',', fmt='%s')\n",
    "\n",
    "    df_X_train, df_X_test = df_X  # Feature vectors for each instance\n",
    "    df_y_train, df_y_test = df_y  # Labels for each instance\n",
    "    pids_train, pids_test = splitted_pids  # PIDs used for train/test\n",
    "    pidlabels_train, pidlabels_test = splitted_pidlabels  # Labels of PIDs used for train/test\n",
    "\n",
    "    # RandomUnderSampling without NR\n",
    "    rus = RandomUnderSampler(random_state=us_random_state)\n",
    "    df_X_train_resampled, y_train_resampled = rus.fit_resample(df_X_train, df_y_train[label_column])\n",
    "    df_y_train_resampled = df_y_train.loc[df_X_train_resampled.index]\n",
    "\n",
    "    # Split validation data for early_stopping_rounds\n",
    "    df_X_train_resampled_train, df_X_train_resampled_valid, \\\n",
    "    df_y_train_resampled_train, df_y_train_resampled_valid = \\\n",
    "        train_test_split(df_X_train_resampled, df_y_train_resampled, test_size=0.2,\n",
    "                         random_state=tv_random_state,\n",
    "                         stratify=df_y_train_resampled[label_column])\n",
    "\n",
    "    # Set parameters\n",
    "    if len(n_pid_split_dict) == 2:\n",
    "        objective = 'binary'\n",
    "        metric = 'binary_logloss'\n",
    "        num_class = 1  # Number of classes (for binary, it is 1 for some reason)\n",
    "        eval_metric = 'binary_logloss'\n",
    "    else:\n",
    "        objective = 'multiclass'\n",
    "        metric = 'multi_logloss'\n",
    "        num_class = len(n_pid_split_dict)  # Number of classes\n",
    "        eval_metric = 'multi_logloss'\n",
    "\n",
    "    lgb_params = {\n",
    "        'n_estimators': 10000,\n",
    "        'objective': objective,\n",
    "        'metric': metric,\n",
    "        'num_class': num_class,  # Number of classes\n",
    "        'seed': 0\n",
    "    }\n",
    "\n",
    "    fit_params = {\n",
    "        'eval_metric': eval_metric,  # Metric used for early_stopping_rounds\n",
    "        'eval_set': [(df_X_train_resampled_valid.to_numpy(),\n",
    "                      df_y_train_resampled_valid[label_column])],\n",
    "        'callbacks': [lgb.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "    }\n",
    "\n",
    "    # Train classifier\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(df_X_train_resampled_train.values,\n",
    "            df_y_train_resampled_train[label_column],\n",
    "            **fit_params)\n",
    "\n",
    "    # Instance-level results\n",
    "    y_pred_probs = clf.predict_proba(df_X_test)  # Predicted probabilities for each label\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)  # Predicted label indices\n",
    "    y_pred = le.inverse_transform(y_pred)     # Decode labels\n",
    "\n",
    "    # Save instance-level results\n",
    "    case_pred_probs_path = outputdir / 'case_nonr_pred_probs.csv'  # File to save predicted probabilities per instance\n",
    "    df_case_nonr_pred_probs = pd.DataFrame(y_pred_probs, columns=labels)\n",
    "    df_case_nonr_pred_probs.to_csv(case_pred_probs_path, index=None)\n",
    "\n",
    "    case_nonr_true_pred_path = outputdir / 'case_nonr_true_pred.csv'  # File to save true and predicted labels per instance\n",
    "    df_case_nonr_true_pred = pd.DataFrame(\n",
    "        np.array([df_y_test[label_column], y_pred]).T,\n",
    "        columns=(['true', 'pred'])\n",
    "    )\n",
    "    df_case_nonr_true_pred.to_csv(case_nonr_true_pred_path, index=None)\n",
    "    lgbmtools.save_clrep_confmat(df_y_test[label_column], y_pred, labels,\n",
    "                                 filenamehead='case_nonr', outputdir=outputdir)\n",
    "\n",
    "    # PID-level results\n",
    "\n",
    "    # Compute predicted probabilities aggregated by PID\n",
    "    # pidlabels_pred_probs = pred_ratio_bypid(pids_test, df_y_test['pid'], y_pred, labels)  # Prediction ratio per PID\n",
    "    pidlabels_pred_probs = lgbmtools.pred_probsum_bypid(\n",
    "        pids_test,\n",
    "        df_y_test['pid'].to_numpy(),\n",
    "        y_pred_probs,\n",
    "        labels\n",
    "    )  # Sum of prediction probabilities per PID\n",
    "\n",
    "    df_pidlabels_pred_probs = pd.DataFrame(pidlabels_pred_probs, columns=labels)\n",
    "    # Save\n",
    "    pid_pred_probs_path = outputdir / 'pid_nonr_pred_probs.csv'  # File to save prediction probabilities per PID\n",
    "    df_pidlabels_pred_probs.to_csv(pid_pred_probs_path, index=None)\n",
    "\n",
    "    # Predicted labels per PID\n",
    "    pidlabels_pred = np.argmax(pidlabels_pred_probs, axis=1)  # Predicted label indices\n",
    "    pidlabels_pred = le.inverse_transform(pidlabels_pred)     # Decode labels\n",
    "    df_pids_pidlabels_pidpred = pd.DataFrame(\n",
    "        np.array([pids_test, pidlabels_test, pidlabels_pred]).T,\n",
    "        columns=(['pid', 'true', 'pred'])\n",
    "    )\n",
    "    # Save\n",
    "    pids_pidlabels_pidpred_path = outputdir / 'pid_nonr_true_pred.csv'  # File to save true and predicted labels per PID\n",
    "    df_pids_pidlabels_pidpred.to_csv(pids_pidlabels_pidpred_path, index=None)\n",
    "\n",
    "    # Evaluation metrics (PID-level)\n",
    "    lgbmtools.save_clrep_confmat(\n",
    "        pidlabels_test,\n",
    "        pidlabels_pred,\n",
    "        labels,\n",
    "        filenamehead='pid_nonr',\n",
    "        outputdir=outputdir\n",
    "    )\n",
    "\n",
    "    # Predictions on validation data\n",
    "    y_pred_prob1 = clf.predict_proba(df_X_train_resampled_valid)\n",
    "    y_pred1 = np.argmax(y_pred_prob1, axis=1)\n",
    "    y_pred1 = le.inverse_transform(y_pred1)\n",
    "\n",
    "    # Save classification report and confusion matrix for validation data\n",
    "    lgbmtools.save_clrep_confmat(\n",
    "        df_y_train_resampled_valid[label_column],\n",
    "        y_pred1,\n",
    "        labels,\n",
    "        filenamehead='case_nonr_valid',\n",
    "        outputdir=outputdir\n",
    "    )\n",
    "\n",
    "    # Save validation instances\n",
    "    y_pred_prob1_path = outputdir / 'case_nonr_valid_pred_probs.csv'\n",
    "    df_case_nonr_pred_prob1 = pd.DataFrame(y_pred_prob1, columns=labels)\n",
    "    df_case_nonr_pred_prob1.to_csv(y_pred_prob1_path, index=None)\n",
    "\n",
    "    case_nonr_true_pred1_path = outputdir / 'case_nonr_valid_true_pred.csv'\n",
    "    df_case_nonr_true_pred1 = pd.DataFrame(\n",
    "        np.array([df_y_train_resampled_valid[label_column], y_pred1]).T,\n",
    "        columns=(['true', 'pred'])\n",
    "    )\n",
    "    df_case_nonr_true_pred1.to_csv(case_nonr_true_pred1_path, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96b67b5-259f-4d7a-9a58-8c4131d03a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_nonr\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB9QAAAMvCAYAAACDWOvcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAx9tJREFUeJzs3X98zfX///H7mW1nY7aZ2Q/ZTMhW+V0YFUmJ6IeVUkKUd0xh9Une7+RHit79oLRIX6aSfuiH9O4nwvudRtJboRGiU2zToW1+zNnY6/tHl523Y2fYsfNru10vl3O5OK/X67wej+dr5jy8Hq/X62kyDMMQAAAAAAAAAAAAAABwEODtBAAAAAAAAAAAAAAA8EU01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAA8KCNGzeqa9euqlevnkwmkzZv3uztlAAAAACfYDKZNGXKlCp9ZtiwYUpKSnJLPgAg0VAHAAAAAMBjSktLddttt+nQoUOaNWuW3njjDcXGxurRRx/V1Vdfrfr168tkMmnNmjXeThUAAAAAAEgyGYZheDsJAAAAAABqg+3btyslJUWvvvqq7r33XknSmjVrdPXVV6tly5aKjo5Wdna2Vq9erR49eng3WQAAAMDDjh8/rsDAQAUGBp7zZ0pLS1VWViaz2ezGzADUZtyhDgAedPToUW+nAAAAAC86cOCAJCkyMtK+rGPHjjp48KB+/vlnZWRkeCmz83PixAmVlJR4Ow0AAAB4SFlZmY4fP17t+w0JCalSM12SgoKCaKYDcCsa6gD82q+//qrRo0erVatWCg0NVcOGDXXbbbdp7969FbYtKCjQ+PHjlZSUJLPZrCZNmmjIkCGyWq32bY4fP64pU6booosuUkhIiOLj4zVgwADt3r1b0l93Dzl7BOfevXtlMpm0aNEi+7Jhw4YpLCxMu3fvVt++fVW/fn3dddddkqT//Oc/uu2225SYmCiz2ayEhASNHz9excXFFfLevn27Bg4cqEaNGik0NFStWrXSP/7xD0nS6tWrZTKZ9OGHH1b43JIlS2QymZSdnV3VwwoAAAA3GDZsmLp37y5Juu2222QymdSjRw/Vr19fUVFR57Xvt99+Wx07dlT9+vUVHh6u1q1b64UXXnDY5lzq4QMHDmjEiBGKjY1VSEiI2rZtq9dee81hP+W177PPPqvZs2erefPmMpvN+umnnyT9Vb/eeuutioqKUkhIiC677DItX778vMYHAAAA95gyZYpMJpP9HGR4eLgaNmyosWPHOjTMTSaTxowZozfffFOXXHKJzGazPv/8c0nSvn37NHz4cMXGxspsNuuSSy7RwoULK8Q627nX8jinzqF++PBhjRs3zl7DxsTE6Nprr9X3339v38bZHOpHjx7VQw89pISEBJnNZrVq1UrPPvusTn9oc/m4li1bpksvvdSef/nYAECSqnaZDwD4mI0bN+qbb77RHXfcoSZNmmjv3r2aO3euevTooZ9++kl169aVJB05ckRXXnmlcnJyNHz4cHXo0EFWq1XLly/X77//rujoaJ08eVL9+vXTqlWrdMcdd2js2LE6fPiwVqxYoa1bt6p58+ZVzu/EiRPq3bu3rrjiCj377LP2fJYuXapjx45p1KhRatiwob799lvNmTNHv//+u5YuXWr//I8//qgrr7xSQUFBGjlypJKSkrR79259/PHHevLJJ9WjRw8lJCTozTff1C233OIQ+80331Tz5s2Vmpp6HkcYAAAA1eVvf/ubLrjgAj311FN68MEHdfnllys2Nva897tixQoNGjRI11xzjZ5++mlJUk5OjtatW6exY8dKOrd6uLi4WD169NCuXbs0ZswYNWvWTEuXLtWwYcNUUFBg31e5rKwsHT9+XCNHjpTZbFZUVJS2bdumbt266YILLtCjjz6qevXq6d1339XNN9+s999/v0LNCgAAAN8wcOBAJSUlacaMGVq/fr1efPFF/fnnn3r99dft23z11Vd69913NWbMGEVHRyspKUn5+fnq0qWLvTHdqFEjffbZZxoxYoSKioo0btw4SXL53Ov999+v9957T2PGjNHFF1+sgwcP6uuvv1ZOTo46dOjg9DOGYejGG2/U6tWrNWLECLVr105ffPGF/u///k/79u3TrFmzHLb/+uuv9cEHH2j06NGqX7++XnzxRaWlpclisahhw4bVc4AB+DcDAPzYsWPHKizLzs42JBmvv/66fdnjjz9uSDI++OCDCtuXlZUZhmEYCxcuNCQZzz//fKXbrF692pBkrF692mH9nj17DElGVlaWfdnQoUMNScajjz56TnnPmDHDMJlMxq+//mpfdtVVVxn169d3WHZqPoZhGBMnTjTMZrNRUFBgX3bgwAEjMDDQmDx5coU4AAAA8J7yenLp0qVO1y9dutRpvXkmY8eONcLDw40TJ05Uus251MOzZ882JBmLFy+2ryspKTFSU1ONsLAwo6ioyDCM/9W+4eHhxoEDBxz2dc011xitW7c2jh8/7rD/rl27Gi1btjznMQEAAMAzJk+ebEgybrzxRoflo0ePNiQZP/zwg2EYhiHJCAgIMLZt2+aw3YgRI4z4+HjDarU6LL/jjjuMiIgI+3nQczn3Wh7n1HOaERERRnp6+hnHMHToUKNp06b298uWLTMkGdOnT3fY7tZbbzVMJpOxa9cuh3jBwcEOy3744QdDkjFnzpwzxgVQe/DIdwB+LTQ01P7n0tJSHTx4UC1atFBkZKTDY3/ef/99tW3b1ukdMSaTyb5NdHS0HnjggUq3ccWoUaPOmPfRo0dltVrVtWtXGYah//73v5KkP/74Q//+9781fPhwJSYmVprPkCFDZLPZ9N5779mXvfPOOzpx4oQGDx7sct4AAADwD5GRkTp69KhWrFhR6TbnUg9/+umniouL06BBg+zrgoKC9OCDD+rIkSNau3atw+fS0tLUqFEj+/tDhw7pq6++0sCBA3X48GFZrVZZrVYdPHhQvXv31s6dO7Vv377zHS4AAADcID093eF9+TnSTz/91L6se/fuuvjii+3vDcPQ+++/r/79+8swDHv9Z7Va1bt3bxUWFtrP0bp67jUyMlIbNmzQ/v37z3ksn376qerUqaMHH3zQYflDDz0kwzD02WefOSzv1auXwx3ybdq0UXh4uH755ZdzjgmgZqOhDsCvFRcX6/HHH7fPhRMdHa1GjRqpoKBAhYWF9u12796tSy+99Iz72r17t1q1aqXAwOqbDSMwMFBNmjSpsNxisWjYsGGKiopSWFiYGjVqZJ9Pszzv8oLtbHknJyfr8ssv15tvvmlf9uabb6pLly5q0aJFdQ0FAAAAXnbo0CHl5eXZX+V14+jRo3XRRRepT58+atKkiYYPH15hzsdzqYd//fVXtWzZUgEBjqcKUlJS7OtP1axZM4f3u3btkmEYmjRpkho1auTwmjx5sqS/5mgHAACA72nZsqXD++bNmysgIEB79+61Lzu9/vvjjz9UUFCg+fPnV6j/7rnnHkn/q/9cPff6z3/+U1u3blVCQoI6deqkKVOmnLXR/euvv6px48aqX7++w/LK6trTb2aSpAYNGujPP/+sUq4Aai7mUAfg1x544AFlZWVp3LhxSk1NVUREhEwmk+644w6VlZVVe7zKrpY8efKk0+Vms7nCCcmTJ0/q2muv1aFDhzRhwgQlJyerXr162rdvn4YNG+ZS3kOGDNHYsWP1+++/y2azaf369XrppZeqvB8AAAD4rgEDBjjcJT506FAtWrRIMTEx2rx5s7744gt99tln+uyzz5SVlaUhQ4botddec1s+pz51SZK9jn344YfVu3dvp5/hgk8AAAD/4Ow8aGX13+DBgzV06FCn+2nTps155TFw4EBdeeWV+vDDD/Xll1/qmWee0dNPP60PPvhAffr0Oa99l6tTp47T5YZhVMv+Afg/GuoA/Np7772noUOH6rnnnrMvO378uAoKChy2a968ubZu3XrGfTVv3lwbNmxQaWmpgoKCnG7ToEEDSaqw/9OvajyTLVu26Oeff9Zrr72mIUOG2Jef/ojOCy+8UJLOmrck3XHHHcrIyNBbb72l4uJiBQUF6fbbbz/nnAAAAOD7nnvuOYe7ZBo3bmz/c3BwsPr376/+/furrKxMo0eP1iuvvKJJkyapRYsW51QPN23aVD/++KPKysocLgrdvn27ff2ZlNevQUFB6tWrV5XHBwAAAO/ZuXOnwx3ou3btUllZmZKSkir9TKNGjVS/fn2dPHnyrPXfuZx7rUx8fLxGjx6t0aNH68CBA+rQoYOefPLJShvqTZs21cqVK3X48GGHu9TPta4FgNPxyHcAfq1OnToVrhScM2dOhTvG09LS9MMPP+jDDz+ssI/yz6elpclqtTq9s7t8m6ZNm6pOnTr697//7bD+5ZdfrlLOp+6z/M8vvPCCw3aNGjXSVVddpYULF8pisTjNp1x0dLT69OmjxYsX680339T111+v6Ojoc84JAAAAvq9jx47q1auX/VU+f+XBgwcdtgsICLDfCWSz2SSdWz3ct29f5eXl6Z133rGvO3HihObMmaOwsDD7FEWViYmJUY8ePfTKK68oNze3wvo//vijCqMFAACAJ2VmZjq8nzNnjiSd8S7wOnXqKC0tTe+//77TizdPrf/O5dzr6U6ePOkwraf0V83ZuHFje53rTN++fXXy5MkKsWbNmiWTyVRtd7YDqD24Qx2AX+vXr5/eeOMNRURE6OKLL1Z2drZWrlyphg0bOmz3f//3f3rvvfd02223afjw4erYsaMOHTqk5cuXa968eWrbtq2GDBmi119/XRkZGfr222915ZVX6ujRo1q5cqVGjx6tm266SREREbrttts0Z84cmUwmNW/eXP/617+qNBdkcnKymjdvrocfflj79u1TeHi43n//fadz8rz44ou64oor1KFDB40cOVLNmjXT3r179cknn2jz5s0O2w4ZMkS33nqrJOmJJ56o+sEEAACA10yfPl2StG3bNknSG2+8oa+//lqS9Nhjj53xs/fee68OHTqknj17qkmTJvr11181Z84ctWvXzj5P5LnUwyNHjtQrr7yiYcOGadOmTUpKStJ7772ndevWafbs2RXmoHQmMzNTV1xxhVq3bq377rtPF154ofLz85Wdna3ff/9dP/zww/kcJgAAALjJnj17dOONN+r6669Xdna2Fi9erDvvvFNt27Y94+dmzpyp1atXq3Pnzrrvvvt08cUX69ChQ/r++++1cuVKHTp0SJLO6dzr6Q4fPqwmTZro1ltvVdu2bRUWFqaVK1dq48aNDk8sPV3//v119dVX6x//+If27t2rtm3b6ssvv9RHH32kcePGqXnz5ud3sADUOjTUAfi1F154QXXq1NGbb76p48ePq1u3blq5cmWFORvDwsL0n//8R5MnT9aHH36o1157TTExMbrmmmvUpEkTSX9dUfnpp5/qySef1JIlS/T++++rYcOG9hOC5ebMmaPS0lLNmzdPZrNZAwcO1DPPPKNLL730nHIOCgrSxx9/rAcffFAzZsxQSEiIbrnlFo0ZM6ZCgdq2bVutX79ekyZN0ty5c3X8+HE1bdpUAwcOrLDf/v37q0GDBiorK9ONN95Y1UMJAAAAL5o0aZLD+4ULF9r/fLaG+uDBgzV//ny9/PLLKigoUFxcnG6//XZNmTLF/uj2c6mHQ0NDtWbNGj366KN67bXXVFRUpFatWikrK0vDhg07p3FcfPHF+u677zR16lQtWrRIBw8eVExMjNq3b6/HH3+8CkcEAAAAnvTOO+/o8ccf16OPPqrAwECNGTNGzzzzzFk/Fxsbq2+//VbTpk3TBx98oJdfflkNGzbUJZdcoqefftq+3bmeez1V3bp1NXr0aH355Zf64IMPVFZWphYtWujll1/WqFGjKs0pICBAy5cv1+OPP6533nlHWVlZSkpK0jPPPKOHHnqo6gcHQK1nMip7lgYAwK+cOHFCjRs3Vv/+/bVgwQJvpwMAAAAAAADAx02ZMkVTp07VH3/8wRSSAFAJ5lAHgBpi2bJl+uOPPzRkyBBvpwIAAAAAAAAAAFAj8Mh3APBzGzZs0I8//qgnnnhC7du3V/fu3b2dEgAAAAAAAAAAQI3AHeoA4Ofmzp2rUaNGKSYmRq+//rq30wEAAAAAAAAAAKgxmEMdAAAAAAAAAAAAAAAnuEMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOBEoLcTcLeysjLt379f9evXl8lk8nY6AAAA1cYwDB0+fFiNGzdWQADXSfor6lUAAFBTUa/WDNSrAACgJqpKrVrjG+r79+9XQkKCt9MAAABwm99++01NmjTxdhpwEfUqAACo6ahX/Rv1KgAAqMnOpVat8Q31+vXrS/rrYISHh3s5GwAAgOpTVFSkhIQEe70D/0S9CgAAairq1ZqBehUAANREValVa3xDvfwxROHh4RR8AACgRuKxi/6NehUAANR01Kv+jXoVAADUZOdSqzJ5EQAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4EejtBACgprFYLLJarR6NGR0drcTERI/GBAAAQO3jjVpXot4FAADAmXmyTqU2BWofGuoAUI0sFouSk1NUXHzMo3FDQ+tq+/YcCjkAAAC4jbdqXYl6FwAAAJXzdJ1KbQrUPjTUAaAaWa1WFRcfU+fhkxUen+SRmEW5e7Vh4VRZrVaKOAAAALiNN2pdiXoXAAAAZ+bJOpXaFKidaKgDgBuExycpKrGVt9MAAAAAqh21LgAAAHwRdSoAdwnwdgIAAAAAAAAAAAAAAPgiGuoAAAAAAAAAAAAAADjh1YZ6UlKSTCZThVd6erok6fjx40pPT1fDhg0VFhamtLQ05efnezNlAAAAAAAAAAAAAEAt4dWG+saNG5Wbm2t/rVixQpJ02223SZLGjx+vjz/+WEuXLtXatWu1f/9+DRgwwJspAwAAAAAAAAAAAABqiUBvBm/UqJHD+5kzZ6p58+bq3r27CgsLtWDBAi1ZskQ9e/aUJGVlZSklJUXr169Xly5dvJEyAAAAAAAAAAAAAKCW8Jk51EtKSrR48WINHz5cJpNJmzZtUmlpqXr16mXfJjk5WYmJicrOzq50PzabTUVFRQ4vAAAAAAAAAAAAAACqymca6suWLVNBQYGGDRsmScrLy1NwcLAiIyMdtouNjVVeXl6l+5kxY4YiIiLsr4SEBDdmDQAAAAAAAAAAAACoqXymob5gwQL16dNHjRs3Pq/9TJw4UYWFhfbXb7/9Vk0ZAgAAoLZJSkqSyWSq8EpPT5ckHT9+XOnp6WrYsKHCwsKUlpam/Px8L2cNAAAAAAAAoLr4REP9119/1cqVK3Xvvffal8XFxamkpEQFBQUO2+bn5ysuLq7SfZnNZoWHhzu8AAAAAFds3LhRubm59teKFSskSbfddpskafz48fr444+1dOlSrV27Vvv379eAAQO8mTIAAAAAAACAahTo7QQkKSsrSzExMbrhhhvsyzp27KigoCCtWrVKaWlpkqQdO3bIYrEoNTXVW6kCAACgFmnUqJHD+5kzZ6p58+bq3r27CgsLtWDBAi1ZskQ9e/aU9Fddm5KSovXr16tLly5O92mz2WSz2ezvi4qK3DcAAAAAAAAAAOfF63eol5WVKSsrS0OHDlVg4P/6+xERERoxYoQyMjK0evVqbdq0Sffcc49SU1MrPTkJAAAAuEtJSYkWL16s4cOHy2QyadOmTSotLVWvXr3s2yQnJysxMVHZ2dmV7mfGjBmKiIiwvxISEjyRPgAAAAAAAAAXeL2hvnLlSlksFg0fPrzCulmzZqlfv35KS0vTVVddpbi4OH3wwQdeyBIAAAC13bJly1RQUKBhw4ZJkvLy8hQcHKzIyEiH7WJjY5WXl1fpfiZOnKjCwkL767fffnNj1gAAAKipkpKSZDKZKrzS09MlScePH1d6eroaNmyosLAwpaWlKT8/38tZAwAA+B+vP/L9uuuuk2EYTteFhIQoMzNTmZmZHs4KAAAAcLRgwQL16dNHjRs3Pq/9mM1mmc3masoKAAAAtdXGjRt18uRJ+/utW7fq2muv1W233SZJGj9+vD755BMtXbpUERERGjNmjAYMGKB169Z5K2UAAAC/5PWGOgAAAODrfv31V61cudLhaUlxcXEqKSlRQUGBw13q+fn5iouL80KWAAAAqE0aNWrk8H7mzJlq3ry5unfvrsLCQi1YsEBLlixRz549JUlZWVlKSUnR+vXrzzilps1mk81ms78vKipyzwAAAAD8hNcf+Q4AAAD4uqysLMXExOiGG26wL+vYsaOCgoK0atUq+7IdO3bIYrEoNTXVG2kCAACgliopKdHixYs1fPhwmUwmbdq0SaWlperVq5d9m+TkZCUmJio7O/uM+5oxY4YiIiLsr4SEBHenDwAA4NNoqAMAAABnUFZWpqysLA0dOlSBgf97wFNERIRGjBihjIwMrV69Wps2bdI999yj1NTUM97xAwAAAFS3ZcuWqaCgQMOGDZMk5eXlKTg42OFJSpIUGxurvLy8M+5r4sSJKiwstL9+++03N2UNAADgH3jkOwAAAHAGK1eulMVi0fDhwyusmzVrlgICApSWliabzabevXvr5Zdf9kKWAAAAqM0WLFigPn36qHHjxue9L7PZLLPZXA1ZAQAA1Aw01AEAAIAzuO6662QYhtN1ISEhyszMVGZmpoezAgAAAP7y66+/auXKlfrggw/sy+Li4lRSUqKCggKHu9Tz8/MVFxfnhSwBAAD8F498BwAAAAAAAAA/lZWVpZiYGN1www32ZR07dlRQUJBWrVplX7Zjxw5ZLBalpqZ6I00AAAC/xR3qAAAAAAAAAOCHysrKlJWVpaFDhyow8H+neiMiIjRixAhlZGQoKipK4eHheuCBB5SamqouXbp4MWMAAAD/Q0MdAAAAAAAAAPzQypUrZbFYNHz48ArrZs2apYCAAKWlpclms6l37956+eWXvZAlAACAf6OhDgAAAAAAAAB+6LrrrpNhGE7XhYSEKDMzU5mZmR7OCgAAoGZhDnUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADAiUBvJwAA8D8Wi0VWq9WjMaOjo5WYmOjRmAAAAAAAAAAAoHajoQ4AqBKLxaLk5BQVFx/zaNzQ0Lravj2HpjoAAAAAAAAAAPAYGuoAgCqxWq0qLj6mzsMnKzw+ySMxi3L3asPCqbJarTTUAQAAAAAAAACAx9BQBwC4JDw+SVGJrbydBgAAAAAAAAAAgNsEeDsBAAAAAAAAAAAAAAB8EQ11AAAAAAAAAAAAAACcoKEOAAAAAAAAAAAAAIATNNQBAAAAAAAAAAAAAHCChjoAAAAAAAAAAAAAAE7QUAcAAAAAAAAAAAAAwAka6gAAAAAAAAAAAAAAOEFDHQAAAAAAAAAAAAAAJwK9nQAAAAAAAAAAAADgL3JycjwWKzo6WomJiR6LB6AiGuoAAAAAAL9lsVhktVq9EpsTW57lyZOWp+LnDAAAgHLFhQclmTR48GCPxQwNravt23OoSQEvoqEOAAAAAPBLFotFyckpKi4+5pX4nNjyDG+ctDwVP2cAAACUKz12WJKhdndOUKNmyW6PV5S7VxsWTpXVaqUeBbyIhjoAAAAAwC9ZrVYVFx9T5+GTFR6f5NHYnNjyHE+ftDwVP2cAAAA4ExaTqKjEVt5OA4CH0FAHAAAAAPi18PgkTmbVApy0BAAAAAB4Q4C3EwAAAAAAAAAAAAAAwBfRUAcAAAAAAAAAAAAAwAmvN9T37dunwYMHq2HDhgoNDVXr1q313Xff2dcbhqHHH39c8fHxCg0NVa9evbRz504vZgwAAAAAAAAAAAAAqA282lD/888/1a1bNwUFBemzzz7TTz/9pOeee04NGjSwb/PPf/5TL774oubNm6cNGzaoXr166t27t44fP+7FzAEAAAAAAAAAAAAANV2gN4M//fTTSkhIUFZWln1Zs2bN7H82DEOzZ8/WY489pptuukmS9Prrrys2NlbLli3THXfc4fGcAQAAAABA7ZKTk+PxmNHR0UpMTPR4XAAAAACAI6821JcvX67evXvrtttu09q1a3XBBRdo9OjRuu+++yRJe/bsUV5ennr16mX/TEREhDp37qzs7GynDXWbzSabzWZ/X1RU5P6BAAAAAACAGqe48KAkkwYPHuzx2KGhdbV9ew5NdQAAAADwMq821H/55RfNnTtXGRkZ+vvf/66NGzfqwQcfVHBwsIYOHaq8vDxJUmxsrMPnYmNj7etON2PGDE2dOtXtuQMAAKDm27dvnyZMmKDPPvtMx44dU4sWLZSVlaXLLrtM0l9PVJo8ebJeffVVFRQUqFu3bpo7d65atmzp5cwBANWh9NhhSYba3TlBjZoleyxuUe5ebVg4VVarlYY6AAAAAHiZVxvqZWVluuyyy/TUU09Jktq3b6+tW7dq3rx5Gjp0qEv7nDhxojIyMuzvi4qKlJCQUC35AgAAoPb4888/1a1bN1199dX67LPP1KhRI+3cuVMNGjSwb/PPf/5TL774ol577TU1a9ZMkyZNUu/evfXTTz8pJCTEi9kDAKpTWEyiohJbeTsNAAAAAIAXeLWhHh8fr4svvthhWUpKit5//31JUlxcnCQpPz9f8fHx9m3y8/PVrl07p/s0m80ym83uSRgAAAC1xtNPP62EhARlZWXZlzVr1sz+Z8MwNHv2bD322GO66aabJEmvv/66YmNjtWzZMqfTEwEAAAAAAADwL15tqHfr1k07duxwWPbzzz+radOmkv46YRkXF6dVq1bZG+hFRUXasGGDRo0a5el0AZwni8Uiq9Xq0ZjR0dE8IhEA4JLly5erd+/euu2227R27VpdcMEFGj16tO677z5J0p49e5SXl6devXrZPxMREaHOnTsrOzu70oa6zWaTzWazvy8qKnLvQADUON6oqyUpJyfH4zEBAGfGFEUAAADu59WG+vjx49W1a1c99dRTGjhwoL799lvNnz9f8+fPlySZTCaNGzdO06dPV8uWLe2P0WzcuLFuvvlmb6YOoIosFouSk1NUXHzMo3FDQ+tq+/YcmuoAgCr75ZdfNHfuXGVkZOjvf/+7Nm7cqAcffFDBwcEaOnSo8vLyJEmxsbEOn4uNjbWvc2bGjBmaOnWqW3MHUHN5q64+VamtxGuxAQD/wxRFAAAAnuHVhvrll1+uDz/8UBMnTtS0adPUrFkzzZ49W3fddZd9m0ceeURHjx7VyJEjVVBQoCuuuEKff/45BR/gZ6xWq4qLj6nz8MkKj0/ySMyi3L3asHCqrFYrDXUAQJWVlZXpsssu01NPPSVJat++vbZu3ap58+Zp6NChLu934sSJysjIsL8vKipSQkLCeecLoHbwRl1dLndLtrYun68TJ054NC4AwDmmKAIAAPAMrzbUJalfv37q169fpetNJpOmTZumadOmeTArAO4SHp+kqMRW3k4DAICzio+P18UXX+ywLCUlRe+//74kKS4uTpKUn5+v+Ph4+zb5+fn26YqcMZvNMpvN1Z8wgFrFG3V1Ue5ej8YDAJwZUxQB8HWemqqIqYkAuJvXG+oAAACAL+rWrZt27NjhsOznn39W06ZNJf11909cXJxWrVplb6AXFRVpw4YNGjVqlKfTBQAAQC3DFEUAfJk3pipiaiIA7kJDHQBqCE9dickVnwBqi/Hjx6tr16566qmnNHDgQH377beaP3++5s+fL+mvJymNGzdO06dPV8uWLe1zUjZu3Fg333yzd5MHAABAjccURQB8mSenKmJqIgDuRkMdAPxcceFBSSYNHjzYo3G54hNATXf55Zfrww8/1MSJEzVt2jQ1a9ZMs2fP1l133WXf5pFHHtHRo0c1cuRIFRQU6IorrtDnn3+ukJAQL2YOAACA2oApigD4A09MVcTURADcjYY6APi50mOHJRlqd+cENWqW7PZ4XPEJoDbp16+f+vXrV+l6k8mkadOmadq0aR7MCgAAAGCKIgAAAE+hoQ4ANURYTKLbr/aUuOITAAAAAABfwBRFAAAAnkFDHQAAAAAAAAD8DFMUAQAAeAYNdQAAAAAAAADwQ0xRBAAA4H4B3k4AAAAAAAAAAAAAAABfREMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnvNpQnzJlikwmk8MrOTnZvv748eNKT09Xw4YNFRYWprS0NOXn53sxYwAAAAAAAAAAAABAbeH1O9QvueQS5ebm2l9ff/21fd348eP18ccfa+nSpVq7dq3279+vAQMGeDFbAAAAAAAAAAAAAEBtEej1BAIDFRcXV2F5YWGhFixYoCVLlqhnz56SpKysLKWkpGj9+vXq0qWLp1MFAAAAAAAAAAAAANQiXm+o79y5U40bN1ZISIhSU1M1Y8YMJSYmatOmTSotLVWvXr3s2yYnJysxMVHZ2dmVNtRtNptsNpv9fVFRkdvHAMC35eTk1MhYAAD3mzJliqZOneqwrFWrVtq+fbukv6Yoeuihh/T222/LZrOpd+/eevnllxUbG+uNdAEAAAAAAABUM6821Dt37qxFixapVatWys3N1dSpU3XllVdq69atysvLU3BwsCIjIx0+Exsbq7y8vEr3OWPGjAonPQHUTsWFByWZNHjwYI/HLrWVeDwmAMA9LrnkEq1cudL+PjDwfyX0+PHj9cknn2jp0qWKiIjQmDFjNGDAAK1bt84bqQIAAAAAAACoZl5tqPfp08f+5zZt2qhz585q2rSp3n33XYWGhrq0z4kTJyojI8P+vqioSAkJCeedKwD/U3rssCRD7e6coEbNkj0SM3dLtrYun68TJ054JB4AwP2YoggAAAAAAACovbz+yPdTRUZG6qKLLtKuXbt07bXXqqSkRAUFBQ53qefn5zs9oVnObDbLbDZ7IFsA/iIsJlFRia08Eqsod69H4gAAPIcpigCciaen/GGKIQBAOaYnAgAA8AyfaqgfOXJEu3fv1t13362OHTsqKChIq1atUlpamiRpx44dslgsSk1N9XKmAAAAqA2YoghAZbw5vZDEFEMAgL8wPREAAID7ebWh/vDDD6t///5q2rSp9u/fr8mTJ6tOnToaNGiQIiIiNGLECGVkZCgqKkrh4eF64IEHlJqayuMzAQAA4BFMUQSgMt6YXkhiiiEAgCOmJwIAAHA/rzbUf//9dw0aNEgHDx5Uo0aNdMUVV2j9+vVq1KiRJGnWrFkKCAhQWlqaw2OJAAAAAG9giiIAp/Pk9EISUwwBABxV9/REElMUAQAAnC7Am8Hffvtt7d+/XzabTb///rvefvttNW/e3L4+JCREmZmZOnTokI4ePaoPPvjgjCcnAQAAAHcqn6IoPj7eYYqickxRBAAAAE8pn57o888/19y5c7Vnzx5deeWVOnz4sMvTE0l/TVEUERFhf/E0JQAAUNv51BzqAAAAgC9hiiIAAAD4KndMTyQxRREAAMDpaKgDAAAAlWCKIgAAAPiL6pieSGKKIgAAgNPRUAcAAAAq8fbbb59xffkURZmZmR7KCAAAAHCufHqiu+++22F6orS0NElMTwQAAOAqGuoAAAAAAAAA4GeYnggAAMAzaKgDAAAAAAAAgJ9heiIAAADPoKEOAAAAAAAAAH6G6YkAAAA8g4Y6AAAAAAAAAAAA4KNycnI8Eic6OlqJiYkeiQX4ExrqAAAAAAAAAAAAgI8pLjwoyaTBgwd7JF5oaF1t355DUx04DQ11AAAAAAAAAAAAwMeUHjssyVC7OyeoUbNkt8Yqyt2rDQunymq10lAHTkNDHailLBaLrFarx+J56pE0AAAAAAAAAADUJGExiYpKbOXtNIBai4Y6UAtZLBYlJ6eouPiYx2OX2ko8HhMAAAAAAAAAAABwBQ11oBayWq0qLj6mzsMnKzw+ySMxc7dka+vy+Tpx4oRH4gEAAAAAAAAAAADni4Y6UIuFxyd57DExRbl7PRIHAAAAAAAAAAAAqC4B3k4AAAAAAAAAAAAAAABfREMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcCLQ2wkAAAAAAAAAAADURhaLRVar1WPxbDabzGaz2+Pk5OS4PQYAeAoNdQAAAAAAAAAAAA+zWCxKTk5RcfExzwU1mSTD8Fi4UluJx2IBgLvQUAcAAAAAAAAAAPAwq9Wq4uJj6jx8ssLjk9weL3dLtrYun692d05Qo2bJHol14sQJt8YBAE+goQ4AAAAAAAAAAOAl4fFJikps5fY4Rbl7JUlhMYluj1ceCwBqggBvJwAAAAAAAAAAAAAAgC+ioQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATgR6OwEAAHyVxWKR1Wr1aMzo6GglJiZ6NCYAAAAAAAAAAHCOhjoAAE5YLBYlJ6eouPiYR+OGhtbV9u05NNUBAAAAAAAAAPABLjXUL7zwQm3cuFENGzZ0WF5QUKAOHTrol19+qZbkAADwFqvVquLiY+o8fLLC45M8ErMod682LJwqq9VKQx04T9SrAAAA8FXUqgAAAP7FpYb63r17dfLkyQrLbTab9u3bd95JAQDgK8LjkxSV2MrbaQCoIupVAAAA+CpqVQAAAP9SpYb68uXL7X/+4osvFBERYX9/8uRJrVq1SklJSdWWHAAAAFAV1KsAAADwVdSqAAAA/qlKDfWbb75ZkmQymTR06FCHdUFBQUpKStJzzz1XbckBAAAAVUG9CgAAAF9FrQoAAOCfAqqycVlZmcrKypSYmKgDBw7Y35eVlclms2nHjh3q16+fS4nMnDlTJpNJ48aNsy87fvy40tPT1bBhQ4WFhSktLU35+fku7R8AAAA1nzvrVQAAAOB8UKsCAAD4pyo11Mvt2bNH0dHR1ZbExo0b9corr6hNmzYOy8ePH6+PP/5YS5cu1dq1a7V//34NGDCg2uICAACgZqruehUAAACoLtSqAAAA/qVKj3w/1apVq7Rq1Sr71ZSnWrhw4Tnv58iRI7rrrrv06quvavr06fblhYWFWrBggZYsWaKePXtKkrKyspSSkqL169erS5curqYOAACAWqC66lUAAACgulGrAgAA+A+X7lCfOnWqrrvuOq1atUpWq1V//vmnw6sq0tPTdcMNN6hXr14Oyzdt2qTS0lKH5cnJyUpMTFR2dnal+7PZbCoqKnJ4AQAAoHapznq1HFMUAQAAoDq4o1YFAACA+7h0h/q8efO0aNEi3X333ecV/O2339b333+vjRs3VliXl5en4OBgRUZGOiyPjY1VXl5epfucMWOGpk6del55AQAAwL9VV71a7kxTFH3yySdaunSpIiIiNGbMGA0YMEDr1q2rlrgAAACoeaq7VgUAAIB7uXSHeklJibp27XpegX/77TeNHTtWb775pkJCQs5rX6eaOHGiCgsL7a/ffvut2vYNAAAA/1Ad9Wq5U6coatCggX15+RRFzz//vHr27KmOHTsqKytL33zzjdavX1/p/niiEgAAQO1WnbXqqXiiEgAAgHu41FC/9957tWTJkvMKvGnTJh04cEAdOnRQYGCgAgMDtXbtWr344osKDAxUbGysSkpKVFBQ4PC5/Px8xcXFVbpfs9ms8PBwhxcAAABql+qoV8tV9xRFM2bMUEREhP2VkJBQLXkCAADAP1RnrVruTE9U+vjjj7V06VKtXbtW+/fv14ABA6o1NgAAQE3n0iPfjx8/rvnz52vlypVq06aNgoKCHNY///zzZ93HNddcoy1btjgsu+eee5ScnKwJEyYoISFBQUFBWrVqldLS0iRJO3bskMViUWpqqitpAwAAoJaojnpVcs8URRMnTlRGRob9fVFREU11AACAWqS6atVypz5Rafr06fbl5U9UWrJkiXr27ClJysrKUkpKitavX68uXbqc/2AAAABqAZca6j/++KPatWsnSdq6davDOpPJdE77qF+/vi699FKHZfXq1VPDhg3ty0eMGKGMjAxFRUUpPDxcDzzwgFJTUyn2AAAAcEbVUa+WT1G0YsWKap2iyGw2y2w2V9v+AAAA4F+qo1Y91alPVDq1oX62JypVdo7VZrPJZrPZ3zNFEQAAqO1caqivXr26uvNwatasWQoICFBaWppsNpt69+6tl19+2SOxAQAA4L+qo149dYqicidPntS///1vvfTSS/riiy/sUxSdepf62aYoAgAAQO1WnedW3fFEpRkzZmjq1KnVliMAAIC/c6mh7i5r1qxxeB8SEqLMzExlZmZ6JyEAAADUWkxRBAAAAF/mricqMUURAACAI5ca6ldfffUZHz/01VdfuZwQAAAAcL6qo15liiIAAAC4Q3WdW3XXE5WYoggAAMCRSw318jl+ypWWlmrz5s3aunWrhg4dWh15AQAAAC7zVL3KFEUAAACoquqqVXmiEgAAgGe41FCfNWuW0+VTpkzRkSNHzishAAAA4Hy5q15liiIAAACcr+qqVXmiEgAAgGcEVOfOBg8erIULF1bnLgEAAIBqQ70KAAAAX+WOWnXWrFnq16+f0tLSdNVVVykuLk4ffPBBtcYAAACo6Vy6Q70y2dnZCgkJqc5dAgAAANWGehUAAAC+qjpqVZ6oBAAAUP1caqgPGDDA4b1hGMrNzdV3332nSZMmVUtiAAAAgKuoVwEAAOCrqFUBAAD8i0sN9YiICIf3AQEBatWqlaZNm6brrruuWhIDAAAAXEW9CgAAAF9FrQoAAOBfXGqoZ2VlVXceAAAAQLWhXgUAAICvolYFAADwL+c1h/qmTZuUk5MjSbrkkkvUvn37akkKAAAAqA7UqwAAAPBV1KoAAAD+waWG+oEDB3THHXdozZo1ioyMlCQVFBTo6quv1ttvv61GjRpVZ44AAEiS/URDTYsFoPpRrwIAAMBXUasCAAD4F5ca6g888IAOHz6sbdu2KSUlRZL0008/aejQoXrwwQf11ltvVWuSAIDarbjwoCSTBg8e7PHYpbYSj8cEcP6oVwEAAOCrqFUBAAD8i0sN9c8//1wrV660F3ySdPHFFyszM1PXXXddtSUHAIAklR47LMlQuzsnqFGzZI/EzN2Sra3L5+vEiRMeiQegelGvAgAAwFdRqwIAAPgXlxrqZWVlCgoKqrA8KChIZWVl550UAADOhMUkKiqxlUdiFeXu9UgcAO5BvQoAAABfRa0KAADgXwJc+VDPnj01duxY7d+/375s3759Gj9+vK655ppqSw4AAABwBfUqAAAAfBW1KgAAgH9xqaH+0ksvqaioSElJSWrevLmaN2+uZs2aqaioSHPmzKnuHAEAAIAqoV4FAACAr6JWBQAA8C8uPfI9ISFB33//vVauXKnt27dLklJSUtSrV69qTQ4AAABwBfUqAAAAfBW1KgAAgH+pUkP9q6++0pgxY7R+/XqFh4fr2muv1bXXXitJKiws1CWXXKJ58+bpyiuvdEuyAAAAwJlQrwIAapKcnByvxI2OjlZiYqJXYgM1GbUqAACAf6pSQ3327Nm67777FB4eXmFdRESE/va3v+n555+n6AMAAIBXUK8CAGqC4sKDkkwaPHiwV+KHhtbV9u05NNWBakatCgAA4J+q1FD/4Ycf9PTTT1e6/rrrrtOzzz573kkBAAAArqBeBQDUBKXHDksy1O7OCWrULNmjsYty92rDwqmyWq001IFqRq0KAADgn6rUUM/Pz1dQUFDlOwsM1B9//HHeSQEAAACuoF4FANQkYTGJikps5e00AFQTalUAAAD/FFCVjS+44AJt3bq10vU//vij4uPjzzspAAAAwBXUqwAAAPBV1KoAAAD+qUoN9b59+2rSpEk6fvx4hXXFxcWaPHmy+vXrV23JAQAAAFVBvQoAAABfRa0KAADgn6r0yPfHHntMH3zwgS666CKNGTNGrVr99dix7du3KzMzUydPntQ//vEPtyQKAAAAnA31KgAAAHwVtSoAAIB/qlJDPTY2Vt98841GjRqliRMnyjAMSZLJZFLv3r2VmZmp2NhYtyQKAAAAnA31KgAAAHwVtSoAAIB/qlJDXZKaNm2qTz/9VH/++ad27dolwzDUsmVLNWjQwB35AQAAAFVCvQoAAABfRa0KAADgf6rcUC/XoEEDXX755dWZCwAAAFBtqFcBAADgq6hVAQAA/IfLDXUAAAAAAAAAAABPsFgsslqtHolls9lkNpvdHicnJ8ftMQAA54+GOgAAAAAAAAAA8FkWi0XJySkqLj7mmYAmk2QYnoklqdRW4rFYAICqo6EOAAAAAAAAAAB8ltVqVXHxMXUePlnh8UlujZW7JVtbl89XuzsnqFGzZI/EOnHihFvjAADODw11AAAAAAAAAADg88LjkxSV2MqtMYpy90qSwmISPRYLAODbArydAAAAAAAAAAAAAAAAvoiGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACa821OfOnas2bdooPDxc4eHhSk1N1WeffWZff/z4caWnp6thw4YKCwtTWlqa8vPzvZgxAAAAAAAAAAAAAKC28GpDvUmTJpo5c6Y2bdqk7777Tj179tRNN92kbdu2SZLGjx+vjz/+WEuXLtXatWu1f/9+DRgwwJspAwAAAAAAAAAAAABqCa821Pv376++ffuqZcuWuuiii/Tkk08qLCxM69evV2FhoRYsWKDnn39ePXv2VMeOHZWVlaVvvvlG69ev92baAAAAqCV4ohIAAAAAAABQu/nMHOonT57U22+/raNHjyo1NVWbNm1SaWmpevXqZd8mOTlZiYmJys7OrnQ/NptNRUVFDi8AAADAFTxRCQAAAAAAAKjdvN5Q37Jli8LCwmQ2m3X//ffrww8/1MUXX6y8vDwFBwcrMjLSYfvY2Fjl5eVVur8ZM2YoIiLC/kpISHDzCAAAAFBT8UQlAAAA+CqepgQAAOAZXm+ot2rVSps3b9aGDRs0atQoDR06VD/99JPL+5s4caIKCwvtr99++60aswUAAEBtxROVAAAA4Et4mhIAAIBnBHo7geDgYLVo0UKS1LFjR23cuFEvvPCCbr/9dpWUlKigoMDhLvX8/HzFxcVVuj+z2Syz2ezutAEAAFBLbNmyRampqTp+/LjCwsLsT1TavHmzy09Umjp1qpuzBgAAQE3Xv39/h/dPPvmk5s6dq/Xr16tJkyZasGCBlixZop49e0qSsrKylJKSovXr16tLly6V7tdms8lms9nfcwEoAACo7bx+h/rpysrKZLPZ1LFjRwUFBWnVqlX2dTt27JDFYlFqaqoXMwQAAEBtwhOVAAAA4Ouq62lKElNqAgAAnM6rd6hPnDhRffr0UWJiog4fPqwlS5ZozZo1+uKLLxQREaERI0YoIyNDUVFRCg8P1wMPPKDU1NQzXkEJAAAAVCeeqAQAAABfVd1PU5L+OmebkZFhf19UVERTHQAA1GpebagfOHBAQ4YMUW5uriIiItSmTRt98cUXuvbaayVJs2bNUkBAgNLS0mSz2dS7d2+9/PLL3kwZAAAAtZyzJyqlpaVJ4olKAAAA8KzypykVFhbqvffe09ChQ7V27drz2icXgAIAADjyakN9wYIFZ1wfEhKizMxMZWZmeigjAAAA4H94ohIAAAB8WXU/TQkAAAAVebWhDgAAAPgynqgEAAAAf8LTlAAAAKofDXUAAACgEjxRCQAAAL6KpykBAAB4Bg11AAAAAAAAAPAzPE0JAADAM2ioAwAAAAAAAICf4WlKAAAAnhHg7QQAAAAAAAAAAAAAAPBFNNQBAAAAAAAAAAAAAHCChjoAAAAAAAAAAAAAAE7QUAcAAAAAAAAAAAAAwAka6gAAAAAAAAAAAAAAOEFDHQAAAAAAAAAAAAAAJ2ioAwAAAAAAAAAAAADgRKC3EwAAAAAA+D+LxSKr1erRmDk5OR6NBwAAAAAAah8a6gAAAACA82KxWJScnKLi4mNeiV9qK/FKXAAAAACoaTx14XJ0dLQSExM9Egs4XzTUAQAAAADnxWq1qrj4mDoPn6zw+CSPxc3dkq2ty+frxIkTHosJAAAAADVRceFBSSYNHjzYI/FCQ+tq+/YcmurwCzTUAQAAAADVIjw+SVGJrTwWryh3r8diAQAAAEBNVnrssCRD7e6coEbNkt0aqyh3rzYsnCqr1UpDHX6BhjoAAAAAAAAAAAAAhcUkevRCacAfBHg7AQAAAAAAAAAAAAAAfBENdQAAAAAAAAAAAAAAnOCR74ATFotFVqvVozGjo6OZKwQAAAAAAAAAAADwITTUgdNYLBYlJ6eouPiYR+OGhtbV9u05NNUBAAAAAAAAAAAAH0FDHTiN1WpVcfExdR4+WeHxSR6JWZS7VxsWTpXVaqWhDgAAAAAAAAAAAPgIGupAJcLjkxSV2MrbaQAAAAAAAAAAAADwkgBvJwAAAAAAAAAAAAAAgC+ioQ4AAAAAAAAAAAAAgBM88h0AAAAAahCLxSKr1erRmDk5OR6NBwAAAAAA4Ck01AEAAACghrBYLEpOTlFx8TGvxC+1lXglLgAAAAAAgLvQUAcAAACAGsJqtaq4+Jg6D5+s8Pgkj8XN3ZKtrcvn68SJEx6LCQAAAAAA4Ak01AEAAACghgmPT1JUYiuPxSvK3euxWAAAAAAAAJ4U4O0EAAAAAAAAAAAAAADwRTTUAQAAAAAAAAAAAABwgoY6AAAAAAAAAAAAAABO0FAHAAAAAAAAAAAAAMAJGuoAAAAAAAAAAAAAADjh1Yb6jBkzdPnll6t+/fqKiYnRzTffrB07djhsc/z4caWnp6thw4YKCwtTWlqa8vPzvZQxAAAAAAAAAAAAAKC28GpDfe3atUpPT9f69eu1YsUKlZaW6rrrrtPRo0ft24wfP14ff/yxli5dqrVr12r//v0aMGCAF7MGAABAbcEFoAAAAAAAAEDt5tWG+ueff65hw4bpkksuUdu2bbVo0SJZLBZt2rRJklRYWKgFCxbo+eefV8+ePdWxY0dlZWXpm2++0fr1672ZOgAAAGoBLgAFAACAr+LiTwAAAM/wqTnUCwsLJUlRUVGSpE2bNqm0tFS9evWyb5OcnKzExERlZ2c73YfNZlNRUZHDCwAAAHAFF4ACAADAV3HxJwAAgGcEejuBcmVlZRo3bpy6deumSy+9VJKUl5en4OBgRUZGOmwbGxurvLw8p/uZMWOGpk6d6u50AQAAUAtV9QLQLl26VNiHzWaTzWazv+cCUAAAALji888/d3i/aNEixcTEaNOmTbrqqqvsF38uWbJEPXv2lCRlZWUpJSVF69evd1qrAgAAoCKfaainp6dr69at+vrrr89rPxMnTlRGRob9fVFRkRISEs43PQAAANRyXAAKAAAAX1YdF39KXAAKAPCcnJwcj8SJjo5WYmKiR2KhZvKJhvqYMWP0r3/9S//+97/VpEkT+/K4uDiVlJSooKDA4SRlfn6+4uLinO7LbDbLbDa7O2UAAADUMlwACgAAAF9VXRd/SlwACgBwv+LCg5JMGjx4sEfihYbW1fbtOTTV4TKvNtQNw9ADDzygDz/8UGvWrFGzZs0c1nfs2FFBQUFatWqV0tLSJEk7duyQxWJRamqqN1IGAABALcQFoAAAAPBl1XXxp8QFoAAA9ys9dliSoXZ3TlCjZslujVWUu1cbFk6V1WqloQ6XebWhnp6eriVLluijjz5S/fr17VdGRkREKDQ0VBERERoxYoQyMjIUFRWl8PBwPfDAA0pNTWWOHwAAALgdF4ACAADA11XnxZ8SF4ACADwnLCZRUYmtvJ0GcFZebajPnTtXktSjRw+H5VlZWRo2bJgkadasWQoICFBaWppsNpt69+6tl19+2cOZAgAAoDbiAlAAAAD4Ki7+BAAA8AyvP/L9bEJCQpSZmanMzEwPZAQAAAD8DxeAAgAAwFdx8ScAAIBneLWhDgAAAPgyLgAFAACAr+LiTwAAAM+goQ4AAAAAAAAAfoaLPwEAADwjwNsJAAAAAAAAAAAAAADgi2ioAwAAAAAAAAAAAADgBA11AAAAAAAAAAAAAACcoKEOAAAAAAAAAAAAAIATNNQBAAAAAAAAAAAAAHCChjoAAAAAAAAAAAAAAE7QUAcAAAAAAAAAAAAAwAka6gAAAAAAAAAAAAAAOEFDHQAAAAAAAAAAAAAAJ2ioAwAAAAAAAAAAAADgBA11AAAAAAAAAAAAAACcoKEOAAAAAAAAAAAAAIATgd5OAMD/5OTk1Kg4AAAAAAD/5I3/N0ZHRysxMdHjcQEAAADgTGioAz6guPCgJJMGDx7s0bilthKPxgMAAAAA+DZv/f9UkkJD62r79hya6gBwHiwWi6xWq8fi2Ww2mc1mt8fhBiEAgDfRUAd8QOmxw5IMtbtzgho1S3Z7vNwt2dq6fL5OnDjh9lgAAAAAAP/h6f+flivK3asNC6fKarXSUAcAF1ksFiUnp6i4+JjngppMkmF4LBw3CAEAvIGGOuBDwmISFZXYyu1xinL3uj0GAAAAAMB/eer/pwCA6mO1WlVcfEydh09WeHyS2+OV37TjiYuwuEEIAOBNNNQBAAAAAAAAAKghwuOTPHrTjicuwuIGIQCANwV4OwEAAAAAAAAAAAAAAHwRDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnAr2dAAAAAADUNBaLRVar1eNxc3JyPB4TAAAAAACgJqOhDgAAAADVyGKxKDk5RcXFx7yWQ6mtxGuxAQAAAAAAahIa6gAAAABQjaxWq4qLj6nz8MkKj0/yaOzcLdnauny+Tpw44dG4AAAAAAAANRUNdQAAAABwg/D4JEUltvJozKLcvR6NBwAAAAAAUNMFeDsBAAAAAAAAAAAAAAB8EQ11AAAAAAAAAAAAAACc8GpD/d///rf69++vxo0by2QyadmyZQ7rDcPQ448/rvj4eIWGhqpXr17auXOnd5IFAABArUO9CgAAAAAAANRuXm2oHz16VG3btlVmZqbT9f/85z/14osvat68edqwYYPq1aun3r176/jx4x7OFAAAALUR9SoAAAB8GReAAgAAuJ9XG+p9+vTR9OnTdcstt1RYZxiGZs+erccee0w33XST2rRpo9dff1379++vUBgCAAAA7kC9CgAAAF/GBaAAAADu57NzqO/Zs0d5eXnq1auXfVlERIQ6d+6s7OzsSj9ns9lUVFTk8AIAAACqG/UqAAAAvI0LQAEAANzPZxvqeXl5kqTY2FiH5bGxsfZ1zsyYMUMRERH2V0JCglvzBAAAQO1EvQoAAABfxgWgAAAA1cNnG+qumjhxogoLC+2v3377zdspAQAAAHbUqwAAAPAELgAFAACoHj7bUI+Li5Mk5efnOyzPz8+3r3PGbDYrPDzc4QUAAABUN+pVAAAA1ERcAAoAAOAo0NsJVKZZs2aKi4vTqlWr1K5dO0lSUVGRNmzYoFGjRnk3OQAA3CgnJ8ej8aKjo5WYmOjRmEBNQL0KAAAAX3bqBaDx8fH25fn5+fb61Rmz2Syz2ezu9AAAAPyGVxvqR44c0a5du+zv9+zZo82bNysqKkqJiYkaN26cpk+frpYtW6pZs2aaNGmSGjdurJtvvtl7SQMA4CbFhQclmTR48GCPxg0Nravt23NoqgNOUK8CAADAX3EBKAAA/+PJm5i4ganm8WpD/bvvvtPVV19tf5+RkSFJGjp0qBYtWqRHHnlER48e1ciRI1VQUKArrrhCn3/+uUJCQryVMgAAblN67LAkQ+3unKBGzZI9ErMod682LJwqq9VKkQc4Qb0KAAAAX8YFoAAAnJk3bmLiBqaax6sN9R49esgwjErXm0wmTZs2TdOmTfNgVgAAeFdYTKKiElt5Ow0Aol4FAACAb+MCUAAAzszTNzFxA1PN5LNzqAMAAAAAAAAAKscFoAAAnBtuYsL5CPB2AgAAAAAAAAAAAAAA+CIa6gAAAAAAAAAAAAAAOEFDHQAAAAAAAAAAAAAAJ2ioAwAAAAAAAAAAAADgRKC3EwAAAN6Xk5PjsVjR0dFKTEz0WDwAtZvFYpHVavVoTE/+mwoAAAAAAAD3oqEOAEAtVlx4UJJJgwcP9ljM0NC62r49h6Y6ALezWCxKTk5RcfExr8QvtZV4JS4AAAAAAACqDw11AABqsdJjhyUZanfnBDVqluz2eEW5e7Vh4VRZrVYa6gDczmq1qrj4mDoPn6zw+CSPxc3dkq2ty+frxIkTHosJAAAAAAAA96ChDgAAFBaTqKjEVt5OAwDcIjw+yaP/xhXl7vVYLAAAAAAAALgXDXX4PE/Pe8mclwAAAAAAeIe3/k8eHR3NE5QAAAAAOEVDHT7Nm/NeMuclAAAAAACeUVx4UJJJgwcP9kr80NC62r49h6Y6ALfw1A1D3CgEAIB70FCHT/PGvJfMeQkAAAAAgGeVHjssyVC7OyeoUbNkj8Yuyt2rDQunymq10lAHUO28ccMQNwoBAFC9aKjDL3hy3kvmvAQAAAAAwDvCYhI99v9/APAET94wxI1CAAC4Bw11VAnzmQMAAAAAAABA1XjihiFuFAIAwD1oqOOcMZ85AAAAAAAAAAAAgNqEhjrOGfOZAwAAAAAAAAAAAKhNaKijypjPHAAAAAAAAAAAAEBtEODtBAAAAAAAAAAAAAAA8EU01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcCLQ2wng/FgsFlmtVo/EysnJ8UgcAEDN5+nvlOjoaCUmJno0JoD/8WTNeirqVwBAVXjje4M6FfgfT9eM/P4BANzJU7Ul32eeQUPdj1ksFiUnp6i4+JhH45baSjwaDwBQcxQXHpRk0uDBgz0aNzS0rrZvz6G4BLzAWzXrqahfAQBn4q0aVaJOBcp5o2bk9w8A4A6eri35PvMMGup+zGq1qrj4mDoPn6zw+CS3x8vdkq2ty+frxIkTbo8FAKiZSo8dlmSo3Z0T1KhZskdiFuXu1YaFU2W1WiksAS/wdM16KupXAMC58EaNKlGnAqfydM3I7x8AwF08WVvyfeY5NNRrgPD4JEUltnJ7nKLcvW6PAQCoHcJiEj3y3QXAd3iqZj0V9SsAoCqoUQHv80bNCACAO1Bb1iw01KuRp+f5YU5IAADOHfO2A96Zy5yaFQCAM/PWdyX1KuCZ3z/qYQCAu3nqu8Zms8lsNnskluRb9SoN9WrizbkhmRMSAIDKMW878Bdvz2VOzQoAgCNvzt0uUa+idvPG7x/1MACgunn8+8xkkgzDM7HkW/WqXzTUMzMz9cwzzygvL09t27bVnDlz1KlTJ2+n5cAbc0MyJyQAAGfHvO3wBOrVylGzAgDgnLfmbpeoV2sjf6hXPcmTv3/UwwAAd/HG95mnaldfq1d9vqH+zjvvKCMjQ/PmzVPnzp01e/Zs9e7dWzt27FBMTIy306vAk/P8MCckAADnjnmL4C7Uq2dGzQoAwJlRp8Ld/K1e9SRP/P5RDwMA3M2T32e1tXb1+Yb6888/r/vuu0/33HOPJGnevHn65JNPtHDhQj366KMVtrfZbLLZbPb3hYWFkqSioiK35nnkyBFJ0qFfd+iErditscoV5f4qSSrct1NBgaYaF4+YNSceMWtWzNowRmLWnHhei5lnkfRXfeDOGqR834YHH7WEiqhXz8wbv4Pejs2Ya35cb8ZmzIy5psZmzB4eM/VqreIP9aqna1VP/v7V1Fiejkcs/4tHLP+LRyz/i1dTY0meqVerUquaDB+uaEtKSlS3bl299957uvnmm+3Lhw4dqoKCAn300UcVPjNlyhRNnTrVg1kCAAB412+//aYmTZp4O41aiXoVAADg7KhXvYd6FQAA4MzOpVb16TvUrVarTp48qdjYWIflsbGx2r59u9PPTJw4URkZGfb3ZWVlOnTokBo2bCiTybNX+1aHoqIiJSQk6LffflN4eLi30/GK2n4MGH/tHr/EMWD8tXv8EsfgTOM3DEOHDx9W48aNvZQdqFf/Utt/T8txHDgG5TgOHINyHAeOQbnaehyoV73Pn+vV2vp7c744bq7j2LmOY+c6jp3rOHau49j9pSq1qk831F1hNptlNpsdlkVGRnonmWoUHh5eq/9SSxwDxl+7xy9xDBh/7R6/xDGobPwRERFeyAbno6bWqxK/p+U4DhyDchwHjkE5jgPHoFxtPA7Uq/7H1+rV2vh7Ux04bq7j2LmOY+c6jp3rOHau49ide60a4OY8zkt0dLTq1Kmj/Px8h+X5+fmKi4vzUlYAAADAX6hXAQAA4MuoVwEAAM6fTzfUg4OD1bFjR61atcq+rKysTKtWrVJqaqoXMwMAAACoVwEAAODbqFcBAADOn88/8j0jI0NDhw7VZZddpk6dOmn27Nk6evSo7rnnHm+n5hFms1mTJ0+u8Jil2qS2HwPGX7vHL3EMGH/tHr/EMajt4/cHtb1elfh7Wo7jwDEox3HgGJTjOHAMynEc4E3+Wq/ye+MajpvrOHau49i5jmPnOo6d6zh2VWcyDMPwdhJn89JLL+mZZ55RXl6e2rVrpxdffFGdO3f2dloAAACAJOpVAAAA+DbqVQAAANf5RUMdAAAAAAAAAAAAAABP8+k51AEAAAAAAAAAAAAA8BYa6gAAAAAAAAAAAAAAOEFDHQAAAAAAAAAAAAAAJ2ioAwAAAAAAAAAAAADgBA11D8jMzFRSUpJCQkLUuXNnffvtt5Vuu2jRIplMJodXSEiIwzbDhg2rsM3111/vsM2hQ4d01113KTw8XJGRkRoxYoSOHDnilvGdTXWP//T15a9nnnnGvk1SUlKF9TNnznTbGM+kKuOXpIKCAqWnpys+Pl5ms1kXXXSRPv300yrt8/jx40pPT1fDhg0VFhamtLQ05efnV/vYzlV1H4MZM2bo8ssvV/369RUTE6Obb75ZO3bscNhHjx49KvwduP/++90yvrOp7vFPmTKlwtiSk5Md9uFLfweqe/zOfr9NJpPS09Pt2/jSz1+q2jFwlrvJZNINN9xg38YwDD3++OOKj49XaGioevXqpZ07dzrsx1+/B842/tLSUk2YMEGtW7dWvXr11LhxYw0ZMkT79+932I+/fg+cy8/f3+oA+IfaXq+Wq+11q0TtWq62168SNWw5allq2XK1vaYFXEFt5TpqMtdQw7mO2s911Iuuo850HbWpFxhwq7ffftsIDg42Fi5caGzbts247777jMjISCM/P9/p9llZWUZ4eLiRm5trf+Xl5TlsM3ToUOP666932ObQoUMO21x//fVG27ZtjfXr1xv/+c9/jBYtWhiDBg1y2zgr447xn7ouNzfXWLhwoWEymYzdu3fbt2natKkxbdo0h+2OHDni1rE6U9Xx22w247LLLjP69u1rfP3118aePXuMNWvWGJs3b67SPu+//34jISHBWLVqlfHdd98ZXbp0Mbp27er28TrjjmPQu3dvIysry9i6dauxefNmo2/fvkZiYqLDz7h79+7Gfffd5/B3oLCw0O3jPZ07xj958mTjkksucRjbH3/84bAfX/k74I7xHzhwwGHsK1asMCQZq1evtm/jKz9/w6j6MTh48KBD3lu3bjXq1KljZGVl2beZOXOmERERYSxbtsz44YcfjBtvvNFo1qyZUVxcbN/GX78Hzjb+goICo1evXsY777xjbN++3cjOzjY6depkdOzY0WE//vo9cC4/f3+qA+Afanu9Wq62162GQe1alZxPVdPqV8Oghi1HLUstW66217SAK6itXEdN5hpqONdR+7mOetF11Jmuozb1DhrqbtapUycjPT3d/v7kyZNG48aNjRkzZjjdPisry4iIiDjjPocOHWrcdNNNla7/6aefDEnGxo0b7cs+++wzw2QyGfv27atS/ufLHeM/3U033WT07NnTYVnTpk2NWbNmVTXdalfV8c+dO9e48MILjZKSEpf3WVBQYAQFBRlLly61b5OTk2NIMrKzs893SFXmjmNwugMHDhiSjLVr19qXde/e3Rg7dqzLeVcXd4x/8uTJRtu2bStd70t/Bzzx8x87dqzRvHlzo6yszL7MV37+hlH1Y3C6WbNmGfXr17cXJ2VlZUZcXJzxzDPP2LcpKCgwzGaz8dZbbxmG4d/fA6c7ffzOfPvtt4Yk49dff7Uv89fvgdM5G78/1QHwD7W9Xi1X2+tWw6B2LVfb61fDoIYtRy1LLVuutte0gCuorVxHTeYaajjXUfu5jnrRddSZrqM29Q4e+e5GJSUl2rRpk3r16mVfFhAQoF69eik7O7vSzx05ckRNmzZVQkKCbrrpJm3btq3CNmvWrFFMTIxatWqlUaNG6eDBg/Z12dnZioyM1GWXXWZf1qtXLwUEBGjDhg3VNLqzc+f4y+Xn5+uTTz7RiBEjKqybOXOmGjZsqPbt2+uZZ57RiRMnzm9AVeTK+JcvX67U1FSlp6crNjZWl156qZ566imdPHnynPe5adMmlZaWOmyTnJysxMTEMx53d3DHMXCmsLBQkhQVFeWw/M0331R0dLQuvfRSTZw4UceOHauGUZ07d45/586daty4sS688ELdddddslgs9nW+8nfAEz//kpISLV68WMOHD5fJZHJY5+2ff3l+rvw7eKoFCxbojjvuUL169SRJe/bsUV5ensM+IyIi1LlzZ/s+/f174FSnj9+ZwsJCmUwmRUZGOiz3x++B01U2fn+oA+Afanu9Wq62160StWu52l6/StSw5ahlqWXL1faaFnAFtZXrqMlcQw3nOmo/11Evuo4603XUpt4T6O0EajKr1aqTJ08qNjbWYXlsbKy2b9/u9DOtWrXSwoUL1aZNGxUWFurZZ59V165dtW3bNjVp0kSSdP3112vAgAFq1qyZdu/erb///e/q06ePsrOzVadOHeXl5SkmJsZhv4GBgYqKilJeXp57BuuEu8Z/qtdee03169fXgAEDHJY/+OCD6tChg6KiovTNN99o4sSJys3N1fPPP199AzwLV8b/yy+/6KuvvtJdd92lTz/9VLt27dLo0aNVWlqqyZMnn9M+8/LyFBwcXOEfutjYWI/+/CX3HIPTlZWVady4cerWrZsuvfRS+/I777xTTZs2VePGjfXjjz9qwoQJ2rFjhz744IPqHeQZuGv8nTt31qJFi9SqVSvl5uZq6tSpuvLKK7V161bVr1/fZ/4OeOLnv2zZMhUUFGjYsGEOy33h5y+5dgxO9e2332rr1q1asGCBfVn5z9DZPsvX+fP3wKmcjf90x48f14QJEzRo0CCFh4fbl/vr98CpKhu/v9QB8A+1vV4tV9vrVonatVxtr18lathy1LLUsuVqe00LuILaynXUZK6hhnMdtZ/rqBddR53pOmpT76Gh7mNSU1OVmppqf9+1a1elpKTolVde0RNPPCFJuuOOO+zrW7durTZt2qh58+Zas2aNrrnmGo/nXJ3OZfynWrhwoe666y6FhIQ4LM/IyLD/uU2bNgoODtbf/vY3zZgxQ2az2X0DOE9lZWWKiYnR/PnzVadOHXXs2FH79u3TM8884/QLtSaq6jFIT0/X1q1b9fXXXzssHzlypP3PrVu3Vnx8vK655hrt3r1bzZs3d/s4XHUu4+/Tp499+zZt2qhz585q2rSp3n33XadXZvuTqv78FyxYoD59+qhx48YOy/3153+6BQsWqHXr1urUqZO3U/GKs42/tLRUAwcOlGEYmjt3rsM6f/0eOFVl46/JdQD8Q22vV8vV9rpVonYtV9vrV4kathy1rKPaXsuWq+01LXCuqK1cR03mGmo411H7uY56sXpQZ7qO2tR1PPLdjaKjo1WnTh3l5+c7LM/Pz1dcXNw57SMoKEjt27fXrl27Kt3mwgsvVHR0tH2buLg4HThwwGGbEydO6NChQ+cctzq4e/z/+c9/tGPHDt17771n3U/nzp114sQJ7d2795ziVgdXxh8fH6+LLrpIderUsS9LSUlRXl6eSkpKzmmfcXFxKikpUUFBwTnHdRd3HINTjRkzRv/617+0evVqp1crn6pz586SdMbfperm7vGXi4yM1EUXXeTwb4Av/B1w9/h//fVXrVy58pz/DZA8+/OXzu/fwaNHj+rtt9+u8J+M8s+d7d8Bf/8eqGz85cqLu19//VUrVqxwuFrSGX/5Hih3tvGfylfrAPiH2l6vlqvtdatE7VquttevEjVsOWpZatlytb2mBVxBbeU6ajLXUMO5jtrPddSLrqPOdB21qffQUHej4OBgdezYUatWrbIvKysr06pVqxyuuDyTkydPasuWLYqPj690m99//10HDx60b5OamqqCggJt2rTJvs1XX32lsrIy+z+snuDu8S9YsEAdO3ZU27Ztz7qfzZs3KyAgoMLjPNzJlfF369ZNu3btUllZmX3Zzz//rPj4eAUHB5/TPjt27KigoCCHbXbs2CGLxXLOx726uOMYSJJhGBozZow+/PBDffXVV2rWrNlZc9m8ebMknfF3qbq5a/ynO3LkiHbv3m0fm6/8HXD3+LOyshQTE6MbbrjhrLl44+cvnd+/g0uXLpXNZtPgwYMdljdr1kxxcXEO+ywqKtKGDRvs+6wJ3wOVjV/6X3G3c+dOrVy5Ug0bNjxrLv7yPVDuTOM/na/WAfAPtb1eLVfb61aJ2rVcba9fJWrYctSy1LLlantNC7iC2sp11GSuoYZzHbWf66gXXUed6TpqUy8y4FZvv/22YTabjUWLFhk//fSTMXLkSCMyMtLIy8szDMMw7r77buPRRx+1bz916lTjiy++MHbv3m1s2rTJuOOOO4yQkBBj27ZthmEYxuHDh42HH37YyM7ONvbs2WOsXLnS6NChg9GyZUvj+PHj9v1cf/31Rvv27Y0NGzYYX3/9tdGyZUtj0KBBnh28Uf3jL1dYWGjUrVvXmDt3boWY33zzjTFr1ixj8+bNxu7du43FixcbjRo1MoYMGeLewTpR1fFbLBajfv36xpgxY4wdO3YY//rXv4yYmBhj+vTp57xPwzCM+++/30hMTDS++uor47vvvjNSU1ON1NRUzw38FO44BqNGjTIiIiKMNWvWGLm5ufbXsWPHDMMwjF27dhnTpk0zvvvuO2PPnj3GRx99ZFx44YXGVVdd5dnBG+4Z/0MPPWSsWbPG2LNnj7Fu3TqjV69eRnR0tHHgwAH7Nr7yd8Ad4zcMwzh58qSRmJhoTJgwoUJMX/r5G0bVj0G5K664wrj99tud7nPmzJlGZGSk8dFHHxk//vijcdNNNxnNmjUziouL7dv46/dAucrGX1JSYtx4441GkyZNjM2bNzv8G2Cz2QzD8O/vgXKVjd/f6gD4h9per5ar7XWrYVC7nmvONb1+NQxq2HLUstSy5Wp7TQu4gtrKddRkrqGGcx21n+uoF11Hnek6alPvoKHuAXPmzDESExON4OBgo1OnTsb69evt67p3724MHTrU/n7cuHH2bWNjY42+ffsa33//vX39sWPHjOuuu85o1KiRERQUZDRt2tS47777HIofwzCMgwcPGoMGDTLCwsKM8PBw45577jEOHz7s9rE6U53jL/fKK68YoaGhRkFBQYV1mzZtMjp37mxEREQYISEhRkpKivHUU085nMD1pKqM3zD++oepc+fOhtlsNi688ELjySefNE6cOHHO+zQMwyguLjZGjx5tNGjQwKhbt65xyy23GLm5uW4b49lU9zGQ5PSVlZVlGMZfhclVV11lREVFGWaz2WjRooXxf//3f0ZhYaEnhltBdY//9ttvN+Lj443g4GDjggsuMG6//XZj165dDvvwpb8D7vgd+OKLLwxJxo4dOyrE87Wfv2FU/Rhs377dkGR8+eWXTvdXVlZmTJo0yYiNjTXMZrNxzTXXVDgW/vo9YBhnHv+ePXsq/Tdg9erVhmH4//fAmcbvj3UA/ENtr1fL1fa61TCoXcvV9vrVMKhhy1HLUsuWq+01LeAKaivXUZO5hhrOddR+rqNedB11puuoTT3PZBiG4Y473wEAAAAAAAAAAAAA8GfMoQ4AAAAAAAAAAAAAgBM01AEAAAAAAAAAAAAAcIKGOgAAAAAAAAAAAAAATtBQBwAAAAAAAAAAAADACRrqAAAAAAAAAAAAAAA4QUMdAAAAAAAAAAAAAAAnaKgDAAAAAAAAAAAAAOAEDXUAAAAAAAAAAAAAAJygoQ4AAAAAgJcZhqGRI0cqKipKJpNJmzdv9nZKAAAAgEetWbNGJpNJBQUF1botAJwvGuoAAAAAAHjZ559/rkWLFulf//qXcnNzVVRUpP79+6tx48YymUxatmyZt1MEAAAA3Kpr167Kzc1VREREtW4LAOeLhjoAeEhpaam3UwAAAICP2r17t+Lj49W1a1fFxcXp6NGjatu2rTIzM72dWqVKSkq8nQIAAAB8RHXUhsHBwYqLi5PJZKrWbQHgfNFQB1Bjff7557riiisUGRmphg0bql+/ftq9e7d9/e+//65BgwYpKipK9erV02WXXaYNGzbY13/88ce6/PLLFRISoujoaN1yyy32dc7uEoqMjNSiRYskSXv37pXJZNI777yj7t27KyQkRG+++aYOHjyoQYMG6YILLlDdunXVunVrvfXWWw77KSsr0z//+U+1aNFCZrNZiYmJevLJJyVJPXv21JgxYxy2/+OPPxQcHKxVq1ZVx2EDAACAhw0bNkwPPPCALBaLTCaTkpKS1KdPH02fPt2hBj0bwzA0ZcoUJSYmymw2q3HjxnrwwQft6202myZMmKCEhASZzWa1aNFCCxYssK9fu3atOnXqJLPZrPj4eD366KM6ceKEfX2PHj00ZswYjRs3TtHR0erdu7ckaevWrerTp4/CwsIUGxuru+++W1artRqODAAAALylvPYbM2aMIiIiFB0drUmTJskwDElSUlKSnnjiCQ0ZMkTh4eEaOXKkJOnrr7/WlVdeqdDQUCUkJOjBBx/U0aNH7fs9U016+mPcf/31V/Xv318NGjRQvXr1dMkll+jTTz91uq0kvf/++7rkkktkNpuVlJSk5557zmFMSUlJeuqppzR8+HDVr19fiYmJmj9/vrsOIYAahIY6gBrr6NGjysjI0HfffadVq1YpICBAt9xyi8rKynTkyBF1795d+/bt0/Lly/XDDz/okUceUVlZmSTpk08+0S233KK+ffvqv//9r1atWqVOnTpVOYdHH31UY8eOVU5Ojnr37q3jx4+rY8eO+uSTT7R161aNHDlSd999t7799lv7ZyZOnKiZM2dq0qRJ+umnn7RkyRLFxsZKku69914tWbJENpvNvv3ixYt1wQUXqGfPnud5xAAAAOANL7zwgqZNm6YmTZooNzdXGzdudGk/77//vmbNmqVXXnlFO3fu1LJly9S6dWv7+iFDhuitt97Siy++qJycHL3yyisKCwuTJO3bt099+/bV5Zdfrh9++EFz587VggULNH36dIcYr732moKDg7Vu3TrNmzdPBQUF6tmzp9q3b6/vvvtOn3/+ufLz8zVw4EDXDwgAAAB8wmuvvabAwEB9++23euGFF/T888/r//2//2df/+yzz6pt27b673//q0mTJmn37t26/vrrlZaWph9//FHvvPOOvv76a4cbhM5Uk54uPT1dNptN//73v7VlyxY9/fTTlW67adMmDRw4UHfccYe2bNmiKVOmaNKkSfYboMo999xzuuyyy/Tf//5Xo0eP1qhRo7Rjx47zP1gAajSTUX45EQDUcFarVY0aNdKWLVv0zTff6OGHH9bevXsVFRVVYduuXbvqwgsv1OLFi53uy2Qy6cMPP9TNN99sXxYZGanZs2dr2LBh2rt3r5o1a6bZs2dr7NixZ8yrX79+Sk5O1rPPPqvDhw+rUaNGeumll3TvvfdW2Pb48eNq3Lix5s2bZz9J2bZtWw0YMECTJ0+uwtEAAACAL5k9e7Zmz56tvXv3VljnrPZ05vnnn9crr7yirVu3KigoyGHdzz//rFatWmnFihXq1atXhc/+4x//0Pvvv6+cnBz7YzNffvllTZgwQYWFhQoICFCPHj1UVFSk77//3v656dOn6z//+Y+++OIL+7Lff/9dCQkJ2rFjhy666KIqHAUAAAD4ih49eujAgQPatm2bvT589NFHtXz5cv30009KSkpS+/bt9eGHH9o/c++996pOnTp65ZVX7Mu+/vprde/eXUePHpXFYjljTbpmzRpdffXV+vPPPxUZGak2bdooLS3N6XnP07e966679Mcff+jLL7+0b/PII4/ok08+0bZt2yT9dYf6lVdeqTfeeEPSX094iouL09SpU3X//fdXz4EDUCNxhzqAGmvnzp0aNGiQLrzwQoWHhyspKUmSZLFYtHnzZrVv395pM12SNm/erGuuuea8c7jssssc3p88eVJPPPGEWrduraioKIWFhemLL76QxWKRJOXk5Mhms1UaOyQkRHfffbcWLlwoSfr++++1detWDRs27LxzBQAAgP946qmnFBYWZn9ZLBbddtttKi4u1oUXXqj77rtPH374of2R7Zs3b1adOnXUvXt3p/vLyclRamqqwxyU3bp105EjR/T777/bl3Xs2NHhcz/88INWr17tkEtycrIkOUy3BAAAAP/TpUsXh/owNTVVO3fu1MmTJyVVPPf5ww8/aNGiRQ61Ye/evVVWVqY9e/actSY93YMPPqjp06erW7dumjx5sn788cdKt83JyVG3bt0clnXr1s0hX0lq06aN/c8mk0lxcXE6cODAOeUDoPYK9HYCAOAu/fv3V9OmTfXqq6+qcePGKisr06WXXqqSkhKFhoae8bNnW28ymXT6Az5KS0srbFevXj2H988884xeeOEFzZ49W61bt1a9evU0btw4lZSUnFNc6a8rPdu1a6fff/9dWVlZ6tmzp5o2bXrWzwEAAKDmuP/++x0eq964cWMFBgZqx44dWrlypVasWKHRo0frmWee0dq1a8+pzjwXp9e3R44cUf/+/fX0009X2DY+Pr5aYgIAAMA3OasN//a3v+nBBx+ssG1iYqJ27dpVpf3fe++96t27tz755BN9+eWXmjFjhp577jk98MADLud8+pOcTCaTfRpQAKgMd6gDqJEOHjyoHTt26LHHHtM111yjlJQU/fnnn/b1bdq00ebNm3Xo0CGnn2/Tpo1WrVpV6f4bNWqk3Nxc+/udO3fq2LFjZ81r3bp1uummmzR48GC1bdtWF154oX7++Wf7+pYtWyo0NPSMsVu3bq3LLrtMr776qpYsWaLhw4efNS4AAABqlqioKLVo0cL+Cgz863r50NBQ9e/fXy+++KLWrFmj7OxsbdmyRa1bt1ZZWZnWrl3rdH8pKSnKzs52uGh03bp1ql+/vpo0aVJpHh06dNC2bduUlJTkkE+LFi0qnGAFAACAf9mwYYPD+/Xr16tly5aqU6eO0+07dOign376qUJd2KJFCwUHB5+1JnUmISFB999/vz744AM99NBDevXVV51ul5KSonXr1jksW7dunS666KJK8wWAc0VDHUCN1KBBAzVs2FDz58/Xrl279NVXXykjI8O+ftCgQYqLi9PNN9+sdevW6ZdfftH777+v7OxsSdLkyZP11ltvafLkycrJydGWLVsc7rrp2bOnXnrpJf33v//Vd999p/vvv7/C1Y3OtGzZUitWrNA333yjnJwc/e1vf1N+fr59fUhIiCZMmKBHHnlEr7/+unbv3q3169drwYIFDvu59957NXPmTBmGoVtuueV8DxcAAAB8zJEjR7R582Zt3rxZkuyPyCyfKsiZRYsWacGCBdq6dat++eUXLV68WKGhoWratKmSkpI0dOhQDR8+XMuWLdOePXu0Zs0avfvuu5Kk0aNH67ffftMDDzyg7du366OPPtLkyZOVkZGhgIDKTx2kp6fr0KFDGjRokDZu3Kjdu3friy++0D333OPwaE0AAAD4H4vFooyMDO3YsUNvvfWW5syZo7Fjx1a6/YQJE/TNN99ozJgx2rx5s3bu3KmPPvpIY8aMkaSz1qSnGzdunL744gvt2bNH33//vVavXq2UlBSn2z700ENatWqVnnjiCf3888967bXX9NJLL+nhhx8+/wMBoNajoQ6gRgoICNDbb7+tTZs26dJLL9X48eP1zDPP2NcHBwfryy+/VExMjPr27avWrVtr5syZ9qsVe/TooaVLl2r58uVq166devbsqW+//db++eeee04JCQm68sordeedd+rhhx9W3bp1z5rXY489pg4dOqh3797q0aOHval/qkmTJumhhx7S448/rpSUFN1+++0V5vEZNGiQAgMDNWjQIIWEhJzHkQIAAIAv+u6779S+fXu1b99ekpSRkaH27dvr8ccfr/QzkZGRevXVV9WtWze1adNGK1eu1Mcff6yGDRtKkubOnatbb71Vo0ePVnJysu677z4dPXpUknTBBRfo008/1bfffqu2bdvq/vvv14gRI/TYY4+dMc/GjRtr3bp1OnnypK677jq1bt1a48aNU2Rk5Bkb8QAAAPB9Q4YMUXFxsTp16qT09HSNHTtWI0eOrHT7Nm3aaO3atfr555915ZVX2uvXxo0b27c5U016upMnTyo9PV0pKSm6/vrrddFFF+nll192um2HDh307rvv6u2339all16qxx9/XNOmTdOwYcPO6xgAgCSZjNMnAQYA+Ly9e/eqefPm2rhxozp06ODtdAAAAAAAAADUID169FC7du00e/Zsb6cCAF4X6O0EAADnrrS0VAcPHtRjjz2mLl260EwHAAAAAAAAAABwI56/BgB+ZN26dYqPj9fGjRs1b948b6cDAAAAAAAAAABQo9FQBwAfsWjRIplMJu3du9e+rEePHurRo4fDe8MwtGPHDrVu3drzSQIAAMDv7N27VyaTSYsWLTqn7U0mk6ZMmVLlOFOmTJHJZKry5wAAAOB71qxZ49HHvZ9+HlSS8vPzdeutt6phw4YymUyaPXu21qxZI5PJpDVr1lRp/9SqAM4HDXUAAAAAAGqZTz/91KWmeVU99dRTWrZsmdvjAAAAoOYZP368vvjiC02cOFFvvPGGrr/++mrdP7UqgHNlMgzD8HYSAIC/7lC/5557tGfPHiUlJUmS/arMql5xCQAAAJQzDEM2m01BQUGqU6eOJGnMmDHKzMyUs1MCx48fV2BgoAIDA6sU58SJEzpx4oRCQkLsy8LCwnTrrbee893xAAAAqJ1KSkokScHBwfZlcXFx6tWrlxYvXmxfVlZWppKSEgUHBysg4NzvGaVWBXA+qva/YwCoBY4ePap69ep5Ow0AAACgWphMJocTh2dTlW1P5UoTHgAAAJAcG+nlDhw4oMjISIdlAQEBLtWr1KoAzgePfAdQq5XPnfPTTz/pzjvvVIMGDXTFFVdIkhYvXqyOHTsqNDRUUVFRuuOOO/Tbb79V2MeGDRvUt29fNWjQQPXq1VObNm30wgsv2Nf/+OOPGjZsmC688EKFhIQoLi5Ow4cP18GDBz02TgAAAHjG4cOHNW7cOCUlJclsNismJkbXXnutvv/+e/s2GzZs0PXXX6+IiAjVrVtX3bt317p16xz2U16n7tq1S8OGDVNkZKQiIiJ0zz336NixYw7brlixQldccYUiIyMVFhamVq1a6e9//7t9/elzqA8bNkyZmZmS/mq2l7/KnTqH+nvvvSeTyaS1a9dWGOsrr7wik8mkrVu3OuR86n6OHj2q1157zR5j2LBhWr16tUwmkz788MMK+1yyZIlMJpOys7PP5XADAACgis5Wr/bo0UOXXnqpNm3apK5duyo0NFTNmjXTvHnzKuzLZrNp8uTJatGihcxmsxISEvTII4/IZrNV2Hbx4sXq1KmT6tatqwYNGuiqq67Sl19+aV9/6hzqixYtkslkkmEYyszMdKhXK5tD/WznaKlVAZwPLscBAEm33XabWrZsqaeeekqGYejJJ5/UpEmTNHDgQN177736448/NGfOHF111VX673//a78ycsWKFerXr5/i4+M1duxYxcXFKScnR//61780duxY+za//PKL7rnnHsXFxWnbtm2aP3++tm3bpvXr1zsUcgAAAPBv999/v9577z2NGTNGF198sQ4ePKivv/5aOTk56tChg7766iv16dNHHTt21OTJkxUQEKCsrCz17NlT//nPf9SpUyeH/Q0cOFDNmjXTjBkz9P333+v//b//p5iYGD399NOSpG3btqlfv35q06aNpk2bJrPZrF27dlVo0J/qb3/7m/bv368VK1bojTfeOON4brjhBoWFhendd99V9+7dHda98847uuSSS3TppZc6/ewbb7yhe++9V506ddLIkSMlSc2bN1eXLl2UkJCgN998U7fccovDZ9588001b95cqampZ8wLAAAArjlbvSpJf/75p/r27auBAwdq0KBBevfddzVq1CgFBwdr+PDhkv569PqNN96or7/+WiNHjlRKSoq2bNmiWbNm6eeff3aYm3zq1KmaMmWKunbtqmnTpik4OFgbNmzQV199peuuu65CjldddZXeeOMN3X333br22ms1ZMiQM47pXM7Rno5aFUCVGPj/7f17mJV1vT/+P4czyklETgmCikLmKVJETU1JtLJMy0MeyDxkoqXuys3XI1TatlI7oKYp1i7T7JN21hJRS5GMHSmKpgaOWzk4FiCIAzj37w9/znZkoSyYmbUGHo/rWtc1677v9X6/7ndL5tl6zX0vYBN28cUXF0mKY489tnHbvHnzivbt2xdf+9rXmhz76KOPFh06dGjcvnr16mLo0KHFNttsU/z73/9ucmxDQ0Pjz6+88soa8/70pz8tkhT3339/47YpU6YUSYq5c+c2btt///2L/ffffwPOEACA1tSzZ89i/PjxJfc1NDQUw4YNK8aOHbtGXhw6dGjxwQ9+sHHbGzn1M5/5TJMxPv7xjxdbbrll4/Mrr7yySFK8+OKLa61p7ty5RZJiypQpjdvGjx9frO0jgSTFxRdf3Pj82GOPLfr27VusXr26cdv8+fOLdu3aFZMmTVqj5jfbfPPNi3Hjxq0xx4QJE4rOnTsXixcvbty2aNGiokOHDk3mBgCgeb1dXi2K1z+PTFJ861vfatxWX19f7LbbbkXfvn2LlStXFkVRFP/93/9dtGvXrvjTn/7U5PXXXnttkaR44IEHiqIoiqeeeqpo165d8fGPf7x47bXXmhz75kxc6nPQJGvUOm3atCJJMW3atKIo1v0zWlkV2BBu+Q6Q1/8y8w2/+MUv0tDQkKOOOip1dXWNj/79+2fYsGGZNm1akuRvf/tb5s6dm7PPPnuN7/J581XnXbt2bfz51VdfTV1dXfbaa68kaXLrTwAA2r5evXplxowZeeGFF9bYN2vWrDz11FP51Kc+lZdeeqkxZy5fvjwHHXRQ7r///jQ0NDR5zZtzapK8//3vz0svvZSlS5c2zpckv/zlL9d4bXM5+uijs2jRoia31fz5z3+ehoaGHH300es15oknnpj6+vr8/Oc/b9x26623ZvXq1Tn++OM3tGQAANbi7fLqGzp06JDPfvazjc87deqUz372s1m0aFFmzpyZJLntttsyYsSIDB8+vMlnqAceeGCSNH6Gescdd6ShoSEXXXRR2rVr2pJqjjt3rutntOWQVYG30lAHSDJ06NDGn5966qkURZFhw4Zlq622avKYM2dOFi1alCR55plnkmStt7h8w7/+9a984QtfSL9+/dK1a9dstdVWjfMtWbKkhc4IAIBKuPzyyzN79uwMGjQoe+65Zy655JL885//TPJ6zkyScePGrZEzf/CDH6S+vn6NfDh48OAmz7fYYoskr9+GM3m92b3PPvvklFNOSb9+/XLMMcfkZz/7WbM219/4vvdbb721cdutt96a3XbbLTvssMN6jTl8+PDsscce+clPftK47Sc/+Un22muvbL/99htcMwAApb1dXn3DwIEDs/nmmzfZ9kbumzdvXpLXs+1jjz22Rq5947g3f4barl27vPvd726R81nXz2jLIasCb+U71AHS9CryhoaG1NTU5Pe//33at2+/xrHdunUra+yjjjoqDz74YL70pS9lt912S7du3dLQ0JBDDjmkxa4iAgCgMo466qi8//3vz+23354//OEP+cY3vpH/+q//arwLUpJ84xvfyG677Vby9W/NmqXyaJIURZHk9Rx7//33Z9q0afntb3+bO++8M7feemsOPPDA/OEPf1jr68vRuXPnHH744bn99ttz9dVXZ+HChXnggQdy6aWXbtC4J554Yr7whS/kf//3f1NfX5+HHnoo3/ve9za4XgAA1u7t8uqhhx66zuM0NDRk5513zhVXXFFy/6BBg5qr5IqQVYE301AHeIvtttsuRVFk6NChb3vFzXbbbZckmT17dsaMGVPymH//+9+ZOnVqJk6cmIsuuqhx+xtXJwEAsPEZMGBAzjjjjJxxxhlZtGhR3vve9+ZrX/tarrzyyiRJjx491pof10e7du1y0EEH5aCDDsoVV1yRSy+9NOeff36mTZu21nnKvf3l0UcfnR/+8IeZOnVq5syZk6Io1ul27283zzHHHJNzzz03P/3pT7NixYp07NhxvW8hDwDAultbXn2jof7CCy9k+fLlTa5S/8c//pEkGTJkSJLXPxv9+9//noMOOuhtM992222XhoaGPP7442v9o9INsS6f0a6NrAqsK7d8B3iLI444Iu3bt8/EiRMbr/x5Q1EUeemll5Ik733vezN06NBcddVVWbx48RrHJf93RdFbx7nqqqtapngAACrmtddeW+OW7X379s3AgQNTX1+fkSNHZrvttss3v/nNLFu2bI3Xv/jii2XP+a9//WuNbW98UFlfX7/W173x4ehbc+zajBkzJr17986tt96aW2+9NXvuuWeTr016u3nWNkefPn1y6KGH5sc//nF+8pOf5JBDDkmfPn3WqR4AAMr3Tnn1DatXr873v//9xucrV67M97///Wy11VYZOXJkktevdH/++edz/fXXrzHPihUrsnz58iTJ4Ycfnnbt2mXSpElr3K3zrZ+Zro91+Yx2bWRVYF25Qh3gLbbbbrt89atfzYQJEzJv3rwcfvjh6d69e+bOnZvbb789p512Wr74xS+mXbt2ueaaa3LYYYdlt912y0knnZQBAwbkiSeeyGOPPZa77rorPXr0yH777ZfLL788q1atyrve9a784Q9/yNy5cyt9mgAANLOXX345W2+9dT7xiU9k1113Tbdu3XL33Xfn4Ycfzre+9a20a9cuP/jBD3LooYdmp512ykknnZR3vetdef755zNt2rT06NEjv/71r8uac9KkSbn//vvz4Q9/ONtss00WLVqUq6++OltvvXX23Xfftb7ujQ9CP//5z2fs2LFp3759jjnmmLUe37FjxxxxxBG55ZZbsnz58nzzm99cp/pGjhyZu+++O1dccUUGDhyYoUOHZtSoUY37TzzxxHziE59IknzlK19ZpzEBAFg/75RX3zBw4MD813/9V+bNm5cddtght956a2bNmpXrrrsuHTt2TJKccMIJ+dnPfpbTTz8906ZNyz777JPXXnstTzzxRH72s5/lrrvuyvve975sv/32Of/88/OVr3wl73//+3PEEUekc+fOefjhhzNw4MBcdtllG3RO6/IZ7drIqsC60lAHKOE///M/s8MOO+TKK6/MxIkTk7z+vT8HH3xwPvrRjzYeN3bs2EybNi0TJ07Mt771rTQ0NGS77bbLqaee2njMzTffnLPOOiuTJ09OURQ5+OCD8/vf/z4DBw5s9fMCAKDlbLbZZjnjjDPyhz/8ofE707fffvtcffXV+dznPpckOeCAAzJ9+vR85Stfyfe+970sW7Ys/fv3z6hRo/LZz3627Dk/+tGPZt68ebnxxhtTV1eXPn36ZP/998/EiRPTs2fPtb7uiCOOyFlnnZVbbrklP/7xj1MUxds21JPXb/v+gx/8IDU1NTnqqKPWqb4rrrgip512Wi644IKsWLEi48aNa/Ih5WGHHZYtttgiDQ0NTXI2AADNb13yapJsscUW+eEPf5izzjor119/ffr165fvfe97TT7zbNeuXe64445ceeWV+dGPfpTbb789m222Wbbddtt84QtfaPJVmpMmTcrQoUPz3e9+N+eff34222yz7LLLLjnhhBOa5bzW5TPaUmRVYF3VFM1xTw0AAACAMq1evToDBw7MYYcdlhtuuKHS5QAAbPIOOOCA1NXVZfbs2ZUupeJkVeANvkMdAAAAqIg77rgjL774Yk488cRKlwIAAE3IqsAb3PIdAAAAaFUzZszII488kq985SvZfffds//++1e6JAAASCKrAmtyhToAAADQqq655pp87nOfS9++ffOjH/2o0uUAAEAjWRV4K9+hDgAAAAAAAAAluEIdAAAAAAAAAErQUAcAAAAAAACAEjpUuoCW1tDQkBdeeCHdu3dPTU1NpcsBAGg2RVHk5ZdfzsCBA9Ounb+TbKvkVQBgYyWvbhzkVQBgY1ROVt3oG+ovvPBCBg0aVOkyAABazHPPPZett9660mWwnuRVAGBjJ6+2bfIqALAxW5esutE31Lt3757k9cXo0aNHhasBAGg+S5cuzaBBgxrzDm2TvAoAbKzk1Y2DvAoAbIzKyaobfUP9jdsQ9ejRQ+ADADZKbrvYtsmrAMDGTl5t2+RVAGBjti5Z1ZcXAQAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACUoKEOAAAAAAAAACVoqAMAAAAAAABACRrqAAAAAAAAAFCChjoAAAAAAAAAlKChDgAAAAAAAAAlaKgDAAAAAAAAQAka6gAAAAAAAABQgoY6AAAAAAAAAJSgoQ4AAAAAAAAAJXSodAEA/J/a2trU1dVVZO76+vp07ty51eft06dPBg8e3OrzAgBQvkrl1Upl1UReBQBoS+RVoCVoqANUidra2gwfPiIrVrxSmQJqapKiaPVpu3bdLE88MUfoAwCochXNqxXKqom8CgDQVsir8iq0FA11gCpRV1eXFSteyajPXJweA4a06tzzH52e2b+6Lrt96rxsNXR4q827dP68zLhxYurq6gQ+AIAqV6m8WqmsmsirAABtibwqr0JL0VAHqDI9BgxJ78E7tuqcS+fPS5J06zu41ecGAKBtae28KqsCAFAOeRVobu0qXQAAAAAAAAAAVCMNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAACih4g31559/Pscff3y23HLLdO3aNTvvvHP++te/Nu4viiIXXXRRBgwYkK5du2bMmDF56qmnKlgxAACbClkVAIBqJq8CALS8ijbU//3vf2efffZJx44d8/vf/z6PP/54vvWtb2WLLbZoPObyyy/Pd77znVx77bWZMWNGNt9884wdOzavvvpqBSsHAGBjJ6sCAFDN5FUAgNbRoZKT/9d//VcGDRqUKVOmNG4bOnRo489FUeSqq67KBRdckI997GNJkh/96Efp169f7rjjjhxzzDFrjFlfX5/6+vrG50uXLm3BMwA2VrW1tamrq2vVOefMmdOq8wHw9loiqybyKrDhKpFVE3kVoNrIq0C1kleBjU1FG+q/+tWvMnbs2Hzyk5/Mfffdl3e9610544wzcuqppyZJ5s6dmwULFmTMmDGNr+nZs2dGjRqV6dOnlwx9l112WSZOnNhq5wBsfGprazN8+IisWPFKReZfVb+yIvMC0FRLZNVEXgU2TKWzaiKvAlQLeRWoRvIqsDGqaEP9n//8Z6655pqce+65+f/+v/8vDz/8cD7/+c+nU6dOGTduXBYsWJAk6devX5PX9evXr3HfW02YMCHnnntu4/OlS5dm0KBBLXcSwEanrq4uK1a8klGfuTg9BgxptXnnPzo9s391XVavXt1qcwKwdi2RVRN5FdgwlcqqibwKUG3kVaAayavAxqiiDfWGhoa8733vy6WXXpok2X333TN79uxce+21GTdu3HqN2blz53Tu3Lk5ywQ2UT0GDEnvwTu22nxL589rtbkAeGctkVUTeRVoHq2dVRN5FaDayKtANZNXgY1Ju0pOPmDAgLz73e9usm3EiBGpra1NkvTv3z9JsnDhwibHLFy4sHEfAAC0BFkVAIBqJq8CALSOil6hvs8+++TJJ59ssu0f//hHttlmmyTJ0KFD079//0ydOjW77bZbktdvMTRjxox87nOfa+1ygVZWW1uburq6Vp93zpw5rT4nANVHVgXeSSXyqqwKwBvkVeCdyKsAzaOiDfVzzjkne++9dy699NIcddRR+ctf/pLrrrsu1113XZKkpqYmZ599dr761a9m2LBhGTp0aC688MIMHDgwhx9+eCVLB1pYbW1thg8fkRUrXqlYDavqV1ZsbgAqT1YF3k6l86qsCoC8CrwdeRWg+VS0ob7HHnvk9ttvz4QJEzJp0qQMHTo0V111VY477rjGY7785S9n+fLlOe2007J48eLsu+++ufPOO9OlS5cKVg60tLq6uqxY8UpGfebi9BgwpFXnnv/o9Mz+1XVZvXp1q84LQHWRVYG3U6m8KqsC8AZ5FXg78ipA86loQz1JPvKRj+QjH/nIWvfX1NRk0qRJmTRpUitWBVSLHgOGpPfgHVt1zqXz57XqfABUL1kVeCetnVdlVQDeTF4F3om8CrDh2lW6AAAAAAAAAACoRhrqAAAAAAAAAFCChjoAAAAAAAAAlKChDgAAAAAAAAAlaKgDAAAAAAAAQAka6gAAAAAAAABQgoY6AAAAAAAAAJSgoQ4AAAAAAAAAJWioAwAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACUoKEOAAAAAAAAACVoqAMAAAAAAABACRrqAAAAAAAAAFCChjoAAAAAAAAAlKChDgAAAAAAAAAlaKgDAAAAAAAAQAka6gAAAAAAAABQgoY6AAAAAAAAAJSgoQ4AAAAAAAAAJWioAwAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACUoKEOAAAAAAAAACVoqAMAAAAAAABACRrqAAAAAAAAAFCChjoAAAAAAAAAlKChDgAAAAAAAAAlaKgDAAAAAAAAQAka6gAAAAAAAABQgoY6AAAAAAAAAJSgoQ4AAAAAAAAAJWioAwAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACUoKEOAAAAAAAAACVoqAMAAAAAAABACRVtqF9yySWpqalp8hg+fHjj/ldffTXjx4/PlltumW7duuXII4/MwoULK1gxAACbEnkVAIBqJasCALSOil+hvtNOO2X+/PmNjz//+c+N+84555z8+te/zm233Zb77rsvL7zwQo444ogKVgsAwKZGXgUAoFrJqgAALa9DxQvo0CH9+/dfY/uSJUtyww035Oabb86BBx6YJJkyZUpGjBiRhx56KHvttVfJ8err61NfX9/4fOnSpS1TOAAAmwR5FQCAatXcWTWRVwEA3qriV6g/9dRTGThwYLbddtscd9xxqa2tTZLMnDkzq1atypgxYxqPHT58eAYPHpzp06evdbzLLrssPXv2bHwMGjSoxc8BAICNl7wKAEC1au6smsirAABvVdGG+qhRo3LTTTflzjvvzDXXXJO5c+fm/e9/f15++eUsWLAgnTp1Sq9evZq8pl+/flmwYMFax5wwYUKWLFnS+Hjuueda+CwAANhYyasAAFSrlsiqibwKAPBWFb3l+6GHHtr48y677JJRo0Zlm222yc9+9rN07dp1vcbs3LlzOnfu3FwlAgCwCZNXAQCoVi2RVRN5FQDgrSp+y/c369WrV3bYYYc8/fTT6d+/f1auXJnFixc3OWbhwoUlvxcIAABamrwKAEC1klUBAFpGRa9Qf6tly5blmWeeyQknnJCRI0emY8eOmTp1ao488sgkyZNPPpna2tqMHj26wpUC0JzmzJnT6nP26dMngwcPbvV5gbZNXgXYNMmrQFsgqwJsuuRVaFkVbah/8YtfzGGHHZZtttkmL7zwQi6++OK0b98+xx57bHr27JmTTz455557bnr37p0ePXrkrLPOyujRo7PXXntVsmwAmsmKJS8lqcnxxx/f6nN37bpZnnhijtAHvC15FWDTJq8C1UxWBUBehdZR0Yb6//7v/+bYY4/NSy+9lK222ir77rtvHnrooWy11VZJkiuvvDLt2rXLkUcemfr6+owdOzZXX311JUsGoBmteuXlJEV2+9R52Wro8Fabd+n8eZlx48TU1dUJfMDbklcBNm3yKlDNZFUA5FVoHRVtqN9yyy1vu79Lly6ZPHlyJk+e3EoVAVAJ3foOTu/BO1a6DIA1yKsAJPIqUJ1kVQDeIK9Cy2pX6QIAAAAAAAAAoBppqAMAAAAAAABACRrqAAAAAAAAAFCChjoAAAAAAAAAlKChDgAAAAAAAAAlaKgDAAAAAAAAQAka6gAAAAAAAABQgoY6AAAAAAAAAJSgoQ4AAAAAAAAAJWioAwAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACUoKEOAAAAAAAAACVoqAMAAAAAAABACRrqAAAAAAAAAFBCh0oXAFS/2tra1NXVteqcc+bMadX5AABomyqRVRN5FQCAdSOvArR9GurA26qtrc3w4SOyYsUrFZl/Vf3KiswLAED1q3RWTeRVAADWTl4F2DhoqANvq66uLitWvJJRn7k4PQYMabV55z86PbN/dV1Wr17danMCANC2VCqrJvIqAADvTF4F2DhoqAPrpMeAIek9eMdWm2/p/HmtNhcAAG1ba2fVRF4FAGDdyasAbVu7ShcAAAAAAAAAANVIQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAooWoa6l//+tdTU1OTs88+u3Hbq6++mvHjx2fLLbdMt27dcuSRR2bhwoWVKxIAgE2WvAoAQDWTVwEAWkZVNNQffvjhfP/7388uu+zSZPs555yTX//617ntttty33335YUXXsgRRxxRoSoBANhUyasAAFQzeRUAoOVUvKG+bNmyHHfccbn++uuzxRZbNG5fsmRJbrjhhlxxxRU58MADM3LkyEyZMiUPPvhgHnrooQpWDADApkReBQCgmsmrAAAtq+IN9fHjx+fDH/5wxowZ02T7zJkzs2rVqibbhw8fnsGDB2f69OlrHa++vj5Lly5t8gAAgPUlrwIAUM3kVQCAltWhkpPfcsst+Z//+Z88/PDDa+xbsGBBOnXqlF69ejXZ3q9fvyxYsGCtY1522WWZOHFic5cKAMAmSF4FAKCayasAAC2vYleoP/fcc/nCF76Qn/zkJ+nSpUuzjTthwoQsWbKk8fHcc88129gAAGw65FUAAKqZvAoA0Doq1lCfOXNmFi1alPe+973p0KFDOnTokPvuuy/f+c530qFDh/Tr1y8rV67M4sWLm7xu4cKF6d+//1rH7dy5c3r06NHkAQAA5ZJXAQCoZvIqAEDrqNgt3w866KA8+uijTbaddNJJGT58eM4777wMGjQoHTt2zNSpU3PkkUcmSZ588snU1tZm9OjRlSgZAIBNiLwKAEA1k1cBAFpHxRrq3bt3z3ve854m2zbffPNsueWWjdtPPvnknHvuuendu3d69OiRs846K6NHj85ee+1ViZIBANiEyKsAAFQzeRUAoHVUrKG+Lq688sq0a9cuRx55ZOrr6zN27NhcffXVlS4LAACSyKsAAFQ3eRUAYMNVVUP93nvvbfK8S5cumTx5ciZPnlyZggAA4E3kVQAAqpm8CgDQ/NpVugAAAAAAAAAAqEbr1VDfdttt89JLL62xffHixdl22203uCgAANgQ8ioAANVKVgUAaFvWq6E+b968vPbaa2tsr6+vz/PPP7/BRQEAwIaQVwEAqFayKgBA21LWd6j/6le/avz5rrvuSs+ePRufv/baa5k6dWqGDBnSbMUBAEA55FUAAKqVrAoA0DaV1VA//PDDkyQ1NTUZN25ck30dO3bMkCFD8q1vfavZigMAgHLIqwAAVCtZFQCgbSqrod7Q0JAkGTp0aB5++OH06dOnRYoCAID1Ia8CAFCtZFUAgLaprIb6G+bOndvcdQAAQLORVwEAqFayKgBA27JeDfUkmTp1aqZOnZpFixY1/nXlG2688cYNLgwAADaEvAoAQLWSVQEA2o71aqhPnDgxkyZNyvve974MGDAgNTU1zV0XAACsN3kVAIBqJasCALQt69VQv/baa3PTTTflhBNOaO56AABgg8mrAABUK1kVAKBtabc+L1q5cmX23nvv5q4FAACahbwKAEC1klUBANqW9bpC/ZRTTsnNN9+cCy+8sLnrAdaitrY2dXV1rT7vnDlzWn1OANhQ8iq0vkrkVVkVgLZIVoXKkFcBWF/r1VB/9dVXc9111+Xuu+/OLrvsko4dOzbZf8UVVzRLccDramtrM3z4iKxY8UrFalhVv7JicwNAueRVaF2VzquyKgBtiawKrU9eBWBDrFdD/ZFHHsluu+2WJJk9e3aTfTU1NRtcFNBUXV1dVqx4JaM+c3F6DBjSqnPPf3R6Zv/quqxevbpV5wWADSGvQuuqVF6VVQFoi2RVaH3yKgAbYr0a6tOmTWvuOoB10GPAkPQevGOrzrl0/rxWnQ8AmoO8CpXR2nlVVgWgLZJVoXLkVQDWR7tKFwAAAAAAAAAA1Wi9rlD/wAc+8La3H7rnnnvWuyAAANhQ8ioAANVKVgUAaFvWq6H+xnf8vGHVqlWZNWtWZs+enXHjxjVHXQAAsN7kVQAAqpWsCgDQtqxXQ/3KK68suf2SSy7JsmXLNqggAADYUPIqAADVSlYFAGhbmvU71I8//vjceOONzTkkAAA0G3kVAIBqJasCAFSnZm2oT58+PV26dGnOIQEAoNnIqwAAVCtZFQCgOq3XLd+POOKIJs+Losj8+fPz17/+NRdeeGGzFAYAAOtLXgUAoFrJqgAAbct6NdR79uzZ5Hm7du2y4447ZtKkSTn44IObpTAAAFhf8ioAANVKVgUAaFvWq6E+ZcqU5q4DAACajbwKAEC1klUBANqW9Wqov2HmzJmZM2dOkmSnnXbK7rvv3ixFAQBAc5BXAQCoVrIqAEDbsF4N9UWLFuWYY47Jvffem169eiVJFi9enA984AO55ZZbstVWWzVnjQAAUBZ5FQCAaiWrAgC0Le3W50VnnXVWXn755Tz22GP517/+lX/961+ZPXt2li5dms9//vPNXSMAAJRFXgUAoFrJqgAAbct6XaF+55135u67786IESMat7373e/O5MmTc/DBBzdbcQAAsD7kVQAAqpWsCgDQtqzXFeoNDQ3p2LHjGts7duyYhoaGDS4KAAA2hLwKAEC1klUBANqW9WqoH3jggfnCF76QF154oXHb888/n3POOScHHXRQsxUHAADrQ14FAKBayaoAAG3LejXUv/e972Xp0qUZMmRItttuu2y33XYZOnRoli5dmu9+97vNXSMAAJRFXgUAoFrJqgAAbct6fYf6oEGD8j//8z+5++6788QTTyRJRowYkTFjxjRrcQAAsD7kVQAAqpWsCgDQtpR1hfo999yTd7/73Vm6dGlqamrywQ9+MGeddVbOOuus7LHHHtlpp53ypz/9qaVqBQCAtyWvAgBQrWRVAIC2qayG+lVXXZVTTz01PXr0WGNfz54989nPfjZXXHFFsxUHAADlkFcBAKhWsioAQNtUVkP973//ew455JC17j/44IMzc+bMDS4KAADWh7wKAEC1klUBANqmsr5DfeHChenYsePaB+vQIS+++OIGFwXVrLa2NnV1da0655w5c1p1PgBoq+RVkFcBoFrJqlCZrJrIqwBsmLIa6u9617sye/bsbL/99iX3P/LIIxkwYECzFAbVqLa2NsOHj8iKFa9UZP5V9SsrMi8AtBXyKps6eRUAqpesyqau0lk1kVcBWD9lNdQ/9KEP5cILL8whhxySLl26NNm3YsWKXHzxxfnIRz6yzuNdc801ueaaazJv3rwkyU477ZSLLroohx56aJLk1VdfzX/8x3/klltuSX19fcaOHZurr746/fr1K6dsaDZ1dXVZseKVjPrMxekxYEirzTv/0emZ/avrsnr16labEwDaInmVTZ28CgDVS1ZlU1eprJrIqwBsmLIa6hdccEF+8YtfZIcddsiZZ56ZHXfcMUnyxBNPZPLkyXnttddy/vnnr/N4W2+9db7+9a9n2LBhKYoiP/zhD/Oxj30sf/vb37LTTjvlnHPOyW9/+9vcdttt6dmzZ84888wcccQReeCBB8o7S2hmPQYMSe/BO7bafEvnz2u1uQCgLZNX4XXyKgBUH1kVXtfaWTWRVwHYMGU11Pv165cHH3wwn/vc5zJhwoQURZEkqampydixYzN58uSy/sLxsMMOa/L8a1/7Wq655po89NBD2XrrrXPDDTfk5ptvzoEHHpgkmTJlSkaMGJGHHnooe+21VzmlAwCwCZBXAQCoVrIqAEDbVFZDPUm22Wab/O53v8u///3vPP300ymKIsOGDcsWW2yxQYW89tprue2227J8+fKMHj06M2fOzKpVqzJmzJjGY4YPH57Bgwdn+vTpaw199fX1qa+vb3y+dOnSDaoLAIC2RV4FAKBaVXtWTeRVAIC3Kruh/oYtttgie+yxxwYX8Oijj2b06NF59dVX061bt9x+++1597vfnVmzZqVTp07p1atXk+P79euXBQsWrHW8yy67LBMnTtzgugAAaNvkVQAAqlW1ZtVEXgUAeKt2lS5gxx13zKxZszJjxox87nOfy7hx4/L444+v93gTJkzIkiVLGh/PPfdcM1YLAMCmRl4FAKBaNXdWTeRVAIC3Wu8r1JtLp06dsv322ydJRo4cmYcffjjf/va3c/TRR2flypVZvHhxk7+kXLhwYfr377/W8Tp37pzOnTu3dNkAAGwi5FUAAKpVc2fVRF4FAHiril+h/lYNDQ2pr6/PyJEj07Fjx0ydOrVx35NPPpna2tqMHj26ghUCALApk1cBAKhWsioAQPOr6BXqEyZMyKGHHprBgwfn5Zdfzs0335x77703d911V3r27JmTTz455557bnr37p0ePXrkrLPOyujRo7PXXntVsmwANhJz5sypyLx9+vTJ4MGDKzI3UB55FYBKkleBtyOrAlBp8iqbioo21BctWpQTTzwx8+fPT8+ePbPLLrvkrrvuygc/+MEkyZVXXpl27drlyCOPTH19fcaOHZurr766kiUDsBFYseSlJDU5/vjjKzJ/166b5Ykn5gh90AbIqwBUgrwKrAtZFYBKkVfZ1FS0oX7DDTe87f4uXbpk8uTJmTx5citVBMCmYNUrLycpstunzstWQ4e36txL58/LjBsnpq6uTuCDNkBeBaAS5FVgXciqAFSKvMqmpqINdQCopG59B6f34B0rXQYAAJQkrwIAUM3kVTYV7SpdAAAAAAAAAABUIw11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBIq2lC/7LLLsscee6R79+7p27dvDj/88Dz55JNNjnn11Vczfvz4bLnllunWrVuOPPLILFy4sEIVAwCwKZFXAQCoVrIqAEDrqGhD/b777sv48ePz0EMP5Y9//GNWrVqVgw8+OMuXL2885pxzzsmvf/3r3Hbbbbnvvvvywgsv5Igjjqhg1QAAbCrkVQAAqpWsCgDQOjpUcvI777yzyfObbropffv2zcyZM7PffvtlyZIlueGGG3LzzTfnwAMPTJJMmTIlI0aMyEMPPZS99tqrEmUDALCJkFcBAKhWsioAQOuoaEP9rZYsWZIk6d27d5Jk5syZWbVqVcaMGdN4zPDhwzN48OBMnz69ZOirr69PfX194/OlS5e2cNUAUL45c+a0+px9+vTJ4MGDW31e2JjIqwBsKuRVaHuaI6sm8ioAbYO8SmuqmoZ6Q0NDzj777Oyzzz55z3vekyRZsGBBOnXqlF69ejU5tl+/flmwYEHJcS677LJMnDixpcsFgPWyYslLSWpy/PHHt/rcXbtulieemCP0wXqSVwHYFMir0DY1V1ZN5FUAqpu8SiVUTUN9/PjxmT17dv785z9v0DgTJkzIueee2/h86dKlGTRo0IaWBwDNYtUrLycpstunzstWQ4e32rxL58/LjBsnpq6uTuCD9SSvArApkFehbWqurJrIqwBUN3mVSqiKhvqZZ56Z3/zmN7n//vuz9dZbN27v379/Vq5cmcWLFzf5S8qFCxemf//+Jcfq3LlzOnfu3NIlA8AG6dZ3cHoP3rHSZQDrSF4FYFMjr0Lb0ZxZNZFXAWgb5FVaU7tKTl4URc4888zcfvvtueeeezJ06NAm+0eOHJmOHTtm6tSpjduefPLJ1NbWZvTo0a1dLgAAmxh5FQCAaiWrAgC0jopeoT5+/PjcfPPN+eUvf5nu3bs3fndPz54907Vr1/Ts2TMnn3xyzj333PTu3Ts9evTIWWedldGjR2evvfaqZOkAAGwC5FUAAKqVrAoA0Doq2lC/5pprkiQHHHBAk+1TpkzJpz/96STJlVdemXbt2uXII49MfX19xo4dm6uvvrqVKwUAYFMkrwIAUK1kVQCA1lHRhnpRFO94TJcuXTJ58uRMnjy5FSoCAID/I68CAFCtZFUAgNZR0e9QBwAAAAAAAIBqpaEOAAAAAAAAACVoqAMAAAAAAABACRrqAAAAAAAAAFCChjoAAAAAAAAAlKChDgAAAAAAAAAldKh0AbA+amtrU1dX1+rzzpkzp9XnBACg7ZFXAQCoZpXIq7IqAG2VhjptTm1tbYYPH5EVK16pWA2r6ldWbG4AAKqbvAoAQDWrdF6VVQFoazTUaXPq6uqyYsUrGfWZi9NjwJBWnXv+o9Mz+1fXZfXq1a06LwAAbYe8CgBANatUXpVVAWirNNRps3oMGJLeg3ds1TmXzp/XqvMBANB2yasAAFSz1s6rsioAbVW7ShcAAAAAAAAAANVIQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACgBA11AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASKtpQv//++3PYYYdl4MCBqampyR133NFkf1EUueiiizJgwIB07do1Y8aMyVNPPVWZYgEA2OTIqwAAVDN5FQCg5VW0ob58+fLsuuuumTx5csn9l19+eb7zne/k2muvzYwZM7L55ptn7NixefXVV1u5UgAANkXyKgAA1UxeBQBoeR0qOfmhhx6aQw89tOS+oihy1VVX5YILLsjHPvaxJMmPfvSj9OvXL3fccUeOOeaY1iwVAIBNkLwKAEA1k1cBAFpe1X6H+ty5c7NgwYKMGTOmcVvPnj0zatSoTJ8+fa2vq6+vz9KlS5s8AACgucmrAABUM3kVAKB5VG1DfcGCBUmSfv36Ndner1+/xn2lXHbZZenZs2fjY9CgQS1aJwAAmyZ5FQCAaiavAgA0j6ptqK+vCRMmZMmSJY2P5557rtIlAQBAI3kVAIBqJq8CADRVtQ31/v37J0kWLlzYZPvChQsb95XSuXPn9OjRo8kDAACam7wKAEA1k1cBAJpH1TbUhw4dmv79+2fq1KmN25YuXZoZM2Zk9OjRFawMAADkVQAAqpu8CgDQPDpUcvJly5bl6aefbnw+d+7czJo1K717987gwYNz9tln56tf/WqGDRuWoUOH5sILL8zAgQNz+OGHV65oAAA2GfIqAADVTF4FAGh5FW2o//Wvf80HPvCBxufnnntukmTcuHG56aab8uUvfznLly/PaaedlsWLF2fffffNnXfemS5dulSqZAAANiHyKgAA1UxeBQBoeRVtqB9wwAEpimKt+2tqajJp0qRMmjSpFasCAIDXyasAAFQzeRUAoOVV7XeoAwAAAAAAAEAlaagDAAAAAAAAQAka6gAAAAAAAABQgoY6AAAAAAAAAJSgoQ4AAAAAAAAAJWioAwAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACUoKEOAAAAAAAAACVoqAMAAAAAAABACRrqAAAAAAAAAFBCh0oXAAC0njlz5lRk3j59+mTw4MEVmRsAgLZDXgUAoJrJq5smDXUA2ASsWPJSkpocf/zxFZm/a9fN8sQTc4Q+AABKklcBAKhm8uqmTUMdADYBq155OUmR3T51XrYaOrxV5146f15m3DgxdXV1Ah8AACXJqwAAVDN5ddOmoQ4Am5BufQen9+AdK10GAACUJK8CAFDN5NVNU7tKFwAAAAAAAAAA1cgV6huB2tra1NXVVWTu+vr6dO7cuVXnnDNnTqvOBwDAhpFXAQCoZpXKq5XIqom8CgDl0lBv42prazN8+IisWPFKZQqoqUmKoiJTr6pfWZF5AQBYd/IqAADVrKJ5tYJZNZFXAWBdaai3cXV1dVmx4pWM+szF6TFgSKvOPf/R6Zn9q+uy26fOy1ZDh7f6vKtXr261OQEAWD/yKgAA1axSebVSWfXNc8urALBuNNQ3Ej0GDEnvwTu26pxL589LknTrO7hV535jXgAA2g55FQCAatbaebVSWfXNcwMA66ZdpQsAAAAAAAAAgGqkoQ4AAAAAAAAAJWioAwAAAAAAAEAJGuoAAAAAAAAAUIKGOgAAAAAAAACU0KHSBQAAm4Y5c+a0+px9+vTJ4MGDW31eAADaHnkVAIBqJq9WjoY6ANCiVix5KUlNjj/++Fafu2vXzfLEE3OEPgAA1kpeBQCgmsmrlaehDgC0qFWvvJykyG6fOi9bDR3eavMunT8vM26cmLq6uk0+8AEAsHbyKgAA1UxerTwNdQCgVXTrOzi9B+9Y6TIAAKAkeRUAgGomr1ZOu0oXAAAAAAAAAADVyBXqzai2tjZ1dXWtOuecOXNadT4AANoueRUAgGpViayayKsAwDvTUG8mtbW1GT58RFaseKUi86+qX1mReQEAaBvkVQAAqlWls2oirwIAa6eh3kzq6uqyYsUrGfWZi9NjwJBWm3f+o9Mz+1fXZfXq1a02JwAAbY+8CgBAtapUVk3kVQDgnWmoN7MeA4ak9+AdW22+pfPntdpcAAC0ffIqAADVqrWzaiKvAgDvrF2lCwAAAAAAAACAauQKdQBgozZnzpyKzNunT58MHjy4InMDANB2yKsAAFQzeVVDHQDYSK1Y8lKSmhx//PEVmb9r183yxBNzqib0AQBQXeRVAACqmbz6f9pEQ33y5Mn5xje+kQULFmTXXXfNd7/73ey5556VLgsAqGKrXnk5SZHdPnVetho6vFXnXjp/XmbcODF1dXVVEfhoefIqAFAueZXWJK8CAOWSV/9P1TfUb7311px77rm59tprM2rUqFx11VUZO3ZsnnzyyfTt27fS5QEAVa5b38HpPXjHSpfBRkxeBQA2hLxKS5NXAYANIa8m7SpdwDu54oorcuqpp+akk07Ku9/97lx77bXZbLPNcuONN1a6NAAAkFcBAKhq8ioAwIap6ivUV65cmZkzZ2bChAmN29q1a5cxY8Zk+vTpJV9TX1+f+vr6xudLlixJkixdurRFa122bFmS5F/PPpnV9StadK43Wzr/2STJkuefSscONa02byXnds7OeWOd2zlv/PNWcm7n3MrnvKA2yev5oCUzyBtjF0XRYnPw9uTVd+bfH+e8Mc5bybmds3PeWOd2zvIqLaOt5NVKZdVkE/03wDlv9PNWcm7n7Jw31rmd88aXV8vJqjVFFSfaF154Ie9617vy4IMPZvTo0Y3bv/zlL+e+++7LjBkz1njNJZdckokTJ7ZmmQAAFfXcc89l6623rnQZmyR5FQDgncmrlSOvAgC8vXXJqlV9hfr6mDBhQs4999zG5w0NDfnXv/6VLbfcMjU1rfvXE2+2dOnSDBo0KM8991x69OhRsTraEmtWPmtWPmtWPmtWPmtWPmu2boqiyMsvv5yBAwdWuhTKIK9uPKxZ+axZ+axZ+axZ+axZ+azZupFX2yZ5deNhzcpnzcpnzcpnzcpnzcpnzd5ZOVm1qhvqffr0Sfv27bNw4cIm2xcuXJj+/fuXfE3nzp3TuXPnJtt69erVUiWWrUePHt64ZbJm5bNm5bNm5bNm5bNm5bNm76xnz56VLmGTJq+SWLP1Yc3KZ83KZ83KZ83KZ83embxaWfIqiTVbH9asfNasfNasfNasfNbs7a1rVm3XwnVskE6dOmXkyJGZOnVq47aGhoZMnTq1yS2KAACgEuRVAACqmbwKALDhqvoK9SQ599xzM27cuLzvfe/LnnvumauuuirLly/PSSedVOnSAABAXgUAoKrJqwAAG6bqG+pHH310XnzxxVx00UVZsGBBdtttt9x5553p169fpUsrS+fOnXPxxRevcbsk1s6alc+alc+alc+alc+alc+a0ZbIq5sua1Y+a1Y+a1Y+a1Y+a1Y+a0ZbIq9uuqxZ+axZ+axZ+axZ+axZ+axZ86opiqKodBEAAAAAAAAAUG2q+jvUAQAAAAAAAKBSNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUF9HkydPzpAhQ9KlS5eMGjUqf/nLX9Z67E033ZSampomjy5dujQ55q3733h84xvfaDxmyJAha+z/+te/3mLn2NzKWbMkWbx4ccaPH58BAwakc+fO2WGHHfK73/2urDFfffXVjB8/PltuuWW6deuWI488MgsXLmz2c2spzb1ml112WfbYY4907949ffv2zeGHH54nn3yyyRgHHHDAGu+z008/vUXOryU095pdcskla6zH8OHDm4zhfdZ0zUr9W1VTU5Px48c3HtPW32dJeetW6nxramry4Q9/uPGYoihy0UUXZcCAAenatWvGjBmTp556qsk4//rXv3LcccelR48e6dWrV04++eQsW7asxc6xuTXnmq1atSrnnXdedt5552y++eYZOHBgTjzxxLzwwgtNxmnrvzthQ8ir5ZNXyyevlk9eLZ+8Wj5ZtXyyKrQ+ebV88mr55NXyyavlk1fLJ6+WT16tMgXv6JZbbik6depU3HjjjcVjjz1WnHrqqUWvXr2KhQsXljx+ypQpRY8ePYr58+c3PhYsWNDkmDfvmz9/fnHjjTcWNTU1xTPPPNN4zDbbbFNMmjSpyXHLli1r0XNtLuWuWX19ffG+972v+NCHPlT8+c9/LubOnVvce++9xaxZs8oa8/TTTy8GDRpUTJ06tfjrX/9a7LXXXsXee+/d4ufbHFpizcaOHVtMmTKlmD17djFr1qziQx/6UDF48OAm76P999+/OPXUU5u8z5YsWdLi59scWmLNLr744mKnnXZqsh4vvvhik3G8z5qu2aJFi5qs1x//+MciSTFt2rTGY9ry+6woyl+3l156qcm5zp49u2jfvn0xZcqUxmO+/vWvFz179izuuOOO4u9//3vx0Y9+tBg6dGixYsWKxmMOOeSQYtdddy0eeuih4k9/+lOx/fbbF8cee2xLn26zaO41W7x4cTFmzJji1ltvLZ544oli+vTpxZ577lmMHDmyyTht+XcnbAh5tXzyavnk1fLJq+WTV8snq5ZPVoXWJ6+WT14tn7xaPnm1fPJq+eTV8smr1UdDfR3sueeexfjx4xufv/baa8XAgQOLyy67rOTxU6ZMKXr27FnWHB/72MeKAw88sMm2bbbZprjyyivLLbcqlLtm11xzTbHtttsWK1euXO8xFy9eXHTs2LG47bbbGo+ZM2dOkaSYPn36hp5Si2uJNXurRYsWFUmK++67r3Hb/vvvX3zhC19Y77orqSXW7OKLLy523XXXte73PntnX/jCF4rtttuuaGhoaNzWlt9nRVH+ur3VlVdeWXTv3r0xfDQ0NBT9+/cvvvGNbzQes3jx4qJz587FT3/606IoiuLxxx8vkhQPP/xw4zG///3vi5qamuL5559vjtNqUc29ZqX85S9/KZIUzz77bOO2tvy7EzaEvFo+ebV88mr55NXyyavlk1XLJ6tC65NXyyevlk9eLZ+8Wj55tXzyavnk1erjlu/vYOXKlZk5c2bGjBnTuK1du3YZM2ZMpk+fvtbXLVu2LNtss00GDRqUj33sY3nsscfWeuzChQvz29/+NieffPIa+77+9a9nyy23zO67755vfOMbWb169YadUCtYnzX71a9+ldGjR2f8+PHp169f3vOe9+TSSy/Na6+9ts5jzpw5M6tWrWpyzPDhwzN48OC3/d+qGrTEmpWyZMmSJEnv3r2bbP/JT36SPn365D3veU8mTJiQV155pRnOqmW15Jo99dRTGThwYLbddtscd9xxqa2tbdznffb277OVK1fmxz/+cT7zmc+kpqamyb62+D5L1v/3wJvdcMMNOeaYY7L55psnSebOnZsFCxY0GbNnz54ZNWpU45jTp09Pr1698r73va/xmDFjxqRdu3aZMWNGc5xai2mJNStlyZIlqampSa9evZpsb4u/O2FDyKvlk1fLJ6+WT14tn7xaPlm1fLIqtD55tXzyavnk1fLJq+WTV8snr5ZPXq1OHSpdQLWrq6vLa6+9ln79+jXZ3q9fvzzxxBMlX7PjjjvmxhtvzC677JIlS5bkm9/8Zvbee+889thj2Xrrrdc4/oc//GG6d++eI444osn2z3/+83nve9+b3r1758EHH8yECRMyf/78XHHFFc13gi1gfdbsn//8Z+65554cd9xx+d3vfpenn346Z5xxRlatWpWLL754ncZcsGBBOnXqtMZ//P369cuCBQua7wRbQEus2Vs1NDTk7LPPzj777JP3vOc9jds/9alPZZtttsnAgQPzyCOP5LzzzsuTTz6ZX/ziF817ks2spdZs1KhRuemmm7Ljjjtm/vz5mThxYt7//vdn9uzZ6d69u/fZO7zP7rjjjixevDif/vSnm2xvq++zZP3W7c3+8pe/ZPbs2bnhhhsat73xXik15hv7FixYkL59+zbZ36FDh/Tu3XujfK+9Wak1e6tXX3015513Xo499tj06NGjcXtb/d0JG0JeLZ+8Wj55tXzyavnk1fLJquWTVaH1yavlk1fLJ6+WT14tn7xaPnm1fPJqddJQbwGjR4/O6NGjG5/vvffeGTFiRL7//e/nK1/5yhrH33jjjTnuuOPSpUuXJtvPPffcxp932WWXdOrUKZ/97Gdz2WWXpXPnzi13AhXQ0NCQvn375rrrrkv79u0zcuTIPP/88/nGN75R8pcK5a/Z+PHjM3v27Pz5z39usv20005r/HnnnXfOgAEDctBBB+WZZ57Jdttt1+Ln0ZrWZc0OPfTQxuN32WWXjBo1Kttss01+9rOflfwr541due+zG264IYceemgGDhzYZPum9D57qxtuuCE777xz9txzz0qX0ma805qtWrUqRx11VIqiyDXXXNNk36b0uxM2hLxaPnm1fPJq+eTV8smrG0ZWLZ+sCq1DXi2fvFo+ebV88mr55NUNI6+WT15tGW75/g769OmT9u3bZ+HChU22L1y4MP3791+nMTp27Jjdd989Tz/99Br7/vSnP+XJJ5/MKaec8o7jjBo1KqtXr868efPWad5KWZ81GzBgQHbYYYe0b9++cduIESOyYMGCrFy5cp3G7N+/f1auXJnFixev87zVoiXW7M3OPPPM/OY3v8m0adNK/hXvm40aNSpJSr5fq0lLr9kbevXqlR122KFxPbzP1r5mzz77bO6+++51/vcsqf73WbJhvweWL1+eW265ZY3/s/DG697p37RFixY12b969er861//2ijfa29Y25q94Y3A9+yzz+aPf/xjk7+gLKWt/O6EDSGvlk9eLZ+8Wj55tXzyavlk1fLJqtD65NXyyavlk1fLJ6+WT14tn7xaPnm1Ommov4NOnTpl5MiRmTp1auO2hoaGTJ06tclfSb6d1157LY8++mgGDBiwxr4bbrghI0eOzK677vqO48yaNSvt2rVb4zYV1WZ91myfffbJ008/nYaGhsZt//jHPzJgwIB06tRpncYcOXJkOnbs2OSYJ598MrW1tev8v1WltMSaJUlRFDnzzDNz++2355577snQoUPfsZZZs2YlScn3azVpqTV7q2XLluWZZ55pXA/vs7Wv2ZQpU9K3b998+MMffsda2sr7LNmw3wO33XZb6uvrc/zxxzfZPnTo0PTv37/JmEuXLs2MGTMaxxw9enQWL16cmTNnNh5zzz33pKGhoTEwV6uWWLPk/wLfU089lbvvvjtbbrnlO9bSVn53woaQV8snr5ZPXi2fvFo+ebV8smr5ZFVoffJq+eTV8smr5ZNXyyevlk9eLZ+8WqUK3tEtt9xSdO7cubjpppuKxx9/vDjttNOKXr16FQsWLCiKoihOOOGE4j//8z8bj584cWJx1113Fc8880wxc+bM4phjjim6dOlSPPbYY03GXbJkSbHZZpsV11xzzRpzPvjgg8WVV15ZzJo1q3jmmWeKH//4x8VWW21VnHjiiS17ss2k3DWrra0tunfvXpx55pnFk08+WfzmN78p+vbtW3z1q19d5zGLoihOP/30YvDgwcU999xT/PWvfy1Gjx5djB49uvVOfAO0xJp97nOfK3r27Fnce++9xfz58xsfr7zySlEURfH0008XkyZNKv76178Wc+fOLX75y18W2267bbHffvu17smvp5ZYs//4j/8o7r333mLu3LnFAw88UIwZM6bo06dPsWjRosZjvM+arllRFMVrr71WDB48uDjvvPPWmLOtv8+Kovx1e8O+++5bHH300SXH/PrXv1706tWr+OUvf1k88sgjxcc+9rFi6NChxYoVKxqPOeSQQ4rdd9+9mDFjRvHnP/+5GDZsWHHssce2zEk2s+Zes5UrVxYf/ehHi6233rqYNWtWk3/T6uvri6Jo+787YUPIq+WTV8snr5ZPXi2fvFo+WbV8siq0Pnm1fPJq+eTV8smr5ZNXyyevlk9erT4a6uvou9/9bjF48OCiU6dOxZ577lk89NBDjfv233//Yty4cY3Pzz777MZj+/XrV3zoQx8q/ud//meNMb///e8XXbt2LRYvXrzGvpkzZxajRo0qevbsWXTp0qUYMWJEcemllxavvvpqi5xfSyhnzYri9f9YR40aVXTu3LnYdttti6997WvF6tWr13nMoiiKFStWFGeccUaxxRZbFJtttlnx8Y9/vJg/f36LnWNza+41S1LyMWXKlKIoXv9lvt9++xW9e/cuOnfuXGy//fbFl770pWLJkiWtcbrNornX7Oijjy4GDBhQdOrUqXjXu95VHH300cXTTz/dZAzvszX/27zrrruKJMWTTz65xnwbw/usKMpftyeeeKJIUvzhD38oOV5DQ0Nx4YUXFv369Ss6d+5cHHTQQWus30svvVQce+yxRbdu3YoePXoUJ510UvHyyy83+7m1lOZcs7lz567137Rp06YVRbFx/O6EDSGvlk9eLZ+8Wj55tXzyavlk1fLJqtD65NXyyavlk1fLJ6+WT14tn7xaPnm1utQURVG0yKXvAAAAAAAAANCG+Q51AAAAAAAAAChBQx0AAAAAAAAAStBQBwAAAAAAAIASNNQBAAAAAAAAoAQNdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXWACrrkkkuy2267NT7/9Kc/ncMPP7xi9QAAsPG59957U1NTk8WLF7/tcUOGDMlVV121zuMecMABOfvsszeoNgAASNb8XLQoipx22mnp3bt3ampqMmvWrLLy57pmYIB10aHSBQAAAAAtZ++99878+fPTs2fPJMlNN92Us88+e40PFx9++OFsvvnm6zzuL37xi3Ts2LHx+ZAhQ3L22WdrsgMAULZvf/vbKYqi8fmdd96Zm266Kffee2+23Xbb9OnTZ438+XbWNQMDrAsNdYC1WLlyZTp16lTpMgAAYIN06tQp/fv3f8fjttpqq7LG7d279/qWBAAATbzR+H7DM888kwEDBmTvvfdu3FZO/lzXDAywLtzyHeD/74ADDsiZZ56Zs88+O3369MnYsWMze/bsHHrooenWrVv69euXE044IXV1dY2vaWhoyOWXX57tt98+nTt3zuDBg/O1r32tcf95552XHXbYIZtttlm23XbbXHjhhVm1alUlTg8AgAr7+c9/np133jldu3bNlltumTFjxmT58uVJkh/84AcZMWJEunTpkuHDh+fqq69ufN28efNSU1OTX/ziF/nABz6QzTbbLLvuumumT5/eeMyzzz6bww47LFtssUU233zz7LTTTvnd736XpOntLu+9996cdNJJWbJkSWpqalJTU5NLLrkkSdNbvn/qU5/K0Ucf3aT+VatWpU+fPvnRj36UpOkt3w844IA8++yzOeeccxrHXb58eXr06JGf//znTca54447svnmm+fll19utrUFAGDDrS2vvnE79okTJ2arrbZKjx49cvrpp2flypWNr21oaMhll12WoUOHpmvXrtl1113XyIGPPfZYPvKRj6RHjx7p3r173v/+9+eZZ55J0vSW75/+9Kdz1llnpba2NjU1NRkyZEiSNb9yqL6+Puedd14GDRqUzp07Z/vtt88NN9yQZN0y8KRJk/Ke97xnjXXYbbfdcuGFFzbjygJtnSvUAd7khz/8YT73uc/lgQceyOLFi3PggQfmlFNOyZVXXpkVK1bkvPPOy1FHHZV77rknSTJhwoRcf/31ufLKK7Pvvvtm/vz5eeKJJxrH6969e2666aYMHDgwjz76aE499dR07949X/7ylyt1igAAVMD8+fNz7LHH5vLLL8/HP/7xvPzyy/nTn/6Uoijyk5/8JBdddFG+973vZffdd8/f/va3nHrqqdl8880zbty4xjHOP//8fPOb38ywYcNy/vnn59hjj83TTz+dDh06ZPz48Vm5cmXuv//+bL755nn88cfTrVu3NerYe++9c9VVV+Wiiy7Kk08+mSQljzvuuOPyyU9+MsuWLWvcf9ddd+WVV17Jxz/+8TWO/8UvfpFdd901p512Wk499dQkyeabb55jjjkmU6ZMySc+8YnGY9943r179w1bVAAAms3b5dUkmTp1arp06ZJ777038+bNy0knnZQtt9yy8eKiyy67LD/+8Y9z7bXXZtiwYbn//vtz/PHHZ6uttsr++++f559/Pvvtt18OOOCA3HPPPenRo0ceeOCBrF69eo1avv3tb2e77bbLddddl4cffjjt27cvWfOJJ56Y6dOn5zvf+U523XXXzJ07t8nFUG9YWwZevHhxJk6cmIcffjh77LFHkuRvf/tbHnnkkfziF79olnUFNg4a6gBvMmzYsFx++eVJkq9+9avZfffdc+mllzbuv/HGGzNo0KD84x//yIABA/Ltb3873/ve9xo/6Nxuu+2y7777Nh5/wQUXNP48ZMiQfPGLX8wtt9yioQ4AsImZP39+Vq9enSOOOCLbbLNNkmTnnXdOklx88cX51re+lSOOOCJJMnTo0Dz++OP5/ve/36Sh/sUvfjEf/vCHkyQTJ07MTjvtlKeffjrDhw9PbW1tjjzyyMYxt91225J1dOrUKT179kxNTc3b3gJz7Nix2XzzzXP77bfnhBNOSJLcfPPN+ehHP1qyEd67d++0b98+3bt3bzLuKaec0vj9lQMGDMiiRYvyu9/9Lnffffc6rx0AAC3v7fJq8nqOvPHGG7PZZptlp512yqRJk/KlL30pX/nKV7Jq1apceumlufvuuzN69Ogkr+fRP//5z/n+97+f/fffP5MnT07Pnj1zyy23NH4P+g477FCylp49e6Z79+5p3779WjPrP/7xj/zsZz/LH//4x4wZM6ZxzlLWloG7deuWsWPHZsqUKY0N9SlTpmT//fdf61jApskt3wHeZOTIkY0///3vf8+0adPSrVu3xsfw4cOTvP4dPnPmzEl9fX0OOuigtY536623Zp999kn//v3TrVu3XHDBBamtrW3x8wAAoLrsuuuuOeigg7Lzzjvnk5/8ZK6//vr8+9//zvLly/PMM8/k5JNPbpI7v/rVrzbe/vINu+yyS+PPAwYMSJIsWrQoSfL5z38+X/3qV7PPPvvk4osvziOPPLJB9Xbo0CFHHXVUfvKTnyRJli9fnl/+8pc57rjjyhpnzz33zE477ZQf/vCHSZIf//jH2WabbbLffvttUH0AADSvteXVN+/fbLPNGp+PHj06y5Yty3PPPZenn346r7zySj74wQ82ybQ/+tGPGjPtrFmz8v73v7+xmb6hZs2alfbt22f//fffoHFOPfXU/PSnP82rr76alStX5uabb85nPvOZZqkR2HhoqAO8yeabb97487Jly3LYYYdl1qxZTR5PPfVU9ttvv3Tt2vVtx5o+fXqOO+64fOhDH8pvfvOb/O1vf8v555/f5LuFAADYNLRv3z5//OMf8/vf/z7vfve7893vfjc77rhjZs+enSS5/vrrm2TO2bNn56GHHmoyxps/fKypqUny+ndVJq9fCf7Pf/4zJ5xwQh599NG8733vy3e/+90Nqvm4447L1KlTs2jRotxxxx3p2rVrDjnkkLLHOeWUU3LTTTclef2Kn5NOOqmxfgAAqsPa8urcuXPf8bXLli1Lkvz2t79tkmkff/zxxu9Rf6fPUsvVXOMddthh6dy5c26//fb8+te/zqpVq5p8XRFA4pbvAGv13ve+N//v//2/DBkyJB06rPnP5bBhw9K1a9dMnTo1p5xyyhr7H3zwwWyzzTY5//zzG7c9++yzLVozAADVq6amJvvss0/22WefXHTRRdlmm23ywAMPZODAgfnnP/9Z9tXfbzVo0KCcfvrpOf300zNhwoRcf/31Oeuss9Y4rlOnTnnttdfecby99947gwYNyq233prf//73+eQnP/m2VxStbdzjjz8+X/7yl/Od73wnjz/+eJPb2AMAUD1K5dXbb789yet381yxYkVjI/uhhx5Kt27dMmjQoPTu3TudO3dObW3tWq8Y32WXXfLDH/4wq1atapar1Hfeeec0NDTkvvvua7zl+9tZW1bt0KFDxo0blylTpqRTp0455phjmr35D7R9GuoAazF+/Phcf/31OfbYY/PlL385vXv3ztNPP51bbrklP/jBD9KlS5ecd955+fKXv5xOnTpln332yYsvvpjHHnssJ598coYNG5ba2trccsst2WOPPfLb3/62MYACALBpmTFjRqZOnZqDDz44ffv2zYwZM/Liiy9mxIgRmThxYj7/+c+nZ8+eOeSQQ1JfX5+//vWv+fe//51zzz13ncY/++yzc+ihh2aHHXbIv//970ybNi0jRowoeeyQIUOybNmyTJ06tfHWnW++feebfepTn8q1116bf/zjH5k2bdrb1jBkyJDcf//9OeaYY9K5c+f06dMnSbLFFlvkiCOOyJe+9KUcfPDB2XrrrdfpnAAAaD1vl1cfeeSRrFy5MieffHIuuOCCzJs3LxdffHHOPPPMtGvXLt27d88Xv/jFnHPOOWloaMi+++6bJUuW5IEHHkiPHj0ybty4nHnmmfnud7+bY445JhMmTEjPnj3z0EMPZc8998yOO+5Ydr1DhgzJuHHj8pnPfCbf+c53suuuu+bZZ5/NokWLctRRR5U8fm0Z+JRTTmnMzg888MCGLSSwUXLLd4C1GDhwYB544IG89tprOfjgg7Pzzjvn7LPPTq9evdKu3ev/fF544YX5j//4j1x00UUZMWJEjj766MbvsfzoRz+ac845J2eeeWZ22223PPjgg7nwwgsreUoAAFRIjx49cv/99+dDH/pQdthhh1xwwQX51re+lUMPPTSnnHJKfvCDH2TKlCnZeeeds//+++emm27K0KFD13n81157LePHj8+IESNyyCGHZIcddsjVV19d8ti99947p59+eo4++uhstdVWufzyy9c67nHHHZfHH38873rXu7LPPvu8bQ2TJk3KvHnzst1222WrrbZqsu/kk0/OypUrfR8lAECVeru8miQHHXRQhg0blv322y9HH310PvrRj+aSSy5pfP1XvvKVXHjhhbnssssaM+lvf/vbxky75ZZb5p577smyZcuy//77Z+TIkbn++us36Gr1a665Jp/4xCdyxhlnZPjw4Tn11FOzfPnykse+XQYeNmxY9t577wwfPjyjRo1a73qAjVdNURRFpYsAAAAANl7//d//nXPOOScvvPBCOnXqVOlyAAAow6c//eksXrw4d9xxR6VLaRFFUWTYsGE544wz1vkOUcCmxS3fAQAAgBbxyiuvZP78+fn617+ez372s5rpAABUlRdffDG33HJLFixYkJNOOqnS5QBVyi3fAQAAgBZx+eWXZ/jw4enfv38mTJhQ6XIAAKCJvn37ZtKkSbnuuuuyxRZbVLocoEq55TsAAAAAAAAAlOAKdQAAAAAAAAAoQUMdAAAAAAAAAErQUAcAAAAAAACAEjTUAQAAAAAAAKAEDXUAAAAAAAAAKEFDHQAAAAAAAABK0FAHAAAAAAAAgBI01AEAAAAAAACghP8fkvaiJHHMPRUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2500x2500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.647393</td>\n",
       "      <td>0.644096</td>\n",
       "      <td>0.656294</td>\n",
       "      <td>0.657999</td>\n",
       "      <td>0.657999</td>\n",
       "      <td>0.657999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.02846</td>\n",
       "      <td>0.02846</td>\n",
       "      <td>0.02846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.541231</td>\n",
       "      <td>0.541052</td>\n",
       "      <td>0.573702</td>\n",
       "      <td>0.57226</td>\n",
       "      <td>0.57226</td>\n",
       "      <td>0.57226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.624537</td>\n",
       "      <td>0.620571</td>\n",
       "      <td>0.639306</td>\n",
       "      <td>0.637672</td>\n",
       "      <td>0.637672</td>\n",
       "      <td>0.637672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.648303</td>\n",
       "      <td>0.647092</td>\n",
       "      <td>0.659103</td>\n",
       "      <td>0.660245</td>\n",
       "      <td>0.660245</td>\n",
       "      <td>0.660245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.670813</td>\n",
       "      <td>0.668615</td>\n",
       "      <td>0.674985</td>\n",
       "      <td>0.677469</td>\n",
       "      <td>0.677469</td>\n",
       "      <td>0.677469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.742488</td>\n",
       "      <td>0.73874</td>\n",
       "      <td>0.737823</td>\n",
       "      <td>0.740416</td>\n",
       "      <td>0.740416</td>\n",
       "      <td>0.740416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max file</th>\n",
       "      <td>ex-division330</td>\n",
       "      <td>ex-division330</td>\n",
       "      <td>ex-division330</td>\n",
       "      <td>ex-division330</td>\n",
       "      <td>ex-division330</td>\n",
       "      <td>ex-division330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy        f1-score       precision          recall  \\\n",
       "count              500.0           500.0           500.0           500.0   \n",
       "mean            0.647393        0.644096        0.656294        0.657999   \n",
       "std             0.032143        0.031651        0.026504         0.02846   \n",
       "min             0.541231        0.541052        0.573702         0.57226   \n",
       "25%             0.624537        0.620571        0.639306        0.637672   \n",
       "50%             0.648303        0.647092        0.659103        0.660245   \n",
       "75%             0.670813        0.668615        0.674985        0.677469   \n",
       "max             0.742488         0.73874        0.737823        0.740416   \n",
       "max file  ex-division330  ex-division330  ex-division330  ex-division330   \n",
       "\n",
       "             sensitivity     specificity  \n",
       "count              500.0           500.0  \n",
       "mean            0.657999        0.657999  \n",
       "std              0.02846         0.02846  \n",
       "min              0.57226         0.57226  \n",
       "25%             0.637672        0.637672  \n",
       "50%             0.660245        0.660245  \n",
       "75%             0.677469        0.677469  \n",
       "max             0.740416        0.740416  \n",
       "max file  ex-division330  ex-division330  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infl</th>\n",
       "      <th>nc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>infl</th>\n",
       "      <td>24752</td>\n",
       "      <td>8032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc</th>\n",
       "      <td>6752</td>\n",
       "      <td>17875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       infl     nc\n",
       "infl  24752   8032\n",
       "nc     6752  17875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid_nonr\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x2500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.722533</td>\n",
       "      <td>0.707004</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.722533</td>\n",
       "      <td>0.722533</td>\n",
       "      <td>0.722533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.060715</td>\n",
       "      <td>0.071552</td>\n",
       "      <td>0.054946</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>0.060715</td>\n",
       "      <td>0.060715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.484444</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.667735</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.706812</td>\n",
       "      <td>0.779503</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.899554</td>\n",
       "      <td>0.90724</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max file</th>\n",
       "      <td>ex-division79</td>\n",
       "      <td>ex-division79</td>\n",
       "      <td>ex-division79</td>\n",
       "      <td>ex-division79</td>\n",
       "      <td>ex-division79</td>\n",
       "      <td>ex-division79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy       f1-score      precision         recall  \\\n",
       "count             500.0          500.0          500.0          500.0   \n",
       "mean           0.722533       0.707004       0.772973       0.722533   \n",
       "std            0.060715       0.071552       0.054946       0.060715   \n",
       "min            0.516667       0.484444       0.522222       0.516667   \n",
       "25%            0.683333       0.667735       0.738095       0.683333   \n",
       "50%            0.716667       0.706812       0.779503       0.716667   \n",
       "75%            0.766667           0.76         0.8125       0.766667   \n",
       "max                 0.9       0.899554        0.90724            0.9   \n",
       "max file  ex-division79  ex-division79  ex-division79  ex-division79   \n",
       "\n",
       "            sensitivity    specificity  \n",
       "count             500.0          500.0  \n",
       "mean           0.722533       0.722533  \n",
       "std            0.060715       0.060715  \n",
       "min            0.516667       0.516667  \n",
       "25%            0.683333       0.683333  \n",
       "50%            0.716667       0.716667  \n",
       "75%            0.766667       0.766667  \n",
       "max                 0.9            0.9  \n",
       "max file  ex-division79  ex-division79  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>infl</th>\n",
       "      <th>nc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>infl</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      infl  nc\n",
       "infl    25   5\n",
       "nc       1  29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbmtools.calc_save_ave_2class_maxf1(experiment_dir, labels, target_label='macro avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432dbe83-2561-4eaf-850d-49bd36d4551a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13688, number of negative: 13688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116151\n",
      "[LightGBM] [Info] Number of data points in the train set: 27376, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.456644\n",
      "[LightGBM] [Info] Number of positive: 10850, number of negative: 10850\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116141\n",
      "[LightGBM] [Info] Number of data points in the train set: 21700, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.45529\n",
      "[LightGBM] [Info] Number of positive: 11079, number of negative: 11079\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115917\n",
      "[LightGBM] [Info] Number of data points in the train set: 22158, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's binary_logloss: 0.541016\n",
      "[LightGBM] [Info] Number of positive: 9586, number of negative: 9586\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115879\n",
      "[LightGBM] [Info] Number of data points in the train set: 19172, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.482426\n",
      "[LightGBM] [Info] Number of positive: 8942, number of negative: 8942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115949\n",
      "[LightGBM] [Info] Number of data points in the train set: 17884, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.512158\n",
      "[LightGBM] [Info] Number of positive: 10820, number of negative: 10820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115919\n",
      "[LightGBM] [Info] Number of data points in the train set: 21640, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.548997\n",
      "[LightGBM] [Info] Number of positive: 10224, number of negative: 10224\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116001\n",
      "[LightGBM] [Info] Number of data points in the train set: 20448, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's binary_logloss: 0.55912\n",
      "[LightGBM] [Info] Number of positive: 10230, number of negative: 10229\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115977\n",
      "[LightGBM] [Info] Number of data points in the train set: 20459, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000098\n",
      "[LightGBM] [Info] Start training from score 0.000098\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.496626\n",
      "[LightGBM] [Info] Number of positive: 8738, number of negative: 8738\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115733\n",
      "[LightGBM] [Info] Number of data points in the train set: 17476, number of used features: 472\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.578232\n",
      "[LightGBM] [Info] Number of positive: 10742, number of negative: 10742\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116004\n",
      "[LightGBM] [Info] Number of data points in the train set: 21484, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.523498\n",
      "[LightGBM] [Info] Number of positive: 9911, number of negative: 9911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115975\n",
      "[LightGBM] [Info] Number of data points in the train set: 19822, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.504836\n",
      "[LightGBM] [Info] Number of positive: 10412, number of negative: 10412\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116027\n",
      "[LightGBM] [Info] Number of data points in the train set: 20824, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.487568\n",
      "[LightGBM] [Info] Number of positive: 10542, number of negative: 10541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115916\n",
      "[LightGBM] [Info] Number of data points in the train set: 21083, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000095\n",
      "[LightGBM] [Info] Start training from score 0.000095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.494433\n",
      "[LightGBM] [Info] Number of positive: 8566, number of negative: 8566\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115927\n",
      "[LightGBM] [Info] Number of data points in the train set: 17132, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.507877\n",
      "[LightGBM] [Info] Number of positive: 11372, number of negative: 11372\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116111\n",
      "[LightGBM] [Info] Number of data points in the train set: 22744, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.462941\n",
      "[LightGBM] [Info] Number of positive: 10280, number of negative: 10280\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115940\n",
      "[LightGBM] [Info] Number of data points in the train set: 20560, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.478665\n",
      "[LightGBM] [Info] Number of positive: 11046, number of negative: 11045\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116036\n",
      "[LightGBM] [Info] Number of data points in the train set: 22091, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000091\n",
      "[LightGBM] [Info] Start training from score 0.000091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.508849\n",
      "[LightGBM] [Info] Number of positive: 11747, number of negative: 11747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116037\n",
      "[LightGBM] [Info] Number of data points in the train set: 23494, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.529003\n",
      "[LightGBM] [Info] Number of positive: 10033, number of negative: 10032\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115858\n",
      "[LightGBM] [Info] Number of data points in the train set: 20065, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's binary_logloss: 0.56388\n",
      "[LightGBM] [Info] Number of positive: 8115, number of negative: 8115\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115910\n",
      "[LightGBM] [Info] Number of data points in the train set: 16230, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's binary_logloss: 0.496712\n",
      "[LightGBM] [Info] Number of positive: 14660, number of negative: 14660\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116206\n",
      "[LightGBM] [Info] Number of data points in the train set: 29320, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.443652\n",
      "[LightGBM] [Info] Number of positive: 10827, number of negative: 10827\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115949\n",
      "[LightGBM] [Info] Number of data points in the train set: 21654, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.558578\n",
      "[LightGBM] [Info] Number of positive: 11810, number of negative: 11810\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116078\n",
      "[LightGBM] [Info] Number of data points in the train set: 23620, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.48963\n",
      "[LightGBM] [Info] Number of positive: 8625, number of negative: 8624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115984\n",
      "[LightGBM] [Info] Number of data points in the train set: 17249, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500029 -> initscore=0.000116\n",
      "[LightGBM] [Info] Start training from score 0.000116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's binary_logloss: 0.472599\n",
      "[LightGBM] [Info] Number of positive: 12762, number of negative: 12761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116081\n",
      "[LightGBM] [Info] Number of data points in the train set: 25523, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.527966\n",
      "[LightGBM] [Info] Number of positive: 10203, number of negative: 10203\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116014\n",
      "[LightGBM] [Info] Number of data points in the train set: 20406, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.516953\n",
      "[LightGBM] [Info] Number of positive: 9778, number of negative: 9778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115814\n",
      "[LightGBM] [Info] Number of data points in the train set: 19556, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's binary_logloss: 0.568946\n",
      "[LightGBM] [Info] Number of positive: 14344, number of negative: 14344\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116155\n",
      "[LightGBM] [Info] Number of data points in the train set: 28688, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.468195\n",
      "[LightGBM] [Info] Number of positive: 12817, number of negative: 12816\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116140\n",
      "[LightGBM] [Info] Number of data points in the train set: 25633, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.459073\n",
      "[LightGBM] [Info] Number of positive: 10933, number of negative: 10932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116043\n",
      "[LightGBM] [Info] Number of data points in the train set: 21865, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000091\n",
      "[LightGBM] [Info] Start training from score 0.000091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's binary_logloss: 0.522389\n",
      "[LightGBM] [Info] Number of positive: 11883, number of negative: 11883\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115958\n",
      "[LightGBM] [Info] Number of data points in the train set: 23766, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's binary_logloss: 0.542444\n",
      "[LightGBM] [Info] Number of positive: 10419, number of negative: 10419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115977\n",
      "[LightGBM] [Info] Number of data points in the train set: 20838, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.535813\n",
      "[LightGBM] [Info] Number of positive: 13582, number of negative: 13581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116115\n",
      "[LightGBM] [Info] Number of data points in the train set: 27163, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000074\n",
      "[LightGBM] [Info] Start training from score 0.000074\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's binary_logloss: 0.523805\n",
      "[LightGBM] [Info] Number of positive: 11234, number of negative: 11234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115980\n",
      "[LightGBM] [Info] Number of data points in the train set: 22468, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.507251\n",
      "[LightGBM] [Info] Number of positive: 12906, number of negative: 12906\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116111\n",
      "[LightGBM] [Info] Number of data points in the train set: 25812, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.528674\n",
      "[LightGBM] [Info] Number of positive: 8097, number of negative: 8096\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115927\n",
      "[LightGBM] [Info] Number of data points in the train set: 16193, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500031 -> initscore=0.000124\n",
      "[LightGBM] [Info] Start training from score 0.000124\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.482196\n",
      "[LightGBM] [Info] Number of positive: 10494, number of negative: 10493\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115955\n",
      "[LightGBM] [Info] Number of data points in the train set: 20987, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000095\n",
      "[LightGBM] [Info] Start training from score 0.000095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.51996\n",
      "[LightGBM] [Info] Number of positive: 14233, number of negative: 14232\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116057\n",
      "[LightGBM] [Info] Number of data points in the train set: 28465, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's binary_logloss: 0.579934\n",
      "[LightGBM] [Info] Number of positive: 8446, number of negative: 8446\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115921\n",
      "[LightGBM] [Info] Number of data points in the train set: 16892, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.457692\n",
      "[LightGBM] [Info] Number of positive: 11678, number of negative: 11677\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116011\n",
      "[LightGBM] [Info] Number of data points in the train set: 23355, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000086\n",
      "[LightGBM] [Info] Start training from score 0.000086\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's binary_logloss: 0.534474\n",
      "[LightGBM] [Info] Number of positive: 8903, number of negative: 8903\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115909\n",
      "[LightGBM] [Info] Number of data points in the train set: 17806, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.461671\n",
      "[LightGBM] [Info] Number of positive: 11854, number of negative: 11854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116112\n",
      "[LightGBM] [Info] Number of data points in the train set: 23708, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's binary_logloss: 0.488188\n",
      "[LightGBM] [Info] Number of positive: 9082, number of negative: 9081\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115927\n",
      "[LightGBM] [Info] Number of data points in the train set: 18163, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500028 -> initscore=0.000110\n",
      "[LightGBM] [Info] Start training from score 0.000110\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.559052\n",
      "[LightGBM] [Info] Number of positive: 10316, number of negative: 10316\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116058\n",
      "[LightGBM] [Info] Number of data points in the train set: 20632, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's binary_logloss: 0.482911\n",
      "[LightGBM] [Info] Number of positive: 8540, number of negative: 8540\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115891\n",
      "[LightGBM] [Info] Number of data points in the train set: 17080, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's binary_logloss: 0.522181\n",
      "[LightGBM] [Info] Number of positive: 8422, number of negative: 8422\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115916\n",
      "[LightGBM] [Info] Number of data points in the train set: 16844, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's binary_logloss: 0.563432\n",
      "[LightGBM] [Info] Number of positive: 10261, number of negative: 10260\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116053\n",
      "[LightGBM] [Info] Number of data points in the train set: 20521, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000097\n",
      "[LightGBM] [Info] Start training from score 0.000097\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.495877\n",
      "[LightGBM] [Info] Number of positive: 14185, number of negative: 14184\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116064\n",
      "[LightGBM] [Info] Number of data points in the train set: 28369, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000070\n",
      "[LightGBM] [Info] Start training from score 0.000070\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.49254\n",
      "[LightGBM] [Info] Number of positive: 8619, number of negative: 8619\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115900\n",
      "[LightGBM] [Info] Number of data points in the train set: 17238, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.461559\n",
      "[LightGBM] [Info] Number of positive: 10638, number of negative: 10637\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115947\n",
      "[LightGBM] [Info] Number of data points in the train set: 21275, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000094\n",
      "[LightGBM] [Info] Start training from score 0.000094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's binary_logloss: 0.549842\n",
      "[LightGBM] [Info] Number of positive: 11138, number of negative: 11137\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115853\n",
      "[LightGBM] [Info] Number of data points in the train set: 22275, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000090\n",
      "[LightGBM] [Info] Start training from score 0.000090\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's binary_logloss: 0.543374\n",
      "[LightGBM] [Info] Number of positive: 9382, number of negative: 9382\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115813\n",
      "[LightGBM] [Info] Number of data points in the train set: 18764, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.571653\n",
      "[LightGBM] [Info] Number of positive: 13004, number of negative: 13004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116088\n",
      "[LightGBM] [Info] Number of data points in the train set: 26008, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.56326\n",
      "[LightGBM] [Info] Number of positive: 11349, number of negative: 11348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115842\n",
      "[LightGBM] [Info] Number of data points in the train set: 22697, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000088\n",
      "[LightGBM] [Info] Start training from score 0.000088\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's binary_logloss: 0.568896\n",
      "[LightGBM] [Info] Number of positive: 8075, number of negative: 8075\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115960\n",
      "[LightGBM] [Info] Number of data points in the train set: 16150, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's binary_logloss: 0.449132\n",
      "[LightGBM] [Info] Number of positive: 7454, number of negative: 7454\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115818\n",
      "[LightGBM] [Info] Number of data points in the train set: 14908, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's binary_logloss: 0.469773\n",
      "[LightGBM] [Info] Number of positive: 10770, number of negative: 10770\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116022\n",
      "[LightGBM] [Info] Number of data points in the train set: 21540, number of used features: 476\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.5358\n",
      "[LightGBM] [Info] Number of positive: 13270, number of negative: 13269\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115993\n",
      "[LightGBM] [Info] Number of data points in the train set: 26539, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000075\n",
      "[LightGBM] [Info] Start training from score 0.000075\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's binary_logloss: 0.567656\n",
      "[LightGBM] [Info] Number of positive: 10813, number of negative: 10812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116050\n",
      "[LightGBM] [Info] Number of data points in the train set: 21625, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000092\n",
      "[LightGBM] [Info] Start training from score 0.000092\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's binary_logloss: 0.504534\n",
      "[LightGBM] [Info] Number of positive: 9658, number of negative: 9658\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116071\n",
      "[LightGBM] [Info] Number of data points in the train set: 19316, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.49898\n",
      "[LightGBM] [Info] Number of positive: 12786, number of negative: 12785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116055\n",
      "[LightGBM] [Info] Number of data points in the train set: 25571, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's binary_logloss: 0.488536\n",
      "[LightGBM] [Info] Number of positive: 9673, number of negative: 9672\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115998\n",
      "[LightGBM] [Info] Number of data points in the train set: 19345, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000103\n",
      "[LightGBM] [Info] Start training from score 0.000103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's binary_logloss: 0.56439\n",
      "[LightGBM] [Info] Number of positive: 10948, number of negative: 10948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116076\n",
      "[LightGBM] [Info] Number of data points in the train set: 21896, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's binary_logloss: 0.469601\n",
      "[LightGBM] [Info] Number of positive: 10651, number of negative: 10651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115942\n",
      "[LightGBM] [Info] Number of data points in the train set: 21302, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.495884\n",
      "[LightGBM] [Info] Number of positive: 9573, number of negative: 9572\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115841\n",
      "[LightGBM] [Info] Number of data points in the train set: 19145, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000104\n",
      "[LightGBM] [Info] Start training from score 0.000104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.559426\n",
      "[LightGBM] [Info] Number of positive: 10716, number of negative: 10716\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115955\n",
      "[LightGBM] [Info] Number of data points in the train set: 21432, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's binary_logloss: 0.509272\n",
      "[LightGBM] [Info] Number of positive: 11426, number of negative: 11425\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116035\n",
      "[LightGBM] [Info] Number of data points in the train set: 22851, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000088\n",
      "[LightGBM] [Info] Start training from score 0.000088\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's binary_logloss: 0.457777\n",
      "[LightGBM] [Info] Number of positive: 10573, number of negative: 10572\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116076\n",
      "[LightGBM] [Info] Number of data points in the train set: 21145, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000095\n",
      "[LightGBM] [Info] Start training from score 0.000095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.492526\n",
      "[LightGBM] [Info] Number of positive: 11106, number of negative: 11106\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115981\n",
      "[LightGBM] [Info] Number of data points in the train set: 22212, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.554035\n",
      "[LightGBM] [Info] Number of positive: 13805, number of negative: 13804\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116057\n",
      "[LightGBM] [Info] Number of data points in the train set: 27609, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000072\n",
      "[LightGBM] [Info] Start training from score 0.000072\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.520874\n",
      "[LightGBM] [Info] Number of positive: 10050, number of negative: 10049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116081\n",
      "[LightGBM] [Info] Number of data points in the train set: 20099, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.51817\n",
      "[LightGBM] [Info] Number of positive: 10718, number of negative: 10718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116009\n",
      "[LightGBM] [Info] Number of data points in the train set: 21436, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's binary_logloss: 0.521902\n",
      "[LightGBM] [Info] Number of positive: 9636, number of negative: 9636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116079\n",
      "[LightGBM] [Info] Number of data points in the train set: 19272, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's binary_logloss: 0.412632\n",
      "[LightGBM] [Info] Number of positive: 11328, number of negative: 11328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115972\n",
      "[LightGBM] [Info] Number of data points in the train set: 22656, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's binary_logloss: 0.524484\n",
      "[LightGBM] [Info] Number of positive: 10926, number of negative: 10926\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115883\n",
      "[LightGBM] [Info] Number of data points in the train set: 21852, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.57587\n",
      "[LightGBM] [Info] Number of positive: 9281, number of negative: 9280\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116017\n",
      "[LightGBM] [Info] Number of data points in the train set: 18561, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500027 -> initscore=0.000108\n",
      "[LightGBM] [Info] Start training from score 0.000108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.467518\n",
      "[LightGBM] [Info] Number of positive: 9542, number of negative: 9542\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115889\n",
      "[LightGBM] [Info] Number of data points in the train set: 19084, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's binary_logloss: 0.51358\n",
      "[LightGBM] [Info] Number of positive: 9774, number of negative: 9774\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116009\n",
      "[LightGBM] [Info] Number of data points in the train set: 19548, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's binary_logloss: 0.476299\n",
      "[LightGBM] [Info] Number of positive: 9386, number of negative: 9385\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115952\n",
      "[LightGBM] [Info] Number of data points in the train set: 18771, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500027 -> initscore=0.000107\n",
      "[LightGBM] [Info] Start training from score 0.000107\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.508815\n",
      "[LightGBM] [Info] Number of positive: 9356, number of negative: 9356\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115836\n",
      "[LightGBM] [Info] Number of data points in the train set: 18712, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.553666\n",
      "[LightGBM] [Info] Number of positive: 11736, number of negative: 11736\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115948\n",
      "[LightGBM] [Info] Number of data points in the train set: 23472, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.495695\n",
      "[LightGBM] [Info] Number of positive: 9638, number of negative: 9638\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115905\n",
      "[LightGBM] [Info] Number of data points in the train set: 19276, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's binary_logloss: 0.576368\n",
      "[LightGBM] [Info] Number of positive: 9826, number of negative: 9825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115860\n",
      "[LightGBM] [Info] Number of data points in the train set: 19651, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.548344\n",
      "[LightGBM] [Info] Number of positive: 8853, number of negative: 8852\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115948\n",
      "[LightGBM] [Info] Number of data points in the train set: 17705, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500028 -> initscore=0.000113\n",
      "[LightGBM] [Info] Start training from score 0.000113\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.496197\n",
      "[LightGBM] [Info] Number of positive: 10132, number of negative: 10132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116077\n",
      "[LightGBM] [Info] Number of data points in the train set: 20264, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.493005\n",
      "[LightGBM] [Info] Number of positive: 8543, number of negative: 8543\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115849\n",
      "[LightGBM] [Info] Number of data points in the train set: 17086, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.486409\n",
      "[LightGBM] [Info] Number of positive: 9789, number of negative: 9788\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115786\n",
      "[LightGBM] [Info] Number of data points in the train set: 19577, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's binary_logloss: 0.537548\n",
      "[LightGBM] [Info] Number of positive: 10750, number of negative: 10749\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115859\n",
      "[LightGBM] [Info] Number of data points in the train set: 21499, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000093\n",
      "[LightGBM] [Info] Start training from score 0.000093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's binary_logloss: 0.541802\n",
      "[LightGBM] [Info] Number of positive: 10552, number of negative: 10552\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115936\n",
      "[LightGBM] [Info] Number of data points in the train set: 21104, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's binary_logloss: 0.496274\n",
      "[LightGBM] [Info] Number of positive: 11279, number of negative: 11279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116098\n",
      "[LightGBM] [Info] Number of data points in the train set: 22558, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.428707\n",
      "[LightGBM] [Info] Number of positive: 9882, number of negative: 9881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115989\n",
      "[LightGBM] [Info] Number of data points in the train set: 19763, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000101\n",
      "[LightGBM] [Info] Start training from score 0.000101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's binary_logloss: 0.499806\n",
      "[LightGBM] [Info] Number of positive: 12384, number of negative: 12384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116019\n",
      "[LightGBM] [Info] Number of data points in the train set: 24768, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.549856\n",
      "[LightGBM] [Info] Number of positive: 10351, number of negative: 10351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115995\n",
      "[LightGBM] [Info] Number of data points in the train set: 20702, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.523141\n",
      "[LightGBM] [Info] Number of positive: 11678, number of negative: 11677\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116055\n",
      "[LightGBM] [Info] Number of data points in the train set: 23355, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000086\n",
      "[LightGBM] [Info] Start training from score 0.000086\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.503936\n",
      "[LightGBM] [Info] Number of positive: 11721, number of negative: 11720\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116165\n",
      "[LightGBM] [Info] Number of data points in the train set: 23441, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000085\n",
      "[LightGBM] [Info] Start training from score 0.000085\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.460902\n",
      "[LightGBM] [Info] Number of positive: 12568, number of negative: 12568\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116044\n",
      "[LightGBM] [Info] Number of data points in the train set: 25136, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.50753\n",
      "[LightGBM] [Info] Number of positive: 11402, number of negative: 11402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115911\n",
      "[LightGBM] [Info] Number of data points in the train set: 22804, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.581976\n",
      "[LightGBM] [Info] Number of positive: 7788, number of negative: 7788\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115795\n",
      "[LightGBM] [Info] Number of data points in the train set: 15576, number of used features: 472\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.531885\n",
      "[LightGBM] [Info] Number of positive: 9966, number of negative: 9965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115934\n",
      "[LightGBM] [Info] Number of data points in the train set: 19931, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.463558\n",
      "[LightGBM] [Info] Number of positive: 9974, number of negative: 9973\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115956\n",
      "[LightGBM] [Info] Number of data points in the train set: 19947, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.539336\n",
      "[LightGBM] [Info] Number of positive: 8496, number of negative: 8496\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115752\n",
      "[LightGBM] [Info] Number of data points in the train set: 16992, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.542104\n",
      "[LightGBM] [Info] Number of positive: 10694, number of negative: 10693\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115988\n",
      "[LightGBM] [Info] Number of data points in the train set: 21387, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000094\n",
      "[LightGBM] [Info] Start training from score 0.000094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.501657\n",
      "[LightGBM] [Info] Number of positive: 10886, number of negative: 10885\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116077\n",
      "[LightGBM] [Info] Number of data points in the train set: 21771, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000092\n",
      "[LightGBM] [Info] Start training from score 0.000092\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's binary_logloss: 0.440508\n",
      "[LightGBM] [Info] Number of positive: 12058, number of negative: 12058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116016\n",
      "[LightGBM] [Info] Number of data points in the train set: 24116, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.486012\n",
      "[LightGBM] [Info] Number of positive: 12525, number of negative: 12524\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116125\n",
      "[LightGBM] [Info] Number of data points in the train set: 25049, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000080\n",
      "[LightGBM] [Info] Start training from score 0.000080\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.486963\n",
      "[LightGBM] [Info] Number of positive: 12314, number of negative: 12314\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116138\n",
      "[LightGBM] [Info] Number of data points in the train set: 24628, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's binary_logloss: 0.451568\n",
      "[LightGBM] [Info] Number of positive: 11734, number of negative: 11734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115999\n",
      "[LightGBM] [Info] Number of data points in the train set: 23468, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's binary_logloss: 0.504324\n",
      "[LightGBM] [Info] Number of positive: 9670, number of negative: 9669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116077\n",
      "[LightGBM] [Info] Number of data points in the train set: 19339, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000103\n",
      "[LightGBM] [Info] Start training from score 0.000103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.458405\n",
      "[LightGBM] [Info] Number of positive: 10884, number of negative: 10884\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115919\n",
      "[LightGBM] [Info] Number of data points in the train set: 21768, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.575199\n",
      "[LightGBM] [Info] Number of positive: 11416, number of negative: 11416\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116000\n",
      "[LightGBM] [Info] Number of data points in the train set: 22832, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's binary_logloss: 0.497795\n",
      "[LightGBM] [Info] Number of positive: 11528, number of negative: 11528\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116192\n",
      "[LightGBM] [Info] Number of data points in the train set: 23056, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.483635\n",
      "[LightGBM] [Info] Number of positive: 11178, number of negative: 11178\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116039\n",
      "[LightGBM] [Info] Number of data points in the train set: 22356, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's binary_logloss: 0.506044\n",
      "[LightGBM] [Info] Number of positive: 11290, number of negative: 11290\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115872\n",
      "[LightGBM] [Info] Number of data points in the train set: 22580, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's binary_logloss: 0.531003\n",
      "[LightGBM] [Info] Number of positive: 9644, number of negative: 9644\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115975\n",
      "[LightGBM] [Info] Number of data points in the train set: 19288, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's binary_logloss: 0.562864\n",
      "[LightGBM] [Info] Number of positive: 9610, number of negative: 9609\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115973\n",
      "[LightGBM] [Info] Number of data points in the train set: 19219, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000104\n",
      "[LightGBM] [Info] Start training from score 0.000104\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's binary_logloss: 0.449496\n",
      "[LightGBM] [Info] Number of positive: 12630, number of negative: 12630\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116079\n",
      "[LightGBM] [Info] Number of data points in the train set: 25260, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.540854\n",
      "[LightGBM] [Info] Number of positive: 9698, number of negative: 9697\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115901\n",
      "[LightGBM] [Info] Number of data points in the train set: 19395, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000103\n",
      "[LightGBM] [Info] Start training from score 0.000103\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's binary_logloss: 0.546405\n",
      "[LightGBM] [Info] Number of positive: 11701, number of negative: 11700\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115996\n",
      "[LightGBM] [Info] Number of data points in the train set: 23401, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000085\n",
      "[LightGBM] [Info] Start training from score 0.000085\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's binary_logloss: 0.555557\n",
      "[LightGBM] [Info] Number of positive: 9400, number of negative: 9400\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116008\n",
      "[LightGBM] [Info] Number of data points in the train set: 18800, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's binary_logloss: 0.510967\n",
      "[LightGBM] [Info] Number of positive: 9806, number of negative: 9805\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115739\n",
      "[LightGBM] [Info] Number of data points in the train set: 19611, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.515799\n",
      "[LightGBM] [Info] Number of positive: 7374, number of negative: 7373\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115823\n",
      "[LightGBM] [Info] Number of data points in the train set: 14747, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500034 -> initscore=0.000136\n",
      "[LightGBM] [Info] Start training from score 0.000136\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's binary_logloss: 0.495498\n",
      "[LightGBM] [Info] Number of positive: 12286, number of negative: 12286\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116164\n",
      "[LightGBM] [Info] Number of data points in the train set: 24572, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.467234\n",
      "[LightGBM] [Info] Number of positive: 10632, number of negative: 10632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115994\n",
      "[LightGBM] [Info] Number of data points in the train set: 21264, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.472237\n",
      "[LightGBM] [Info] Number of positive: 10976, number of negative: 10976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116030\n",
      "[LightGBM] [Info] Number of data points in the train set: 21952, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.518804\n",
      "[LightGBM] [Info] Number of positive: 10473, number of negative: 10472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115991\n",
      "[LightGBM] [Info] Number of data points in the train set: 20945, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000095\n",
      "[LightGBM] [Info] Start training from score 0.000095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.47653\n",
      "[LightGBM] [Info] Number of positive: 12342, number of negative: 12342\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116060\n",
      "[LightGBM] [Info] Number of data points in the train set: 24684, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.497415\n",
      "[LightGBM] [Info] Number of positive: 11950, number of negative: 11949\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116060\n",
      "[LightGBM] [Info] Number of data points in the train set: 23899, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000084\n",
      "[LightGBM] [Info] Start training from score 0.000084\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's binary_logloss: 0.492629\n",
      "[LightGBM] [Info] Number of positive: 12980, number of negative: 12980\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116081\n",
      "[LightGBM] [Info] Number of data points in the train set: 25960, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.525164\n",
      "[LightGBM] [Info] Number of positive: 7995, number of negative: 7995\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115909\n",
      "[LightGBM] [Info] Number of data points in the train set: 15990, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.524503\n",
      "[LightGBM] [Info] Number of positive: 11870, number of negative: 11869\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116003\n",
      "[LightGBM] [Info] Number of data points in the train set: 23739, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000084\n",
      "[LightGBM] [Info] Start training from score 0.000084\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's binary_logloss: 0.500965\n",
      "[LightGBM] [Info] Number of positive: 9821, number of negative: 9820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116072\n",
      "[LightGBM] [Info] Number of data points in the train set: 19641, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.45301\n",
      "[LightGBM] [Info] Number of positive: 10151, number of negative: 10151\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116013\n",
      "[LightGBM] [Info] Number of data points in the train set: 20302, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.502388\n",
      "[LightGBM] [Info] Number of positive: 9479, number of negative: 9479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115906\n",
      "[LightGBM] [Info] Number of data points in the train set: 18958, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.564723\n",
      "[LightGBM] [Info] Number of positive: 10540, number of negative: 10540\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115882\n",
      "[LightGBM] [Info] Number of data points in the train set: 21080, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.542643\n",
      "[LightGBM] [Info] Number of positive: 10355, number of negative: 10355\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115944\n",
      "[LightGBM] [Info] Number of data points in the train set: 20710, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's binary_logloss: 0.53158\n",
      "[LightGBM] [Info] Number of positive: 11566, number of negative: 11566\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115933\n",
      "[LightGBM] [Info] Number of data points in the train set: 23132, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.552318\n",
      "[LightGBM] [Info] Number of positive: 11494, number of negative: 11493\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115946\n",
      "[LightGBM] [Info] Number of data points in the train set: 22987, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000087\n",
      "[LightGBM] [Info] Start training from score 0.000087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's binary_logloss: 0.457188\n",
      "[LightGBM] [Info] Number of positive: 9886, number of negative: 9886\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116034\n",
      "[LightGBM] [Info] Number of data points in the train set: 19772, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.53066\n",
      "[LightGBM] [Info] Number of positive: 7886, number of negative: 7886\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115935\n",
      "[LightGBM] [Info] Number of data points in the train set: 15772, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.513341\n",
      "[LightGBM] [Info] Number of positive: 12042, number of negative: 12042\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116055\n",
      "[LightGBM] [Info] Number of data points in the train set: 24084, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's binary_logloss: 0.533179\n",
      "[LightGBM] [Info] Number of positive: 9919, number of negative: 9919\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116042\n",
      "[LightGBM] [Info] Number of data points in the train set: 19838, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.549743\n",
      "[LightGBM] [Info] Number of positive: 11158, number of negative: 11158\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116062\n",
      "[LightGBM] [Info] Number of data points in the train set: 22316, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.540648\n",
      "[LightGBM] [Info] Number of positive: 11179, number of negative: 11179\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115874\n",
      "[LightGBM] [Info] Number of data points in the train set: 22358, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.566061\n",
      "[LightGBM] [Info] Number of positive: 12782, number of negative: 12781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116119\n",
      "[LightGBM] [Info] Number of data points in the train set: 25563, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.459311\n",
      "[LightGBM] [Info] Number of positive: 11765, number of negative: 11764\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116050\n",
      "[LightGBM] [Info] Number of data points in the train set: 23529, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000085\n",
      "[LightGBM] [Info] Start training from score 0.000085\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.513163\n",
      "[LightGBM] [Info] Number of positive: 9762, number of negative: 9761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115942\n",
      "[LightGBM] [Info] Number of data points in the train set: 19523, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.52817\n",
      "[LightGBM] [Info] Number of positive: 8959, number of negative: 8959\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115836\n",
      "[LightGBM] [Info] Number of data points in the train set: 17918, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.549721\n",
      "[LightGBM] [Info] Number of positive: 11073, number of negative: 11072\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115975\n",
      "[LightGBM] [Info] Number of data points in the train set: 22145, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000090\n",
      "[LightGBM] [Info] Start training from score 0.000090\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.50752\n",
      "[LightGBM] [Info] Number of positive: 11684, number of negative: 11684\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115961\n",
      "[LightGBM] [Info] Number of data points in the train set: 23368, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's binary_logloss: 0.56247\n",
      "[LightGBM] [Info] Number of positive: 11522, number of negative: 11522\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115998\n",
      "[LightGBM] [Info] Number of data points in the train set: 23044, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's binary_logloss: 0.563511\n",
      "[LightGBM] [Info] Number of positive: 13927, number of negative: 13927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115996\n",
      "[LightGBM] [Info] Number of data points in the train set: 27854, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.560924\n",
      "[LightGBM] [Info] Number of positive: 9783, number of negative: 9783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115946\n",
      "[LightGBM] [Info] Number of data points in the train set: 19566, number of used features: 472\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's binary_logloss: 0.514642\n",
      "[LightGBM] [Info] Number of positive: 9046, number of negative: 9045\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115999\n",
      "[LightGBM] [Info] Number of data points in the train set: 18091, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500028 -> initscore=0.000111\n",
      "[LightGBM] [Info] Start training from score 0.000111\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.428083\n",
      "[LightGBM] [Info] Number of positive: 11874, number of negative: 11874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116022\n",
      "[LightGBM] [Info] Number of data points in the train set: 23748, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's binary_logloss: 0.425378\n",
      "[LightGBM] [Info] Number of positive: 12327, number of negative: 12327\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116031\n",
      "[LightGBM] [Info] Number of data points in the train set: 24654, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.466422\n",
      "[LightGBM] [Info] Number of positive: 11077, number of negative: 11076\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115975\n",
      "[LightGBM] [Info] Number of data points in the train set: 22153, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000090\n",
      "[LightGBM] [Info] Start training from score 0.000090\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.575884\n",
      "[LightGBM] [Info] Number of positive: 10944, number of negative: 10944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115922\n",
      "[LightGBM] [Info] Number of data points in the train set: 21888, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's binary_logloss: 0.576951\n",
      "[LightGBM] [Info] Number of positive: 10469, number of negative: 10468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116050\n",
      "[LightGBM] [Info] Number of data points in the train set: 20937, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000096\n",
      "[LightGBM] [Info] Start training from score 0.000096\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's binary_logloss: 0.532503\n",
      "[LightGBM] [Info] Number of positive: 12012, number of negative: 12012\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116004\n",
      "[LightGBM] [Info] Number of data points in the train set: 24024, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's binary_logloss: 0.535962\n",
      "[LightGBM] [Info] Number of positive: 11624, number of negative: 11624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115823\n",
      "[LightGBM] [Info] Number of data points in the train set: 23248, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's binary_logloss: 0.560392\n",
      "[LightGBM] [Info] Number of positive: 9320, number of negative: 9320\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115918\n",
      "[LightGBM] [Info] Number of data points in the train set: 18640, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's binary_logloss: 0.5513\n",
      "[LightGBM] [Info] Number of positive: 11434, number of negative: 11434\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116091\n",
      "[LightGBM] [Info] Number of data points in the train set: 22868, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.467594\n",
      "[LightGBM] [Info] Number of positive: 10472, number of negative: 10472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115991\n",
      "[LightGBM] [Info] Number of data points in the train set: 20944, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.53289\n",
      "[LightGBM] [Info] Number of positive: 10645, number of negative: 10644\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115978\n",
      "[LightGBM] [Info] Number of data points in the train set: 21289, number of used features: 472\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000094\n",
      "[LightGBM] [Info] Start training from score 0.000094\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.541168\n",
      "[LightGBM] [Info] Number of positive: 13194, number of negative: 13193\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115952\n",
      "[LightGBM] [Info] Number of data points in the train set: 26387, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.498003\n",
      "[LightGBM] [Info] Number of positive: 15910, number of negative: 15910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116127\n",
      "[LightGBM] [Info] Number of data points in the train set: 31820, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.497087\n",
      "[LightGBM] [Info] Number of positive: 10260, number of negative: 10260\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116041\n",
      "[LightGBM] [Info] Number of data points in the train set: 20520, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.456694\n",
      "[LightGBM] [Info] Number of positive: 9808, number of negative: 9808\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115945\n",
      "[LightGBM] [Info] Number of data points in the train set: 19616, number of used features: 472\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.518883\n",
      "[LightGBM] [Info] Number of positive: 9897, number of negative: 9896\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116025\n",
      "[LightGBM] [Info] Number of data points in the train set: 19793, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000101\n",
      "[LightGBM] [Info] Start training from score 0.000101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's binary_logloss: 0.520512\n",
      "[LightGBM] [Info] Number of positive: 11767, number of negative: 11767\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115919\n",
      "[LightGBM] [Info] Number of data points in the train set: 23534, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's binary_logloss: 0.541497\n",
      "[LightGBM] [Info] Number of positive: 8778, number of negative: 8777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115755\n",
      "[LightGBM] [Info] Number of data points in the train set: 17555, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500028 -> initscore=0.000114\n",
      "[LightGBM] [Info] Start training from score 0.000114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.545658\n",
      "[LightGBM] [Info] Number of positive: 9937, number of negative: 9936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115971\n",
      "[LightGBM] [Info] Number of data points in the train set: 19873, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000101\n",
      "[LightGBM] [Info] Start training from score 0.000101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's binary_logloss: 0.478744\n",
      "[LightGBM] [Info] Number of positive: 10648, number of negative: 10648\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115945\n",
      "[LightGBM] [Info] Number of data points in the train set: 21296, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.541066\n",
      "[LightGBM] [Info] Number of positive: 12546, number of negative: 12546\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116053\n",
      "[LightGBM] [Info] Number of data points in the train set: 25092, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's binary_logloss: 0.586544\n",
      "[LightGBM] [Info] Number of positive: 9644, number of negative: 9644\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115900\n",
      "[LightGBM] [Info] Number of data points in the train set: 19288, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's binary_logloss: 0.494664\n",
      "[LightGBM] [Info] Number of positive: 12777, number of negative: 12776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116171\n",
      "[LightGBM] [Info] Number of data points in the train set: 25553, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's binary_logloss: 0.458326\n",
      "[LightGBM] [Info] Number of positive: 11253, number of negative: 11252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116042\n",
      "[LightGBM] [Info] Number of data points in the train set: 22505, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000089\n",
      "[LightGBM] [Info] Start training from score 0.000089\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's binary_logloss: 0.441626\n",
      "[LightGBM] [Info] Number of positive: 14178, number of negative: 14177\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116119\n",
      "[LightGBM] [Info] Number of data points in the train set: 28355, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's binary_logloss: 0.511851\n",
      "[LightGBM] [Info] Number of positive: 8454, number of negative: 8453\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115854\n",
      "[LightGBM] [Info] Number of data points in the train set: 16907, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500030 -> initscore=0.000118\n",
      "[LightGBM] [Info] Start training from score 0.000118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.527771\n",
      "[LightGBM] [Info] Number of positive: 10395, number of negative: 10395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115969\n",
      "[LightGBM] [Info] Number of data points in the train set: 20790, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's binary_logloss: 0.53945\n",
      "[LightGBM] [Info] Number of positive: 12570, number of negative: 12570\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116012\n",
      "[LightGBM] [Info] Number of data points in the train set: 25140, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.554966\n",
      "[LightGBM] [Info] Number of positive: 14152, number of negative: 14152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116092\n",
      "[LightGBM] [Info] Number of data points in the train set: 28304, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's binary_logloss: 0.515223\n",
      "[LightGBM] [Info] Number of positive: 11731, number of negative: 11731\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116125\n",
      "[LightGBM] [Info] Number of data points in the train set: 23462, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's binary_logloss: 0.427425\n",
      "[LightGBM] [Info] Number of positive: 10771, number of negative: 10771\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115925\n",
      "[LightGBM] [Info] Number of data points in the train set: 21542, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.559141\n",
      "[LightGBM] [Info] Number of positive: 8554, number of negative: 8554\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115985\n",
      "[LightGBM] [Info] Number of data points in the train set: 17108, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.469036\n",
      "[LightGBM] [Info] Number of positive: 9523, number of negative: 9523\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115878\n",
      "[LightGBM] [Info] Number of data points in the train set: 19046, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.472798\n",
      "[LightGBM] [Info] Number of positive: 13242, number of negative: 13242\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116171\n",
      "[LightGBM] [Info] Number of data points in the train set: 26484, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's binary_logloss: 0.475078\n",
      "[LightGBM] [Info] Number of positive: 9965, number of negative: 9964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115976\n",
      "[LightGBM] [Info] Number of data points in the train set: 19929, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's binary_logloss: 0.528088\n",
      "[LightGBM] [Info] Number of positive: 10499, number of negative: 10499\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116111\n",
      "[LightGBM] [Info] Number of data points in the train set: 20998, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's binary_logloss: 0.442033\n",
      "[LightGBM] [Info] Number of positive: 10562, number of negative: 10562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116089\n",
      "[LightGBM] [Info] Number of data points in the train set: 21124, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's binary_logloss: 0.454617\n",
      "[LightGBM] [Info] Number of positive: 11474, number of negative: 11473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115985\n",
      "[LightGBM] [Info] Number of data points in the train set: 22947, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000087\n",
      "[LightGBM] [Info] Start training from score 0.000087\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's binary_logloss: 0.529044\n",
      "[LightGBM] [Info] Number of positive: 9483, number of negative: 9483\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116027\n",
      "[LightGBM] [Info] Number of data points in the train set: 18966, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's binary_logloss: 0.477079\n",
      "[LightGBM] [Info] Number of positive: 12362, number of negative: 12361\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116190\n",
      "[LightGBM] [Info] Number of data points in the train set: 24723, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000081\n",
      "[LightGBM] [Info] Start training from score 0.000081\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's binary_logloss: 0.433552\n",
      "[LightGBM] [Info] Number of positive: 11354, number of negative: 11354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116051\n",
      "[LightGBM] [Info] Number of data points in the train set: 22708, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.557339\n",
      "[LightGBM] [Info] Number of positive: 11934, number of negative: 11934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116092\n",
      "[LightGBM] [Info] Number of data points in the train set: 23868, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.465244\n",
      "[LightGBM] [Info] Number of positive: 9261, number of negative: 9260\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115728\n",
      "[LightGBM] [Info] Number of data points in the train set: 18521, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500027 -> initscore=0.000108\n",
      "[LightGBM] [Info] Start training from score 0.000108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's binary_logloss: 0.535316\n",
      "[LightGBM] [Info] Number of positive: 11240, number of negative: 11240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115974\n",
      "[LightGBM] [Info] Number of data points in the train set: 22480, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.503284\n",
      "[LightGBM] [Info] Number of positive: 12474, number of negative: 12474\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116065\n",
      "[LightGBM] [Info] Number of data points in the train set: 24948, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's binary_logloss: 0.508619\n",
      "[LightGBM] [Info] Number of positive: 12238, number of negative: 12238\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116192\n",
      "[LightGBM] [Info] Number of data points in the train set: 24476, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's binary_logloss: 0.448618\n",
      "[LightGBM] [Info] Number of positive: 12302, number of negative: 12302\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115979\n",
      "[LightGBM] [Info] Number of data points in the train set: 24604, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.527861\n",
      "[LightGBM] [Info] Number of positive: 9606, number of negative: 9606\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115956\n",
      "[LightGBM] [Info] Number of data points in the train set: 19212, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.488466\n",
      "[LightGBM] [Info] Number of positive: 10225, number of negative: 10224\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116011\n",
      "[LightGBM] [Info] Number of data points in the train set: 20449, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000098\n",
      "[LightGBM] [Info] Start training from score 0.000098\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's binary_logloss: 0.440288\n",
      "[LightGBM] [Info] Number of positive: 11383, number of negative: 11383\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116030\n",
      "[LightGBM] [Info] Number of data points in the train set: 22766, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's binary_logloss: 0.478015\n",
      "[LightGBM] [Info] Number of positive: 12470, number of negative: 12470\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116035\n",
      "[LightGBM] [Info] Number of data points in the train set: 24940, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's binary_logloss: 0.459467\n",
      "[LightGBM] [Info] Number of positive: 9779, number of negative: 9779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116001\n",
      "[LightGBM] [Info] Number of data points in the train set: 19558, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.468036\n",
      "[LightGBM] [Info] Number of positive: 9821, number of negative: 9820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115939\n",
      "[LightGBM] [Info] Number of data points in the train set: 19641, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.572517\n",
      "[LightGBM] [Info] Number of positive: 9244, number of negative: 9244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115889\n",
      "[LightGBM] [Info] Number of data points in the train set: 18488, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.542164\n",
      "[LightGBM] [Info] Number of positive: 10094, number of negative: 10094\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116048\n",
      "[LightGBM] [Info] Number of data points in the train set: 20188, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's binary_logloss: 0.546173\n",
      "[LightGBM] [Info] Number of positive: 12284, number of negative: 12284\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116035\n",
      "[LightGBM] [Info] Number of data points in the train set: 24568, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's binary_logloss: 0.549856\n",
      "[LightGBM] [Info] Number of positive: 9934, number of negative: 9933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115995\n",
      "[LightGBM] [Info] Number of data points in the train set: 19867, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000101\n",
      "[LightGBM] [Info] Start training from score 0.000101\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.51687\n",
      "[LightGBM] [Info] Number of positive: 12443, number of negative: 12443\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116168\n",
      "[LightGBM] [Info] Number of data points in the train set: 24886, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.515925\n",
      "[LightGBM] [Info] Number of positive: 10949, number of negative: 10948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115916\n",
      "[LightGBM] [Info] Number of data points in the train set: 21897, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000091\n",
      "[LightGBM] [Info] Start training from score 0.000091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's binary_logloss: 0.528478\n",
      "[LightGBM] [Info] Number of positive: 8599, number of negative: 8599\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115885\n",
      "[LightGBM] [Info] Number of data points in the train set: 17198, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's binary_logloss: 0.573466\n",
      "[LightGBM] [Info] Number of positive: 9598, number of negative: 9598\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115853\n",
      "[LightGBM] [Info] Number of data points in the train set: 19196, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.534039\n",
      "[LightGBM] [Info] Number of positive: 9549, number of negative: 9548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115983\n",
      "[LightGBM] [Info] Number of data points in the train set: 19097, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000105\n",
      "[LightGBM] [Info] Start training from score 0.000105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.536392\n",
      "[LightGBM] [Info] Number of positive: 8756, number of negative: 8756\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115923\n",
      "[LightGBM] [Info] Number of data points in the train set: 17512, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.477559\n",
      "[LightGBM] [Info] Number of positive: 12993, number of negative: 12992\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116137\n",
      "[LightGBM] [Info] Number of data points in the train set: 25985, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000077\n",
      "[LightGBM] [Info] Start training from score 0.000077\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.504846\n",
      "[LightGBM] [Info] Number of positive: 10793, number of negative: 10792\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115891\n",
      "[LightGBM] [Info] Number of data points in the train set: 21585, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000093\n",
      "[LightGBM] [Info] Start training from score 0.000093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's binary_logloss: 0.582299\n",
      "[LightGBM] [Info] Number of positive: 10492, number of negative: 10492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115994\n",
      "[LightGBM] [Info] Number of data points in the train set: 20984, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's binary_logloss: 0.502986\n",
      "[LightGBM] [Info] Number of positive: 9440, number of negative: 9440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115974\n",
      "[LightGBM] [Info] Number of data points in the train set: 18880, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's binary_logloss: 0.460644\n",
      "[LightGBM] [Info] Number of positive: 10386, number of negative: 10385\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116012\n",
      "[LightGBM] [Info] Number of data points in the train set: 20771, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500024 -> initscore=0.000096\n",
      "[LightGBM] [Info] Start training from score 0.000096\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.507432\n",
      "[LightGBM] [Info] Number of positive: 11186, number of negative: 11186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116046\n",
      "[LightGBM] [Info] Number of data points in the train set: 22372, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.475197\n",
      "[LightGBM] [Info] Number of positive: 10275, number of negative: 10275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115928\n",
      "[LightGBM] [Info] Number of data points in the train set: 20550, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.541988\n",
      "[LightGBM] [Info] Number of positive: 8158, number of negative: 8157\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115852\n",
      "[LightGBM] [Info] Number of data points in the train set: 16315, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500031 -> initscore=0.000123\n",
      "[LightGBM] [Info] Start training from score 0.000123\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.521227\n",
      "[LightGBM] [Info] Number of positive: 13063, number of negative: 13063\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116048\n",
      "[LightGBM] [Info] Number of data points in the train set: 26126, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.515092\n",
      "[LightGBM] [Info] Number of positive: 10069, number of negative: 10068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115861\n",
      "[LightGBM] [Info] Number of data points in the train set: 20137, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000099\n",
      "[LightGBM] [Info] Start training from score 0.000099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.553378\n",
      "[LightGBM] [Info] Number of positive: 10132, number of negative: 10132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115998\n",
      "[LightGBM] [Info] Number of data points in the train set: 20264, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.477253\n",
      "[LightGBM] [Info] Number of positive: 10506, number of negative: 10506\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116133\n",
      "[LightGBM] [Info] Number of data points in the train set: 21012, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.490885\n",
      "[LightGBM] [Info] Number of positive: 9070, number of negative: 9069\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115898\n",
      "[LightGBM] [Info] Number of data points in the train set: 18139, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500028 -> initscore=0.000110\n",
      "[LightGBM] [Info] Start training from score 0.000110\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's binary_logloss: 0.524514\n",
      "[LightGBM] [Info] Number of positive: 9450, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115997\n",
      "[LightGBM] [Info] Number of data points in the train set: 18899, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000106\n",
      "[LightGBM] [Info] Start training from score 0.000106\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.507506\n",
      "[LightGBM] [Info] Number of positive: 11702, number of negative: 11702\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116090\n",
      "[LightGBM] [Info] Number of data points in the train set: 23404, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's binary_logloss: 0.484355\n",
      "[LightGBM] [Info] Number of positive: 10464, number of negative: 10464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115873\n",
      "[LightGBM] [Info] Number of data points in the train set: 20928, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.561917\n",
      "[LightGBM] [Info] Number of positive: 12746, number of negative: 12746\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115973\n",
      "[LightGBM] [Info] Number of data points in the train set: 25492, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's binary_logloss: 0.53772\n",
      "[LightGBM] [Info] Number of positive: 8365, number of negative: 8364\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115796\n",
      "[LightGBM] [Info] Number of data points in the train set: 16729, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500030 -> initscore=0.000120\n",
      "[LightGBM] [Info] Start training from score 0.000120\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.595759\n",
      "[LightGBM] [Info] Number of positive: 11654, number of negative: 11654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116093\n",
      "[LightGBM] [Info] Number of data points in the train set: 23308, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.465703\n",
      "[LightGBM] [Info] Number of positive: 9557, number of negative: 9556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115870\n",
      "[LightGBM] [Info] Number of data points in the train set: 19113, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500026 -> initscore=0.000105\n",
      "[LightGBM] [Info] Start training from score 0.000105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.571301\n",
      "[LightGBM] [Info] Number of positive: 12134, number of negative: 12134\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116217\n",
      "[LightGBM] [Info] Number of data points in the train set: 24268, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.465927\n",
      "[LightGBM] [Info] Number of positive: 8026, number of negative: 8025\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115867\n",
      "[LightGBM] [Info] Number of data points in the train set: 16051, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500031 -> initscore=0.000125\n",
      "[LightGBM] [Info] Start training from score 0.000125\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.514129\n",
      "[LightGBM] [Info] Number of positive: 11759, number of negative: 11759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116054\n",
      "[LightGBM] [Info] Number of data points in the train set: 23518, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.507098\n",
      "[LightGBM] [Info] Number of positive: 11426, number of negative: 11426\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116054\n",
      "[LightGBM] [Info] Number of data points in the train set: 22852, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's binary_logloss: 0.495259\n",
      "[LightGBM] [Info] Number of positive: 12159, number of negative: 12159\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115931\n",
      "[LightGBM] [Info] Number of data points in the train set: 24318, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's binary_logloss: 0.556946\n",
      "[LightGBM] [Info] Number of positive: 8660, number of negative: 8660\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115890\n",
      "[LightGBM] [Info] Number of data points in the train set: 17320, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's binary_logloss: 0.477144\n",
      "[LightGBM] [Info] Number of positive: 9504, number of negative: 9504\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115882\n",
      "[LightGBM] [Info] Number of data points in the train set: 19008, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.605234\n",
      "[LightGBM] [Info] Number of positive: 11838, number of negative: 11838\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116058\n",
      "[LightGBM] [Info] Number of data points in the train set: 23676, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's binary_logloss: 0.513893\n",
      "[LightGBM] [Info] Number of positive: 11655, number of negative: 11655\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115980\n",
      "[LightGBM] [Info] Number of data points in the train set: 23310, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's binary_logloss: 0.508706\n",
      "[LightGBM] [Info] Number of positive: 12002, number of negative: 12001\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116097\n",
      "[LightGBM] [Info] Number of data points in the train set: 24003, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000083\n",
      "[LightGBM] [Info] Start training from score 0.000083\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's binary_logloss: 0.438866\n",
      "[LightGBM] [Info] Number of positive: 9821, number of negative: 9820\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116087\n",
      "[LightGBM] [Info] Number of data points in the train set: 19641, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000102\n",
      "[LightGBM] [Info] Start training from score 0.000102\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's binary_logloss: 0.463027\n",
      "[LightGBM] [Info] Number of positive: 11468, number of negative: 11468\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115984\n",
      "[LightGBM] [Info] Number of data points in the train set: 22936, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's binary_logloss: 0.507557\n",
      "[LightGBM] [Info] Number of positive: 14138, number of negative: 14137\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116154\n",
      "[LightGBM] [Info] Number of data points in the train set: 28275, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500018 -> initscore=0.000071\n",
      "[LightGBM] [Info] Start training from score 0.000071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's binary_logloss: 0.517878\n",
      "[LightGBM] [Info] Number of positive: 10914, number of negative: 10914\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115904\n",
      "[LightGBM] [Info] Number of data points in the train set: 21828, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's binary_logloss: 0.539586\n",
      "[LightGBM] [Info] Number of positive: 10998, number of negative: 10997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115980\n",
      "[LightGBM] [Info] Number of data points in the train set: 21995, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000091\n",
      "[LightGBM] [Info] Start training from score 0.000091\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.532305\n",
      "[LightGBM] [Info] Number of positive: 10002, number of negative: 10002\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115960\n",
      "[LightGBM] [Info] Number of data points in the train set: 20004, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's binary_logloss: 0.532058\n",
      "[LightGBM] [Info] Number of positive: 9632, number of negative: 9632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115817\n",
      "[LightGBM] [Info] Number of data points in the train set: 19264, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's binary_logloss: 0.567851\n",
      "[LightGBM] [Info] Number of positive: 9234, number of negative: 9233\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115954\n",
      "[LightGBM] [Info] Number of data points in the train set: 18467, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500027 -> initscore=0.000108\n",
      "[LightGBM] [Info] Start training from score 0.000108\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.553032\n",
      "[LightGBM] [Info] Number of positive: 9962, number of negative: 9961\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115906\n",
      "[LightGBM] [Info] Number of data points in the train set: 19923, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's binary_logloss: 0.547715\n",
      "[LightGBM] [Info] Number of positive: 10926, number of negative: 10926\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116125\n",
      "[LightGBM] [Info] Number of data points in the train set: 21852, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.473912\n",
      "[LightGBM] [Info] Number of positive: 12678, number of negative: 12677\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116109\n",
      "[LightGBM] [Info] Number of data points in the train set: 25355, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000079\n",
      "[LightGBM] [Info] Start training from score 0.000079\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's binary_logloss: 0.474366\n",
      "[LightGBM] [Info] Number of positive: 11889, number of negative: 11888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116037\n",
      "[LightGBM] [Info] Number of data points in the train set: 23777, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000084\n",
      "[LightGBM] [Info] Start training from score 0.000084\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's binary_logloss: 0.467474\n",
      "[LightGBM] [Info] Number of positive: 10744, number of negative: 10744\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116160\n",
      "[LightGBM] [Info] Number of data points in the train set: 21488, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.454595\n",
      "[LightGBM] [Info] Number of positive: 12897, number of negative: 12896\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116106\n",
      "[LightGBM] [Info] Number of data points in the train set: 25793, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's binary_logloss: 0.524525\n",
      "[LightGBM] [Info] Number of positive: 7546, number of negative: 7545\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115931\n",
      "[LightGBM] [Info] Number of data points in the train set: 15091, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500033 -> initscore=0.000133\n",
      "[LightGBM] [Info] Start training from score 0.000133\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's binary_logloss: 0.430442\n",
      "[LightGBM] [Info] Number of positive: 11898, number of negative: 11898\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116022\n",
      "[LightGBM] [Info] Number of data points in the train set: 23796, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.532539\n",
      "[LightGBM] [Info] Number of positive: 8314, number of negative: 8313\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115918\n",
      "[LightGBM] [Info] Number of data points in the train set: 16627, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500030 -> initscore=0.000120\n",
      "[LightGBM] [Info] Start training from score 0.000120\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's binary_logloss: 0.478047\n",
      "[LightGBM] [Info] Number of positive: 8328, number of negative: 8328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115829\n",
      "[LightGBM] [Info] Number of data points in the train set: 16656, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's binary_logloss: 0.525563\n",
      "[LightGBM] [Info] Number of positive: 11869, number of negative: 11868\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116150\n",
      "[LightGBM] [Info] Number of data points in the train set: 23737, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000084\n",
      "[LightGBM] [Info] Start training from score 0.000084\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.479544\n",
      "[LightGBM] [Info] Number of positive: 12631, number of negative: 12631\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115981\n",
      "[LightGBM] [Info] Number of data points in the train set: 25262, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's binary_logloss: 0.567985\n",
      "[LightGBM] [Info] Number of positive: 12522, number of negative: 12522\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116108\n",
      "[LightGBM] [Info] Number of data points in the train set: 25044, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's binary_logloss: 0.46767\n",
      "[LightGBM] [Info] Number of positive: 8384, number of negative: 8384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115912\n",
      "[LightGBM] [Info] Number of data points in the train set: 16768, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's binary_logloss: 0.505099\n",
      "[LightGBM] [Info] Number of positive: 13150, number of negative: 13149\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116154\n",
      "[LightGBM] [Info] Number of data points in the train set: 26299, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500019 -> initscore=0.000076\n",
      "[LightGBM] [Info] Start training from score 0.000076\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.444607\n",
      "[LightGBM] [Info] Number of positive: 9114, number of negative: 9113\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115837\n",
      "[LightGBM] [Info] Number of data points in the train set: 18227, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500027 -> initscore=0.000110\n",
      "[LightGBM] [Info] Start training from score 0.000110\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's binary_logloss: 0.563659\n",
      "[LightGBM] [Info] Number of positive: 9667, number of negative: 9667\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115971\n",
      "[LightGBM] [Info] Number of data points in the train set: 19334, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's binary_logloss: 0.50398\n",
      "[LightGBM] [Info] Number of positive: 11086, number of negative: 11085\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116090\n",
      "[LightGBM] [Info] Number of data points in the train set: 22171, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000090\n",
      "[LightGBM] [Info] Start training from score 0.000090\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's binary_logloss: 0.467635\n",
      "[LightGBM] [Info] Number of positive: 12884, number of negative: 12884\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115976\n",
      "[LightGBM] [Info] Number of data points in the train set: 25768, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's binary_logloss: 0.49707\n",
      "[LightGBM] [Info] Number of positive: 10054, number of negative: 10053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115962\n",
      "[LightGBM] [Info] Number of data points in the train set: 20107, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000099\n",
      "[LightGBM] [Info] Start training from score 0.000099\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.471251\n",
      "[LightGBM] [Info] Number of positive: 8230, number of negative: 8230\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115878\n",
      "[LightGBM] [Info] Number of data points in the train set: 16460, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.505656\n",
      "[LightGBM] [Info] Number of positive: 8324, number of negative: 8324\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115932\n",
      "[LightGBM] [Info] Number of data points in the train set: 16648, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.492387\n",
      "[LightGBM] [Info] Number of positive: 11163, number of negative: 11163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116036\n",
      "[LightGBM] [Info] Number of data points in the train set: 22326, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's binary_logloss: 0.558253\n",
      "[LightGBM] [Info] Number of positive: 11444, number of negative: 11444\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116045\n",
      "[LightGBM] [Info] Number of data points in the train set: 22888, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's binary_logloss: 0.557313\n",
      "[LightGBM] [Info] Number of positive: 6600, number of negative: 6600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115842\n",
      "[LightGBM] [Info] Number of data points in the train set: 13200, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.491596\n",
      "[LightGBM] [Info] Number of positive: 10730, number of negative: 10729\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116035\n",
      "[LightGBM] [Info] Number of data points in the train set: 21459, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500023 -> initscore=0.000093\n",
      "[LightGBM] [Info] Start training from score 0.000093\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's binary_logloss: 0.481817\n",
      "[LightGBM] [Info] Number of positive: 10826, number of negative: 10826\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115986\n",
      "[LightGBM] [Info] Number of data points in the train set: 21652, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's binary_logloss: 0.541005\n",
      "[LightGBM] [Info] Number of positive: 12037, number of negative: 12036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116045\n",
      "[LightGBM] [Info] Number of data points in the train set: 24073, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000083\n",
      "[LightGBM] [Info] Start training from score 0.000083\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's binary_logloss: 0.539211\n",
      "[LightGBM] [Info] Number of positive: 9172, number of negative: 9172\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115901\n",
      "[LightGBM] [Info] Number of data points in the train set: 18344, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's binary_logloss: 0.470997\n",
      "[LightGBM] [Info] Number of positive: 8166, number of negative: 8165\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115999\n",
      "[LightGBM] [Info] Number of data points in the train set: 16331, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500031 -> initscore=0.000122\n",
      "[LightGBM] [Info] Start training from score 0.000122\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.499574\n",
      "[LightGBM] [Info] Number of positive: 13238, number of negative: 13238\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116160\n",
      "[LightGBM] [Info] Number of data points in the train set: 26476, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.445887\n",
      "[LightGBM] [Info] Number of positive: 9965, number of negative: 9964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116132\n",
      "[LightGBM] [Info] Number of data points in the train set: 19929, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's binary_logloss: 0.463668\n",
      "[LightGBM] [Info] Number of positive: 7600, number of negative: 7600\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115901\n",
      "[LightGBM] [Info] Number of data points in the train set: 15200, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.489679\n",
      "[LightGBM] [Info] Number of positive: 10583, number of negative: 10583\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115907\n",
      "[LightGBM] [Info] Number of data points in the train set: 21166, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's binary_logloss: 0.556139\n",
      "[LightGBM] [Info] Number of positive: 12859, number of negative: 12859\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116090\n",
      "[LightGBM] [Info] Number of data points in the train set: 25718, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's binary_logloss: 0.529772\n",
      "[LightGBM] [Info] Number of positive: 11746, number of negative: 11745\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116089\n",
      "[LightGBM] [Info] Number of data points in the train set: 23491, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500021 -> initscore=0.000085\n",
      "[LightGBM] [Info] Start training from score 0.000085\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's binary_logloss: 0.480045\n",
      "[LightGBM] [Info] Number of positive: 10036, number of negative: 10036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115898\n",
      "[LightGBM] [Info] Number of data points in the train set: 20072, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's binary_logloss: 0.510649\n",
      "[LightGBM] [Info] Number of positive: 8275, number of negative: 8275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115775\n",
      "[LightGBM] [Info] Number of data points in the train set: 16550, number of used features: 473\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's binary_logloss: 0.540183\n",
      "[LightGBM] [Info] Number of positive: 8154, number of negative: 8153\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115995\n",
      "[LightGBM] [Info] Number of data points in the train set: 16307, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500031 -> initscore=0.000123\n",
      "[LightGBM] [Info] Start training from score 0.000123\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's binary_logloss: 0.426663\n",
      "[LightGBM] [Info] Number of positive: 9420, number of negative: 9420\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115947\n",
      "[LightGBM] [Info] Number of data points in the train set: 18840, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's binary_logloss: 0.56751\n",
      "[LightGBM] [Info] Number of positive: 12758, number of negative: 12757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115918\n",
      "[LightGBM] [Info] Number of data points in the train set: 25515, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500020 -> initscore=0.000078\n",
      "[LightGBM] [Info] Start training from score 0.000078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's binary_logloss: 0.50662\n",
      "[LightGBM] [Info] Number of positive: 11318, number of negative: 11317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116036\n",
      "[LightGBM] [Info] Number of data points in the train set: 22635, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500022 -> initscore=0.000088\n",
      "[LightGBM] [Info] Start training from score 0.000088\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's binary_logloss: 0.487753\n",
      "[LightGBM] [Info] Number of positive: 10049, number of negative: 10048\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115980\n",
      "[LightGBM] [Info] Number of data points in the train set: 20097, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500025 -> initscore=0.000100\n",
      "[LightGBM] [Info] Start training from score 0.000100\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's binary_logloss: 0.485535\n",
      "[LightGBM] [Info] Number of positive: 10715, number of negative: 10715\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115945\n",
      "[LightGBM] [Info] Number of data points in the train set: 21430, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's binary_logloss: 0.508503\n",
      "[LightGBM] [Info] Number of positive: 11052, number of negative: 11052\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 115932\n",
      "[LightGBM] [Info] Number of data points in the train set: 22104, number of used features: 474\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's binary_logloss: 0.580013\n",
      "[LightGBM] [Info] Number of positive: 13071, number of negative: 13071\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116045\n",
      "[LightGBM] [Info] Number of data points in the train set: 26142, number of used features: 475\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's binary_logloss: 0.533424\n"
     ]
    }
   ],
   "source": [
    "experiment_base_name = 'Tsfresh_InflCovidNC'\n",
    "experiment_name = 'CovidNC'\n",
    "experiment_dir = resultdir / experiment_base_name / experiment_name\n",
    "os.makedirs(experiment_dir, exist_ok=True) \n",
    "\n",
    "pid_random_states = range(0,300)  # 300 random states for PID sampling\n",
    "us_random_state = 0  # Random state for under-sampling\n",
    "tv_random_state = 0  # Random state for train/validation split\n",
    "evalfunc = partial(f1_score, average='macro')  # Evaluation function\n",
    "n_pid_split_dict = {'covid': [20, 20], 'nc': [20, 20]}  # Number of train/test samples per class\n",
    "labels = list(n_pid_split_dict.keys())  # Class labels\n",
    "num_class = len(n_pid_split_dict)  # Number of classes\n",
    "le = LabelEncoder()  # Label encoder\n",
    "le.fit(labels)    \n",
    "label_column = 'label'\n",
    "\n",
    "for i, (df_X, df_y, splitted_pids, splitted_pidlabels) \\\n",
    "    in enumerate(kentai.generate_dfxypidspidlabels(\n",
    "            n_pid_split_dict, random_states=pid_random_states, label_column=label_column)):\n",
    "\n",
    "    outputdirname = 'ex-division' + str(i).zfill(2)  # Name of the directory where results will be saved\n",
    "    outputdir = experiment_dir / outputdirname       # Directory where results will be saved\n",
    "    os.makedirs(outputdir, exist_ok=True)           # Create it if it does not exist\n",
    "\n",
    "    # Save PIDs used in the experiment\n",
    "    splitted_pidsfilepath = outputdir / 'splitted_pids.csv'\n",
    "    with open(splitted_pidsfilepath, mode='w') as f:\n",
    "        for pids in splitted_pids:\n",
    "            # Without reshape, it would not be comma-separated but written line by line\n",
    "            np.savetxt(f, np.array(pids).reshape(1, -1), delimiter=',', fmt='%d')\n",
    "\n",
    "    # Save PID labels used in the experiment\n",
    "    splitted_pidlabelsfilepath = outputdir / 'splitted_pidlabels.csv'  # File to store PIDs used in the experiment\n",
    "    with open(splitted_pidlabelsfilepath, mode='w') as f:\n",
    "        for pidlabels in splitted_pidlabels:\n",
    "            # Without reshape, it would not be comma-separated but written line by line\n",
    "            np.savetxt(f, np.array(pidlabels).reshape(1, -1), delimiter=',', fmt='%s')\n",
    "\n",
    "    df_X_train, df_X_test = df_X  # Feature vectors for each instance\n",
    "    df_y_train, df_y_test = df_y  # Labels for each instance\n",
    "    pids_train, pids_test = splitted_pids  # PIDs used for train/test\n",
    "    pidlabels_train, pidlabels_test = splitted_pidlabels  # Labels of PIDs used for train/test\n",
    "\n",
    "    # RandomUnderSampling without NR\n",
    "    rus = RandomUnderSampler(random_state=us_random_state)\n",
    "    df_X_train_resampled, y_train_resampled = rus.fit_resample(df_X_train, df_y_train[label_column])\n",
    "    df_y_train_resampled = df_y_train.loc[df_X_train_resampled.index]\n",
    "\n",
    "    # Split validation data for early_stopping_rounds\n",
    "    df_X_train_resampled_train, df_X_train_resampled_valid, \\\n",
    "    df_y_train_resampled_train, df_y_train_resampled_valid = \\\n",
    "        train_test_split(df_X_train_resampled, df_y_train_resampled, test_size=0.2,\n",
    "                         random_state=tv_random_state,\n",
    "                         stratify=df_y_train_resampled[label_column])\n",
    "\n",
    "    # Set parameters\n",
    "    if len(n_pid_split_dict) == 2:\n",
    "        objective = 'binary'\n",
    "        metric = 'binary_logloss'\n",
    "        num_class = 1  # Number of classes (for binary it is 1)\n",
    "        eval_metric = 'binary_logloss'\n",
    "    else:\n",
    "        objective = 'multiclass'\n",
    "        metric = 'multi_logloss'\n",
    "        num_class = len(n_pid_split_dict)  # Number of classes\n",
    "        eval_metric = 'multi_logloss'\n",
    "\n",
    "    lgb_params = {\n",
    "        'n_estimators': 10000,\n",
    "        'objective': objective,\n",
    "        'metric': metric,\n",
    "        'num_class': num_class,  # Number of classes\n",
    "        'seed': 0\n",
    "    }\n",
    "        \n",
    "    fit_params = {\n",
    "        'eval_metric': eval_metric,  # Metric used for early_stopping_rounds\n",
    "        'eval_set': [(df_X_train_resampled_valid.to_numpy(),\n",
    "                      df_y_train_resampled_valid[label_column])],\n",
    "        'callbacks': [lgb.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "    }\n",
    "\n",
    "    # Train classifier\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(df_X_train_resampled_train.values,\n",
    "            df_y_train_resampled_train[label_column],\n",
    "            **fit_params)\n",
    "\n",
    "    # Instance-level results\n",
    "    y_pred_probs = clf.predict_proba(df_X_test)  # Predicted probabilities for each label\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)     # Predicted label indices\n",
    "    y_pred = le.inverse_transform(y_pred)        # Decode labels\n",
    "\n",
    "    # Save instance-level results\n",
    "    case_pred_probs_path = outputdir / 'case_nonr_pred_probs.csv'  # File to save predicted probabilities per instance\n",
    "    df_case_nonr_pred_probs = pd.DataFrame(y_pred_probs, columns=labels)\n",
    "    df_case_nonr_pred_probs.to_csv(case_pred_probs_path, index=None)\n",
    "\n",
    "    case_nonr_true_pred_path = outputdir / 'case_nonr_true_pred.csv'  # File to save true and predicted labels per instance\n",
    "    df_case_nonr_true_pred = pd.DataFrame(\n",
    "        np.array([df_y_test[label_column], y_pred]).T,\n",
    "        columns=(['true', 'pred'])\n",
    "    )\n",
    "    df_case_nonr_true_pred.to_csv(case_nonr_true_pred_path, index=None)\n",
    "    lgbmtools.save_clrep_confmat(df_y_test[label_column], y_pred, labels,\n",
    "                                 filenamehead='case_nonr', outputdir=outputdir)\n",
    "\n",
    "    # PID-level results\n",
    "\n",
    "    # Compute predicted probabilities aggregated by PID\n",
    "    # pidlabels_pred_probs = pred_ratio_bypid(pids_test, df_y_test['pid'], y_pred, labels)  # Prediction ratio per PID\n",
    "    pidlabels_pred_probs = lgbmtools.pred_probsum_bypid(\n",
    "        pids_test,\n",
    "        df_y_test['pid'].to_numpy(),\n",
    "        y_pred_probs,\n",
    "        labels\n",
    "    )  # Sum of prediction probabilities per PID\n",
    "\n",
    "    df_pidlabels_pred_probs = pd.DataFrame(pidlabels_pred_probs, columns=labels)\n",
    "    # Save\n",
    "    pid_pred_probs_path = outputdir / 'pid_nonr_pred_probs.csv'  # File to save prediction probabilities per PID\n",
    "    df_pidlabels_pred_probs.to_csv(pid_pred_probs_path, index=None)            \n",
    "        \n",
    "    # Predicted labels per PID\n",
    "    pidlabels_pred = np.argmax(pidlabels_pred_probs, axis=1)  # Predicted label indices\n",
    "    pidlabels_pred = le.inverse_transform(pidlabels_pred)     # Decode labels\n",
    "    df_pids_pidlabels_pidpred = pd.DataFrame(\n",
    "        np.array([pids_test, pidlabels_test, pidlabels_pred]).T,\n",
    "        columns=(['pid', 'true', 'pred'])\n",
    "    )\n",
    "    # Save\n",
    "    pids_pidlabels_pidpred_path = outputdir / 'pid_nonr_true_pred.csv'  # File to save true and predicted labels per PID\n",
    "    df_pids_pidlabels_pidpred.to_csv(pids_pidlabels_pidpred_path, index=None)\n",
    "\n",
    "    # Evaluation metrics (PID-level)\n",
    "    lgbmtools.save_clrep_confmat(\n",
    "        pidlabels_test,\n",
    "        pidlabels_pred,\n",
    "        labels,\n",
    "        filenamehead='pid_nonr',\n",
    "        outputdir=outputdir\n",
    "    )\n",
    "\n",
    "    # Predictions on validation data\n",
    "    y_pred_prob1 = clf.predict_proba(df_X_train_resampled_valid)\n",
    "    y_pred1 = np.argmax(y_pred_prob1, axis=1)\n",
    "    y_pred1 = le.inverse_transform(y_pred1)\n",
    "\n",
    "    # Save classification report and confusion matrix for validation data\n",
    "    lgbmtools.save_clrep_confmat(\n",
    "        df_y_train_resampled_valid[label_column],\n",
    "        y_pred1,\n",
    "        labels,\n",
    "        filenamehead='case_nonr_valid',\n",
    "        outputdir=outputdir\n",
    "    )\n",
    "\n",
    "    # Save validation instances\n",
    "    y_pred_prob1_path = outputdir / 'case_nonr_valid_pred_probs.csv'\n",
    "    df_case_nonr_pred_prob1 = pd.DataFrame(y_pred_prob1, columns=labels)\n",
    "    df_case_nonr_pred_prob1.to_csv(y_pred_prob1_path, index=None)\n",
    "\n",
    "    case_nonr_true_pred1_path = outputdir / 'case_nonr_valid_true_pred.csv'\n",
    "    df_case_nonr_true_pred1 = pd.DataFrame(\n",
    "        np.array([df_y_train_resampled_valid[label_column], y_pred1]).T,\n",
    "        columns=(['true', 'pred'])\n",
    "    )\n",
    "    df_case_nonr_true_pred1.to_csv(case_nonr_true_pred1_path, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12507c27-7b75-42ba-b56f-bdd7b320dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_nonr\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x2500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.599989</td>\n",
       "      <td>0.591102</td>\n",
       "      <td>0.608737</td>\n",
       "      <td>0.614098</td>\n",
       "      <td>0.614098</td>\n",
       "      <td>0.614098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047659</td>\n",
       "      <td>0.045085</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>0.038513</td>\n",
       "      <td>0.038513</td>\n",
       "      <td>0.038513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.423681</td>\n",
       "      <td>0.406223</td>\n",
       "      <td>0.468769</td>\n",
       "      <td>0.469855</td>\n",
       "      <td>0.469855</td>\n",
       "      <td>0.469855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.571843</td>\n",
       "      <td>0.566382</td>\n",
       "      <td>0.585824</td>\n",
       "      <td>0.589082</td>\n",
       "      <td>0.589082</td>\n",
       "      <td>0.589082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.604937</td>\n",
       "      <td>0.594202</td>\n",
       "      <td>0.611736</td>\n",
       "      <td>0.619172</td>\n",
       "      <td>0.619172</td>\n",
       "      <td>0.619172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.633279</td>\n",
       "      <td>0.622404</td>\n",
       "      <td>0.632702</td>\n",
       "      <td>0.641685</td>\n",
       "      <td>0.641685</td>\n",
       "      <td>0.641685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.703141</td>\n",
       "      <td>0.69192</td>\n",
       "      <td>0.694468</td>\n",
       "      <td>0.711332</td>\n",
       "      <td>0.711332</td>\n",
       "      <td>0.711332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max file</th>\n",
       "      <td>ex-division173</td>\n",
       "      <td>ex-division52</td>\n",
       "      <td>ex-division52</td>\n",
       "      <td>ex-division52</td>\n",
       "      <td>ex-division52</td>\n",
       "      <td>ex-division52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy       f1-score      precision         recall  \\\n",
       "count              300.0          300.0          300.0          300.0   \n",
       "mean            0.599989       0.591102       0.608737       0.614098   \n",
       "std             0.047659       0.045085       0.035012       0.038513   \n",
       "min             0.423681       0.406223       0.468769       0.469855   \n",
       "25%             0.571843       0.566382       0.585824       0.589082   \n",
       "50%             0.604937       0.594202       0.611736       0.619172   \n",
       "75%             0.633279       0.622404       0.632702       0.641685   \n",
       "max             0.703141        0.69192       0.694468       0.711332   \n",
       "max file  ex-division173  ex-division52  ex-division52  ex-division52   \n",
       "\n",
       "            sensitivity    specificity  \n",
       "count             300.0          300.0  \n",
       "mean           0.614098       0.614098  \n",
       "std            0.038513       0.038513  \n",
       "min            0.469855       0.469855  \n",
       "25%            0.589082       0.589082  \n",
       "50%            0.619172       0.619172  \n",
       "75%            0.641685       0.641685  \n",
       "max            0.711332       0.711332  \n",
       "max file  ex-division52  ex-division52  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covid</th>\n",
       "      <th>nc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>15839</td>\n",
       "      <td>7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc</th>\n",
       "      <td>3270</td>\n",
       "      <td>9824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       covid    nc\n",
       "covid  15839  7717\n",
       "nc      3270  9824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid_nonr\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x2500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.64126</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.66075</td>\n",
       "      <td>0.66075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.079288</td>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.07548</td>\n",
       "      <td>0.07548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.386602</td>\n",
       "      <td>0.440476</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.579218</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.648411</td>\n",
       "      <td>0.70101</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.699248</td>\n",
       "      <td>0.757412</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.89899</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max file</th>\n",
       "      <td>ex-division207</td>\n",
       "      <td>ex-division207</td>\n",
       "      <td>ex-division207</td>\n",
       "      <td>ex-division207</td>\n",
       "      <td>ex-division207</td>\n",
       "      <td>ex-division207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                accuracy        f1-score       precision          recall  \\\n",
       "count              300.0           300.0           300.0           300.0   \n",
       "mean             0.66075         0.64126        0.697593         0.66075   \n",
       "std              0.07548        0.089723        0.079288         0.07548   \n",
       "min                 0.45        0.386602        0.440476            0.45   \n",
       "25%                  0.6        0.579218            0.65             0.6   \n",
       "50%                0.675        0.648411         0.70101           0.675   \n",
       "75%                  0.7        0.699248        0.757412             0.7   \n",
       "max                  0.9         0.89899        0.916667             0.9   \n",
       "max file  ex-division207  ex-division207  ex-division207  ex-division207   \n",
       "\n",
       "             sensitivity     specificity  \n",
       "count              300.0           300.0  \n",
       "mean             0.66075         0.66075  \n",
       "std              0.07548         0.07548  \n",
       "min                 0.45            0.45  \n",
       "25%                  0.6             0.6  \n",
       "50%                0.675           0.675  \n",
       "75%                  0.7             0.7  \n",
       "max                  0.9             0.9  \n",
       "max file  ex-division207  ex-division207  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covid</th>\n",
       "      <th>nc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       covid  nc\n",
       "covid     16   4\n",
       "nc         0  20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbmtools.calc_save_ave_2class_maxf1(experiment_dir, labels, target_label='macro avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe43e754-d4cb-40bb-8f20-d7b69b66ae91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116398\n",
      "[LightGBM] [Info] Number of data points in the train set: 41064, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's multi_logloss: 0.744108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116371\n",
      "[LightGBM] [Info] Number of data points in the train set: 32551, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's multi_logloss: 0.720396\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116239\n",
      "[LightGBM] [Info] Number of data points in the train set: 33237, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.816088\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116241\n",
      "[LightGBM] [Info] Number of data points in the train set: 28759, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.791218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116196\n",
      "[LightGBM] [Info] Number of data points in the train set: 26827, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's multi_logloss: 0.75428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116282\n",
      "[LightGBM] [Info] Number of data points in the train set: 32460, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's multi_logloss: 0.783826\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116295\n",
      "[LightGBM] [Info] Number of data points in the train set: 30672, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 0.782518\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116302\n",
      "[LightGBM] [Info] Number of data points in the train set: 30688, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098547\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.755556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116146\n",
      "[LightGBM] [Info] Number of data points in the train set: 26215, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's multi_logloss: 0.863103\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116294\n",
      "[LightGBM] [Info] Number of data points in the train set: 32227, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 0.783652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116281\n",
      "[LightGBM] [Info] Number of data points in the train set: 29733, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's multi_logloss: 0.778707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116296\n",
      "[LightGBM] [Info] Number of data points in the train set: 31236, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.756727\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116192\n",
      "[LightGBM] [Info] Number of data points in the train set: 31624, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.834656\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116222\n",
      "[LightGBM] [Info] Number of data points in the train set: 25699, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098651\n",
      "[LightGBM] [Info] Start training from score -1.098651\n",
      "[LightGBM] [Info] Start training from score -1.098534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 0.781461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116353\n",
      "[LightGBM] [Info] Number of data points in the train set: 34116, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.765487\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116232\n",
      "[LightGBM] [Info] Number of data points in the train set: 30840, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's multi_logloss: 0.770591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 33136, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 0.845422\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116245\n",
      "[LightGBM] [Info] Number of data points in the train set: 31924, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.86338\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116178\n",
      "[LightGBM] [Info] Number of data points in the train set: 30098, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 0.87269\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116191\n",
      "[LightGBM] [Info] Number of data points in the train set: 24345, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 0.833628\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116411\n",
      "[LightGBM] [Info] Number of data points in the train set: 40406, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098662\n",
      "[LightGBM] [Info] Start training from score -1.098588\n",
      "[LightGBM] [Info] Start training from score -1.098588\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.735774\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116189\n",
      "[LightGBM] [Info] Number of data points in the train set: 29884, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's multi_logloss: 0.856575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116291\n",
      "[LightGBM] [Info] Number of data points in the train set: 35431, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's multi_logloss: 0.728675\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 25874, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098690\n",
      "[LightGBM] [Info] Start training from score -1.098574\n",
      "[LightGBM] [Info] Start training from score -1.098574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.77169\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116289\n",
      "[LightGBM] [Info] Number of data points in the train set: 38284, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's multi_logloss: 0.824812\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116304\n",
      "[LightGBM] [Info] Number of data points in the train set: 30609, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.802549\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116173\n",
      "[LightGBM] [Info] Number of data points in the train set: 29335, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's multi_logloss: 0.803776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 36756, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's multi_logloss: 0.804755\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116353\n",
      "[LightGBM] [Info] Number of data points in the train set: 38450, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098664\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's multi_logloss: 0.68857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116298\n",
      "[LightGBM] [Info] Number of data points in the train set: 32798, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098673\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.762064\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116265\n",
      "[LightGBM] [Info] Number of data points in the train set: 34912, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's multi_logloss: 0.873297\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 31257, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's multi_logloss: 0.809136\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116229\n",
      "[LightGBM] [Info] Number of data points in the train set: 30573, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 0.834141\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116235\n",
      "[LightGBM] [Info] Number of data points in the train set: 33703, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 0.737901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116325\n",
      "[LightGBM] [Info] Number of data points in the train set: 38719, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's multi_logloss: 0.748411\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116188\n",
      "[LightGBM] [Info] Number of data points in the train set: 24290, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098695\n",
      "[LightGBM] [Info] Start training from score -1.098571\n",
      "[LightGBM] [Info] Start training from score -1.098571\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's multi_logloss: 0.784757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116187\n",
      "[LightGBM] [Info] Number of data points in the train set: 31480, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's multi_logloss: 0.793707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116402\n",
      "[LightGBM] [Info] Number of data points in the train set: 42698, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098659\n",
      "[LightGBM] [Info] Start training from score -1.098589\n",
      "[LightGBM] [Info] Start training from score -1.098589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.836824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116243\n",
      "[LightGBM] [Info] Number of data points in the train set: 25339, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's multi_logloss: 0.779413\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116181\n",
      "[LightGBM] [Info] Number of data points in the train set: 35032, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.83581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116235\n",
      "[LightGBM] [Info] Number of data points in the train set: 26709, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.794756\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 32390, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098674\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.768507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116216\n",
      "[LightGBM] [Info] Number of data points in the train set: 27244, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098539\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 0.815652\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116298\n",
      "[LightGBM] [Info] Number of data points in the train set: 30948, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 0.762509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116171\n",
      "[LightGBM] [Info] Number of data points in the train set: 25620, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.794405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116234\n",
      "[LightGBM] [Info] Number of data points in the train set: 25267, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.777937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116207\n",
      "[LightGBM] [Info] Number of data points in the train set: 30782, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098677\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 0.79304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116458\n",
      "[LightGBM] [Info] Number of data points in the train set: 42554, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098659\n",
      "[LightGBM] [Info] Start training from score -1.098589\n",
      "[LightGBM] [Info] Start training from score -1.098589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_logloss: 0.806986\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116157\n",
      "[LightGBM] [Info] Number of data points in the train set: 25857, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.78143\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116249\n",
      "[LightGBM] [Info] Number of data points in the train set: 31912, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.808258\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116216\n",
      "[LightGBM] [Info] Number of data points in the train set: 33412, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 0.863762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116139\n",
      "[LightGBM] [Info] Number of data points in the train set: 28147, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 0.909655\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116370\n",
      "[LightGBM] [Info] Number of data points in the train set: 39012, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.845548\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 34046, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098671\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's multi_logloss: 0.805718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116258\n",
      "[LightGBM] [Info] Number of data points in the train set: 24225, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 0.786498\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116025\n",
      "[LightGBM] [Info] Number of data points in the train set: 22363, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098657\n",
      "[LightGBM] [Info] Start training from score -1.098657\n",
      "[LightGBM] [Info] Start training from score -1.098523\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 0.776423\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 32311, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 0.869586\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116367\n",
      "[LightGBM] [Info] Number of data points in the train set: 39808, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.856007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116402\n",
      "[LightGBM] [Info] Number of data points in the train set: 32438, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098674\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's multi_logloss: 0.769832\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116260\n",
      "[LightGBM] [Info] Number of data points in the train set: 28975, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.757209\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 38356, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's multi_logloss: 0.814517\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116313\n",
      "[LightGBM] [Info] Number of data points in the train set: 29018, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098681\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's multi_logloss: 0.806841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 32844, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's multi_logloss: 0.809095\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116225\n",
      "[LightGBM] [Info] Number of data points in the train set: 31953, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's multi_logloss: 0.80738\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116170\n",
      "[LightGBM] [Info] Number of data points in the train set: 28718, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098682\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.825887\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116324\n",
      "[LightGBM] [Info] Number of data points in the train set: 32148, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid_0's multi_logloss: 0.762431\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116282\n",
      "[LightGBM] [Info] Number of data points in the train set: 34276, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's multi_logloss: 0.799207\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 31718, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098675\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.732575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116246\n",
      "[LightGBM] [Info] Number of data points in the train set: 33319, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.775614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 41414, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098661\n",
      "[LightGBM] [Info] Start training from score -1.098588\n",
      "[LightGBM] [Info] Start training from score -1.098588\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's multi_logloss: 0.733831\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116305\n",
      "[LightGBM] [Info] Number of data points in the train set: 30148, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.78405\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116310\n",
      "[LightGBM] [Info] Number of data points in the train set: 32155, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 0.832422\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116310\n",
      "[LightGBM] [Info] Number of data points in the train set: 28908, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's multi_logloss: 0.733456\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116296\n",
      "[LightGBM] [Info] Number of data points in the train set: 33984, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[309]\tvalid_0's multi_logloss: 0.827723\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116295\n",
      "[LightGBM] [Info] Number of data points in the train set: 32779, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.833141\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116257\n",
      "[LightGBM] [Info] Number of data points in the train set: 27842, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098684\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 0.800493\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116218\n",
      "[LightGBM] [Info] Number of data points in the train set: 28627, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098542\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.827544\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116294\n",
      "[LightGBM] [Info] Number of data points in the train set: 29323, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.782354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116202\n",
      "[LightGBM] [Info] Number of data points in the train set: 28156, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.843162\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 28068, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.776086\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116239\n",
      "[LightGBM] [Info] Number of data points in the train set: 35208, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's multi_logloss: 0.820722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116176\n",
      "[LightGBM] [Info] Number of data points in the train set: 28915, number of used features: 473\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.87117\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116226\n",
      "[LightGBM] [Info] Number of data points in the train set: 29476, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's multi_logloss: 0.886542\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116224\n",
      "[LightGBM] [Info] Number of data points in the train set: 26558, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 0.858466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 30396, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.80791\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116146\n",
      "[LightGBM] [Info] Number of data points in the train set: 25629, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.808785\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116222\n",
      "[LightGBM] [Info] Number of data points in the train set: 29366, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098680\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.813848\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116220\n",
      "[LightGBM] [Info] Number of data points in the train set: 32248, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's multi_logloss: 0.791712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116311\n",
      "[LightGBM] [Info] Number of data points in the train set: 31656, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.798554\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 33837, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's multi_logloss: 0.736579\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 29644, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.781782\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116354\n",
      "[LightGBM] [Info] Number of data points in the train set: 37152, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's multi_logloss: 0.778863\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116271\n",
      "[LightGBM] [Info] Number of data points in the train set: 31053, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 0.859008\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116276\n",
      "[LightGBM] [Info] Number of data points in the train set: 35032, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's multi_logloss: 0.791323\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116402\n",
      "[LightGBM] [Info] Number of data points in the train set: 35162, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's multi_logloss: 0.80247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 37704, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's multi_logloss: 0.73569\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116252\n",
      "[LightGBM] [Info] Number of data points in the train set: 34207, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.84267\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116065\n",
      "[LightGBM] [Info] Number of data points in the train set: 23364, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.847831\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116312\n",
      "[LightGBM] [Info] Number of data points in the train set: 29896, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's multi_logloss: 0.740672\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116270\n",
      "[LightGBM] [Info] Number of data points in the train set: 29920, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 0.772208\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116165\n",
      "[LightGBM] [Info] Number of data points in the train set: 25488, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.798179\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116213\n",
      "[LightGBM] [Info] Number of data points in the train set: 32080, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.731207\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116229\n",
      "[LightGBM] [Info] Number of data points in the train set: 32656, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.727016\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116292\n",
      "[LightGBM] [Info] Number of data points in the train set: 36175, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's multi_logloss: 0.709112\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116414\n",
      "[LightGBM] [Info] Number of data points in the train set: 37574, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098666\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[279]\tvalid_0's multi_logloss: 0.786831\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116367\n",
      "[LightGBM] [Info] Number of data points in the train set: 36943, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's multi_logloss: 0.802934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 35203, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's multi_logloss: 0.794724\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116310\n",
      "[LightGBM] [Info] Number of data points in the train set: 29008, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's multi_logloss: 0.738496\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116209\n",
      "[LightGBM] [Info] Number of data points in the train set: 32652, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_logloss: 0.865722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 34248, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[338]\tvalid_0's multi_logloss: 0.777481\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116468\n",
      "[LightGBM] [Info] Number of data points in the train set: 34584, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's multi_logloss: 0.779303\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116284\n",
      "[LightGBM] [Info] Number of data points in the train set: 33535, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 0.754726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116257\n",
      "[LightGBM] [Info] Number of data points in the train set: 33871, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 0.844173\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116223\n",
      "[LightGBM] [Info] Number of data points in the train set: 28932, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.919583\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116194\n",
      "[LightGBM] [Info] Number of data points in the train set: 28828, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.744935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116410\n",
      "[LightGBM] [Info] Number of data points in the train set: 37891, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's multi_logloss: 0.810167\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 29092, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 0.775214\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116301\n",
      "[LightGBM] [Info] Number of data points in the train set: 35102, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.79753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116280\n",
      "[LightGBM] [Info] Number of data points in the train set: 28200, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.767722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116085\n",
      "[LightGBM] [Info] Number of data points in the train set: 29416, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.823615\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116111\n",
      "[LightGBM] [Info] Number of data points in the train set: 22120, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098657\n",
      "[LightGBM] [Info] Start training from score -1.098657\n",
      "[LightGBM] [Info] Start training from score -1.098522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.825226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116502\n",
      "[LightGBM] [Info] Number of data points in the train set: 36859, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 0.754041\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 31896, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.728199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 32928, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.860608\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116316\n",
      "[LightGBM] [Info] Number of data points in the train set: 31418, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.801038\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116246\n",
      "[LightGBM] [Info] Number of data points in the train set: 34051, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's multi_logloss: 0.837231\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116335\n",
      "[LightGBM] [Info] Number of data points in the train set: 35848, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's multi_logloss: 0.773469\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116302\n",
      "[LightGBM] [Info] Number of data points in the train set: 38940, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.765526\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116154\n",
      "[LightGBM] [Info] Number of data points in the train set: 23985, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's multi_logloss: 0.735049\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116254\n",
      "[LightGBM] [Info] Number of data points in the train set: 31440, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's multi_logloss: 0.847801\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 29462, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098680\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_logloss: 0.73479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116279\n",
      "[LightGBM] [Info] Number of data points in the train set: 30453, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's multi_logloss: 0.781135\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116263\n",
      "[LightGBM] [Info] Number of data points in the train set: 28437, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.831424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 31620, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.77402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116244\n",
      "[LightGBM] [Info] Number of data points in the train set: 31065, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.832908\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116226\n",
      "[LightGBM] [Info] Number of data points in the train set: 34699, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.838061\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116205\n",
      "[LightGBM] [Info] Number of data points in the train set: 31783, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.774891\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 29659, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's multi_logloss: 0.836537\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116231\n",
      "[LightGBM] [Info] Number of data points in the train set: 23659, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098655\n",
      "[LightGBM] [Info] Start training from score -1.098655\n",
      "[LightGBM] [Info] Start training from score -1.098528\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.84661\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116386\n",
      "[LightGBM] [Info] Number of data points in the train set: 36127, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 0.791134\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 29757, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's multi_logloss: 0.780901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 33475, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.796841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116278\n",
      "[LightGBM] [Info] Number of data points in the train set: 33537, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.805776\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 38344, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's multi_logloss: 0.748308\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116372\n",
      "[LightGBM] [Info] Number of data points in the train set: 35294, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[384]\tvalid_0's multi_logloss: 0.7388\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 29284, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's multi_logloss: 0.835257\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116129\n",
      "[LightGBM] [Info] Number of data points in the train set: 26877, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.849689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 33218, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098672\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's multi_logloss: 0.805737\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116244\n",
      "[LightGBM] [Info] Number of data points in the train set: 35052, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's multi_logloss: 0.838351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116278\n",
      "[LightGBM] [Info] Number of data points in the train set: 34567, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 0.782844\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116213\n",
      "[LightGBM] [Info] Number of data points in the train set: 33638, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098672\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's multi_logloss: 0.88472\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116215\n",
      "[LightGBM] [Info] Number of data points in the train set: 29349, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.811694\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 27136, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098539\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's multi_logloss: 0.713622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116325\n",
      "[LightGBM] [Info] Number of data points in the train set: 35623, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's multi_logloss: 0.761948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116229\n",
      "[LightGBM] [Info] Number of data points in the train set: 36981, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's multi_logloss: 0.756455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 33230, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098672\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.868653\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116215\n",
      "[LightGBM] [Info] Number of data points in the train set: 32832, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.829576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 31406, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.832079\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 36036, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_logloss: 0.883565\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116252\n",
      "[LightGBM] [Info] Number of data points in the train set: 34872, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.795714\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116226\n",
      "[LightGBM] [Info] Number of data points in the train set: 27960, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.817841\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116340\n",
      "[LightGBM] [Info] Number of data points in the train set: 34303, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's multi_logloss: 0.743975\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116256\n",
      "[LightGBM] [Info] Number of data points in the train set: 31416, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's multi_logloss: 0.794467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 31934, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098675\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 0.818065\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116214\n",
      "[LightGBM] [Info] Number of data points in the train set: 39580, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's multi_logloss: 0.788997\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116457\n",
      "[LightGBM] [Info] Number of data points in the train set: 47731, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098633\n",
      "[LightGBM] [Info] Start training from score -1.098633\n",
      "[LightGBM] [Info] Start training from score -1.098570\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.798138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 30780, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's multi_logloss: 0.774939\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116218\n",
      "[LightGBM] [Info] Number of data points in the train set: 29424, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.856369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 29690, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098680\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's multi_logloss: 0.741847\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116297\n",
      "[LightGBM] [Info] Number of data points in the train set: 35301, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.849039\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116195\n",
      "[LightGBM] [Info] Number of data points in the train set: 26332, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098536\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.793617\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116223\n",
      "[LightGBM] [Info] Number of data points in the train set: 29810, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.710734\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116212\n",
      "[LightGBM] [Info] Number of data points in the train set: 31944, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 0.826036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116352\n",
      "[LightGBM] [Info] Number of data points in the train set: 37639, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 0.840807\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116180\n",
      "[LightGBM] [Info] Number of data points in the train set: 28932, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's multi_logloss: 0.767742\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116424\n",
      "[LightGBM] [Info] Number of data points in the train set: 38330, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098664\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's multi_logloss: 0.81106\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116292\n",
      "[LightGBM] [Info] Number of data points in the train set: 33758, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098672\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's multi_logloss: 0.794687\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116414\n",
      "[LightGBM] [Info] Number of data points in the train set: 42532, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098636\n",
      "[LightGBM] [Info] Start training from score -1.098636\n",
      "[LightGBM] [Info] Start training from score -1.098565\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's multi_logloss: 0.803499\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116136\n",
      "[LightGBM] [Info] Number of data points in the train set: 25360, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 0.895221\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 31185, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 0.855993\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116336\n",
      "[LightGBM] [Info] Number of data points in the train set: 37711, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.840233\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116434\n",
      "[LightGBM] [Info] Number of data points in the train set: 42456, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's multi_logloss: 0.769301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116393\n",
      "[LightGBM] [Info] Number of data points in the train set: 35193, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's multi_logloss: 0.710452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116255\n",
      "[LightGBM] [Info] Number of data points in the train set: 32313, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's multi_logloss: 0.842605\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116311\n",
      "[LightGBM] [Info] Number of data points in the train set: 25663, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098651\n",
      "[LightGBM] [Info] Start training from score -1.098651\n",
      "[LightGBM] [Info] Start training from score -1.098534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's multi_logloss: 0.763516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116223\n",
      "[LightGBM] [Info] Number of data points in the train set: 28569, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's multi_logloss: 0.786944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116287\n",
      "[LightGBM] [Info] Number of data points in the train set: 32140, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's multi_logloss: 0.823053\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116224\n",
      "[LightGBM] [Info] Number of data points in the train set: 29894, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's multi_logloss: 0.752604\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116298\n",
      "[LightGBM] [Info] Number of data points in the train set: 31497, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 0.722038\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 31687, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.775759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 34420, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.755559\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 28449, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.70505\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116450\n",
      "[LightGBM] [Info] Number of data points in the train set: 37084, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 0.741796\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116218\n",
      "[LightGBM] [Info] Number of data points in the train set: 30578, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098678\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 0.828422\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 35803, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.741489\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116157\n",
      "[LightGBM] [Info] Number of data points in the train set: 27782, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098684\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.811616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116280\n",
      "[LightGBM] [Info] Number of data points in the train set: 33720, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's multi_logloss: 0.787226\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116403\n",
      "[LightGBM] [Info] Number of data points in the train set: 37423, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 0.797183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116427\n",
      "[LightGBM] [Info] Number of data points in the train set: 36715, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's multi_logloss: 0.776192\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116214\n",
      "[LightGBM] [Info] Number of data points in the train set: 36907, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 0.815897\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 28819, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 0.802158\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116259\n",
      "[LightGBM] [Info] Number of data points in the train set: 30674, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098677\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.801354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116286\n",
      "[LightGBM] [Info] Number of data points in the train set: 34149, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.806586\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116353\n",
      "[LightGBM] [Info] Number of data points in the train set: 37411, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's multi_logloss: 0.778765\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116216\n",
      "[LightGBM] [Info] Number of data points in the train set: 29337, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 0.828492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116188\n",
      "[LightGBM] [Info] Number of data points in the train set: 29462, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098680\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.870097\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116193\n",
      "[LightGBM] [Info] Number of data points in the train set: 27732, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.832368\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116366\n",
      "[LightGBM] [Info] Number of data points in the train set: 30283, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.81464\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 36852, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's multi_logloss: 0.854971\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116300\n",
      "[LightGBM] [Info] Number of data points in the train set: 29800, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's multi_logloss: 0.771099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116478\n",
      "[LightGBM] [Info] Number of data points in the train set: 37329, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's multi_logloss: 0.784068\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116200\n",
      "[LightGBM] [Info] Number of data points in the train set: 32846, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098673\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.842747\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116227\n",
      "[LightGBM] [Info] Number of data points in the train set: 25797, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.826453\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 28795, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.769386\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116299\n",
      "[LightGBM] [Info] Number of data points in the train set: 28646, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098682\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.808007\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116182\n",
      "[LightGBM] [Info] Number of data points in the train set: 26268, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.796584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116341\n",
      "[LightGBM] [Info] Number of data points in the train set: 38978, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098664\n",
      "[LightGBM] [Info] Start training from score -1.098587\n",
      "[LightGBM] [Info] Start training from score -1.098587\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's multi_logloss: 0.811494\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 32378, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098674\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's multi_logloss: 0.860064\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116226\n",
      "[LightGBM] [Info] Number of data points in the train set: 31476, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 0.8376\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116184\n",
      "[LightGBM] [Info] Number of data points in the train set: 28320, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.767313\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 31156, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 0.817911\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116256\n",
      "[LightGBM] [Info] Number of data points in the train set: 33559, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.779482\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116185\n",
      "[LightGBM] [Info] Number of data points in the train set: 30825, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.833991\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116040\n",
      "[LightGBM] [Info] Number of data points in the train set: 24472, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 0.814321\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116397\n",
      "[LightGBM] [Info] Number of data points in the train set: 39189, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.771912\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116259\n",
      "[LightGBM] [Info] Number of data points in the train set: 30206, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.810528\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116227\n",
      "[LightGBM] [Info] Number of data points in the train set: 30396, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.738192\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116316\n",
      "[LightGBM] [Info] Number of data points in the train set: 31519, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 0.814902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116241\n",
      "[LightGBM] [Info] Number of data points in the train set: 27208, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098539\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's multi_logloss: 0.826781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 28348, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098542\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.781719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116280\n",
      "[LightGBM] [Info] Number of data points in the train set: 35107, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's multi_logloss: 0.781077\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116210\n",
      "[LightGBM] [Info] Number of data points in the train set: 31392, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.847648\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116270\n",
      "[LightGBM] [Info] Number of data points in the train set: 38239, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's multi_logloss: 0.767972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116135\n",
      "[LightGBM] [Info] Number of data points in the train set: 25094, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098692\n",
      "[LightGBM] [Info] Start training from score -1.098572\n",
      "[LightGBM] [Info] Start training from score -1.098572\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's multi_logloss: 0.879423\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116327\n",
      "[LightGBM] [Info] Number of data points in the train set: 34963, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 0.746532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116189\n",
      "[LightGBM] [Info] Number of data points in the train set: 28670, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098682\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 0.89624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116463\n",
      "[LightGBM] [Info] Number of data points in the train set: 36403, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's multi_logloss: 0.802535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116234\n",
      "[LightGBM] [Info] Number of data points in the train set: 24076, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098654\n",
      "[LightGBM] [Info] Start training from score -1.098654\n",
      "[LightGBM] [Info] Start training from score -1.098529\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's multi_logloss: 0.83236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116332\n",
      "[LightGBM] [Info] Number of data points in the train set: 35277, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[299]\tvalid_0's multi_logloss: 0.778403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 34279, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 0.781194\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 36477, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's multi_logloss: 0.789759\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116214\n",
      "[LightGBM] [Info] Number of data points in the train set: 25980, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.811525\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116160\n",
      "[LightGBM] [Info] Number of data points in the train set: 28512, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.794654\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116362\n",
      "[LightGBM] [Info] Number of data points in the train set: 35515, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's multi_logloss: 0.786459\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 34965, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.77488\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116389\n",
      "[LightGBM] [Info] Number of data points in the train set: 36004, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's multi_logloss: 0.763503\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 29462, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098680\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "[LightGBM] [Info] Start training from score -1.098578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's multi_logloss: 0.830078\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 34404, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 0.821415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116396\n",
      "[LightGBM] [Info] Number of data points in the train set: 41296, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[291]\tvalid_0's multi_logloss: 0.767903\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116196\n",
      "[LightGBM] [Info] Number of data points in the train set: 32743, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 0.76791\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116273\n",
      "[LightGBM] [Info] Number of data points in the train set: 32992, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's multi_logloss: 0.846441\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 30007, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.813022\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116170\n",
      "[LightGBM] [Info] Number of data points in the train set: 28896, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 0.860308\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116289\n",
      "[LightGBM] [Info] Number of data points in the train set: 27700, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098540\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.801628\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116168\n",
      "[LightGBM] [Info] Number of data points in the train set: 29884, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 0.820991\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116340\n",
      "[LightGBM] [Info] Number of data points in the train set: 32779, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 0.77869\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116400\n",
      "[LightGBM] [Info] Number of data points in the train set: 38032, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.743062\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 35666, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098668\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's multi_logloss: 0.770772\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116446\n",
      "[LightGBM] [Info] Number of data points in the train set: 32232, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's multi_logloss: 0.774213\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116437\n",
      "[LightGBM] [Info] Number of data points in the train set: 38690, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098664\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.773722\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116171\n",
      "[LightGBM] [Info] Number of data points in the train set: 22636, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098656\n",
      "[LightGBM] [Info] Start training from score -1.098656\n",
      "[LightGBM] [Info] Start training from score -1.098524\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's multi_logloss: 0.717093\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116364\n",
      "[LightGBM] [Info] Number of data points in the train set: 35695, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.836182\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116149\n",
      "[LightGBM] [Info] Number of data points in the train set: 24940, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098532\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.737075\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116158\n",
      "[LightGBM] [Info] Number of data points in the train set: 24984, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 0.778842\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116393\n",
      "[LightGBM] [Info] Number of data points in the train set: 35606, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098668\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[363]\tvalid_0's multi_logloss: 0.763414\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 37893, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.855571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116300\n",
      "[LightGBM] [Info] Number of data points in the train set: 37567, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.753341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116214\n",
      "[LightGBM] [Info] Number of data points in the train set: 25152, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's multi_logloss: 0.798466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116469\n",
      "[LightGBM] [Info] Number of data points in the train set: 39448, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.702717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116113\n",
      "[LightGBM] [Info] Number of data points in the train set: 27340, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098649\n",
      "[LightGBM] [Info] Start training from score -1.098539\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 0.853571\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 29001, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.838516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 32116, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.760999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116256\n",
      "[LightGBM] [Info] Number of data points in the train set: 38652, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 0.749097\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116211\n",
      "[LightGBM] [Info] Number of data points in the train set: 30160, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.704827\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116144\n",
      "[LightGBM] [Info] Number of data points in the train set: 24691, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.816408\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116241\n",
      "[LightGBM] [Info] Number of data points in the train set: 24972, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 0.810784\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116293\n",
      "[LightGBM] [Info] Number of data points in the train set: 33489, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.842809\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116334\n",
      "[LightGBM] [Info] Number of data points in the train set: 34332, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.819457\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116120\n",
      "[LightGBM] [Info] Number of data points in the train set: 19800, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 0.763601\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116341\n",
      "[LightGBM] [Info] Number of data points in the train set: 32188, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's multi_logloss: 0.799762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116278\n",
      "[LightGBM] [Info] Number of data points in the train set: 32479, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.828058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 31003, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.795632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116201\n",
      "[LightGBM] [Info] Number of data points in the train set: 27516, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 0.777186\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116191\n",
      "[LightGBM] [Info] Number of data points in the train set: 23606, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098697\n",
      "[LightGBM] [Info] Start training from score -1.098570\n",
      "[LightGBM] [Info] Start training from score -1.098570\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 0.837232\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116449\n",
      "[LightGBM] [Info] Number of data points in the train set: 39715, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_logloss: 0.759664\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 29894, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_logloss: 0.765048\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116229\n",
      "[LightGBM] [Info] Number of data points in the train set: 22800, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.766953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116230\n",
      "[LightGBM] [Info] Number of data points in the train set: 31749, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's multi_logloss: 0.86576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116307\n",
      "[LightGBM] [Info] Number of data points in the train set: 38577, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's multi_logloss: 0.805657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116337\n",
      "[LightGBM] [Info] Number of data points in the train set: 35236, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's multi_logloss: 0.788238\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116275\n",
      "[LightGBM] [Info] Number of data points in the train set: 30108, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.756799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116026\n",
      "[LightGBM] [Info] Number of data points in the train set: 24825, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_logloss: 0.83285\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116217\n",
      "[LightGBM] [Info] Number of data points in the train set: 24460, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.743884\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116328\n",
      "[LightGBM] [Info] Number of data points in the train set: 28260, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.798871\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116234\n",
      "[LightGBM] [Info] Number of data points in the train set: 38272, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.825024\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116233\n",
      "[LightGBM] [Info] Number of data points in the train set: 33952, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.792264\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116254\n",
      "[LightGBM] [Info] Number of data points in the train set: 30146, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.802568\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 32145, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 0.815494\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 33156, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 0.904517\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 36972, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[277]\tvalid_0's multi_logloss: 0.80158\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116186\n",
      "[LightGBM] [Info] Number of data points in the train set: 26546, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.802244\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116233\n",
      "[LightGBM] [Info] Number of data points in the train set: 35383, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's multi_logloss: 0.83516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116217\n",
      "[LightGBM] [Info] Number of data points in the train set: 31780, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.821726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116188\n",
      "[LightGBM] [Info] Number of data points in the train set: 23889, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 0.784326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116174\n",
      "[LightGBM] [Info] Number of data points in the train set: 26342, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098574\n",
      "[LightGBM] [Info] Start training from score -1.098574\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's multi_logloss: 0.84017\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116366\n",
      "[LightGBM] [Info] Number of data points in the train set: 31365, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's multi_logloss: 0.809337\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116391\n",
      "[LightGBM] [Info] Number of data points in the train set: 31893, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.752581\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116310\n",
      "[LightGBM] [Info] Number of data points in the train set: 34804, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's multi_logloss: 0.811043\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116262\n",
      "[LightGBM] [Info] Number of data points in the train set: 28795, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.808882\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116246\n",
      "[LightGBM] [Info] Number of data points in the train set: 29731, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.754975\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 30194, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's multi_logloss: 0.770176\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116507\n",
      "[LightGBM] [Info] Number of data points in the train set: 38258, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098665\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's multi_logloss: 0.781221\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116327\n",
      "[LightGBM] [Info] Number of data points in the train set: 31022, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098677\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.846551\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116235\n",
      "[LightGBM] [Info] Number of data points in the train set: 27396, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's multi_logloss: 0.721076\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116254\n",
      "[LightGBM] [Info] Number of data points in the train set: 28039, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's multi_logloss: 0.693579\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116180\n",
      "[LightGBM] [Info] Number of data points in the train set: 31190, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.87811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116289\n",
      "[LightGBM] [Info] Number of data points in the train set: 32436, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 0.7305\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 37852, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's multi_logloss: 0.776439\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116428\n",
      "[LightGBM] [Info] Number of data points in the train set: 36585, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.769287\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116285\n",
      "[LightGBM] [Info] Number of data points in the train set: 40699, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098563\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_logloss: 0.77065\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 31454, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.764603\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116210\n",
      "[LightGBM] [Info] Number of data points in the train set: 32769, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 0.789391\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116308\n",
      "[LightGBM] [Info] Number of data points in the train set: 30189, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.841535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116110\n",
      "[LightGBM] [Info] Number of data points in the train set: 21381, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 0.737962\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116295\n",
      "[LightGBM] [Info] Number of data points in the train set: 30381, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.796766\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116265\n",
      "[LightGBM] [Info] Number of data points in the train set: 34574, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098670\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's multi_logloss: 0.84598\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116379\n",
      "[LightGBM] [Info] Number of data points in the train set: 38155, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098560\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[344]\tvalid_0's multi_logloss: 0.748064\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116295\n",
      "[LightGBM] [Info] Number of data points in the train set: 35066, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.791899\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116250\n",
      "[LightGBM] [Info] Number of data points in the train set: 31257, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 0.884059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116293\n",
      "[LightGBM] [Info] Number of data points in the train set: 32436, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.730217\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116191\n",
      "[LightGBM] [Info] Number of data points in the train set: 30144, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's multi_logloss: 0.787005\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116402\n",
      "[LightGBM] [Info] Number of data points in the train set: 34195, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.724607\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116233\n",
      "[LightGBM] [Info] Number of data points in the train set: 30184, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.798584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116252\n",
      "[LightGBM] [Info] Number of data points in the train set: 33657, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.82406\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116246\n",
      "[LightGBM] [Info] Number of data points in the train set: 31588, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098549\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 0.746492\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116210\n",
      "[LightGBM] [Info] Number of data points in the train set: 30751, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098547\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 0.834166\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116252\n",
      "[LightGBM] [Info] Number of data points in the train set: 29400, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.795199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116239\n",
      "[LightGBM] [Info] Number of data points in the train set: 33216, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's multi_logloss: 0.755461\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116175\n",
      "[LightGBM] [Info] Number of data points in the train set: 25010, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098692\n",
      "[LightGBM] [Info] Start training from score -1.098572\n",
      "[LightGBM] [Info] Start training from score -1.098572\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.874216\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116183\n",
      "[LightGBM] [Info] Number of data points in the train set: 24703, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's multi_logloss: 0.784813\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116394\n",
      "[LightGBM] [Info] Number of data points in the train set: 37502, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098666\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.766625\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116262\n",
      "[LightGBM] [Info] Number of data points in the train set: 31209, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.774927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116145\n",
      "[LightGBM] [Info] Number of data points in the train set: 27518, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098685\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.802553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116213\n",
      "[LightGBM] [Info] Number of data points in the train set: 38450, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098664\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.819972\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 32918, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098673\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 0.827354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116396\n",
      "[LightGBM] [Info] Number of data points in the train set: 41407, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098636\n",
      "[LightGBM] [Info] Start training from score -1.098636\n",
      "[LightGBM] [Info] Start training from score -1.098564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's multi_logloss: 0.871762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116339\n",
      "[LightGBM] [Info] Number of data points in the train set: 27835, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098540\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's multi_logloss: 0.788517\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116263\n",
      "[LightGBM] [Info] Number of data points in the train set: 34514, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098670\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 0.784357\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116241\n",
      "[LightGBM] [Info] Number of data points in the train set: 31346, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's multi_logloss: 0.684866\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116239\n",
      "[LightGBM] [Info] Number of data points in the train set: 29868, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's multi_logloss: 0.803175\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116432\n",
      "[LightGBM] [Info] Number of data points in the train set: 38851, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's multi_logloss: 0.71896\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116228\n",
      "[LightGBM] [Info] Number of data points in the train set: 34485, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's multi_logloss: 0.790984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116404\n",
      "[LightGBM] [Info] Number of data points in the train set: 40044, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's multi_logloss: 0.81753\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116232\n",
      "[LightGBM] [Info] Number of data points in the train set: 36110, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098668\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.861559\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116174\n",
      "[LightGBM] [Info] Number of data points in the train set: 28713, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.775479\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116317\n",
      "[LightGBM] [Info] Number of data points in the train set: 33069, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's multi_logloss: 0.846895\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116249\n",
      "[LightGBM] [Info] Number of data points in the train set: 25298, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098691\n",
      "[LightGBM] [Info] Start training from score -1.098573\n",
      "[LightGBM] [Info] Start training from score -1.098573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's multi_logloss: 0.779769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116199\n",
      "[LightGBM] [Info] Number of data points in the train set: 29697, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's multi_logloss: 0.75923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116231\n",
      "[LightGBM] [Info] Number of data points in the train set: 26546, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098688\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's multi_logloss: 0.748346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 38042, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098665\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's multi_logloss: 0.816325\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116124\n",
      "[LightGBM] [Info] Number of data points in the train set: 28473, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.756407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116293\n",
      "[LightGBM] [Info] Number of data points in the train set: 35546, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's multi_logloss: 0.742353\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116227\n",
      "[LightGBM] [Info] Number of data points in the train set: 32493, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[370]\tvalid_0's multi_logloss: 0.776922\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116201\n",
      "[LightGBM] [Info] Number of data points in the train set: 24568, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098531\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.771214\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116193\n",
      "[LightGBM] [Info] Number of data points in the train set: 25015, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098532\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.825858\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116275\n",
      "[LightGBM] [Info] Number of data points in the train set: 30777, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's multi_logloss: 0.814426\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116415\n",
      "[LightGBM] [Info] Number of data points in the train set: 38968, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[299]\tvalid_0's multi_logloss: 0.802754\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116314\n",
      "[LightGBM] [Info] Number of data points in the train set: 32896, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.836017\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 26568, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's multi_logloss: 0.777614\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116306\n",
      "[LightGBM] [Info] Number of data points in the train set: 31526, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.729607\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116257\n",
      "[LightGBM] [Info] Number of data points in the train set: 32731, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.831219\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116160\n",
      "[LightGBM] [Info] Number of data points in the train set: 29452, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 0.838388\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116361\n",
      "[LightGBM] [Info] Number of data points in the train set: 32964, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.825705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116165\n",
      "[LightGBM] [Info] Number of data points in the train set: 24525, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.803411\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 26844, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's multi_logloss: 0.854607\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116246\n",
      "[LightGBM] [Info] Number of data points in the train set: 35042, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.79294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116182\n",
      "[LightGBM] [Info] Number of data points in the train set: 25646, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098690\n",
      "[LightGBM] [Info] Start training from score -1.098573\n",
      "[LightGBM] [Info] Start training from score -1.098573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.734553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116377\n",
      "[LightGBM] [Info] Number of data points in the train set: 37106, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098666\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.856562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116228\n",
      "[LightGBM] [Info] Number of data points in the train set: 37941, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's multi_logloss: 0.801017\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116309\n",
      "[LightGBM] [Info] Number of data points in the train set: 36880, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.805675\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116266\n",
      "[LightGBM] [Info] Number of data points in the train set: 28603, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098542\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.798562\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116247\n",
      "[LightGBM] [Info] Number of data points in the train set: 32253, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's multi_logloss: 0.792733\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116304\n",
      "[LightGBM] [Info] Number of data points in the train set: 34305, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 0.863341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116242\n",
      "[LightGBM] [Info] Number of data points in the train set: 25776, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.801004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116270\n",
      "[LightGBM] [Info] Number of data points in the train set: 32433, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.814672\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116450\n",
      "[LightGBM] [Info] Number of data points in the train set: 40471, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098563\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.819642\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116325\n",
      "[LightGBM] [Info] Number of data points in the train set: 31958, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098675\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[361]\tvalid_0's multi_logloss: 0.814275\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116376\n",
      "[LightGBM] [Info] Number of data points in the train set: 35124, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's multi_logloss: 0.794864\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116392\n",
      "[LightGBM] [Info] Number of data points in the train set: 34632, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's multi_logloss: 0.819864\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 29371, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[284]\tvalid_0's multi_logloss: 0.732372\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116077\n",
      "[LightGBM] [Info] Number of data points in the train set: 25387, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098534\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 0.785417\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 28687, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's multi_logloss: 0.865326\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116318\n",
      "[LightGBM] [Info] Number of data points in the train set: 34096, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 0.840279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40147, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098562\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's multi_logloss: 0.816608\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116344\n",
      "[LightGBM] [Info] Number of data points in the train set: 38824, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's multi_logloss: 0.792651\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 29954, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098679\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "[LightGBM] [Info] Start training from score -1.098579\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's multi_logloss: 0.777696\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116255\n",
      "[LightGBM] [Info] Number of data points in the train set: 35455, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.832751\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116045\n",
      "[LightGBM] [Info] Number of data points in the train set: 20234, number of used features: 472\n",
      "[LightGBM] [Info] Start training from score -1.098711\n",
      "[LightGBM] [Info] Start training from score -1.098563\n",
      "[LightGBM] [Info] Start training from score -1.098563\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's multi_logloss: 0.838252\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116288\n",
      "[LightGBM] [Info] Number of data points in the train set: 34605, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.73886\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116245\n",
      "[LightGBM] [Info] Number of data points in the train set: 28953, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.790323\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116354\n",
      "[LightGBM] [Info] Number of data points in the train set: 32392, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.78294\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116397\n",
      "[LightGBM] [Info] Number of data points in the train set: 38054, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098665\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "[LightGBM] [Info] Start training from score -1.098586\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[318]\tvalid_0's multi_logloss: 0.745717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116272\n",
      "[LightGBM] [Info] Number of data points in the train set: 34387, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 0.771482\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116274\n",
      "[LightGBM] [Info] Number of data points in the train set: 24602, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098694\n",
      "[LightGBM] [Info] Start training from score -1.098572\n",
      "[LightGBM] [Info] Start training from score -1.098572\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.777593\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116265\n",
      "[LightGBM] [Info] Number of data points in the train set: 32496, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's multi_logloss: 0.878724\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116220\n",
      "[LightGBM] [Info] Number of data points in the train set: 27765, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_logloss: 0.807415\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116313\n",
      "[LightGBM] [Info] Number of data points in the train set: 36950, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098666\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 0.715116\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116261\n",
      "[LightGBM] [Info] Number of data points in the train set: 36055, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098557\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[347]\tvalid_0's multi_logloss: 0.818789\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116159\n",
      "[LightGBM] [Info] Number of data points in the train set: 25363, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098652\n",
      "[LightGBM] [Info] Start training from score -1.098533\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.843504\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116137\n",
      "[LightGBM] [Info] Number of data points in the train set: 27984, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.836328\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116234\n",
      "[LightGBM] [Info] Number of data points in the train set: 34370, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098670\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "[LightGBM] [Info] Start training from score -1.098583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 0.81191\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116221\n",
      "[LightGBM] [Info] Number of data points in the train set: 32908, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.900101\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 38877, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.809382\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116277\n",
      "[LightGBM] [Info] Number of data points in the train set: 36744, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's multi_logloss: 0.764473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116283\n",
      "[LightGBM] [Info] Number of data points in the train set: 40519, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098637\n",
      "[LightGBM] [Info] Start training from score -1.098563\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.855783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 30103, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.792627\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116231\n",
      "[LightGBM] [Info] Number of data points in the train set: 32752, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.791961\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116253\n",
      "[LightGBM] [Info] Number of data points in the train set: 27799, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098648\n",
      "[LightGBM] [Info] Start training from score -1.098540\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.803799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116245\n",
      "[LightGBM] [Info] Number of data points in the train set: 28711, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.751944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116350\n",
      "[LightGBM] [Info] Number of data points in the train set: 29373, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.81568\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116311\n",
      "[LightGBM] [Info] Number of data points in the train set: 34764, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[340]\tvalid_0's multi_logloss: 0.776854\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116260\n",
      "[LightGBM] [Info] Number of data points in the train set: 30746, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098677\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.818169\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 25512, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 0.779792\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116240\n",
      "[LightGBM] [Info] Number of data points in the train set: 33184, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.850474\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116249\n",
      "[LightGBM] [Info] Number of data points in the train set: 26419, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098537\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's multi_logloss: 0.75994\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116339\n",
      "[LightGBM] [Info] Number of data points in the train set: 34884, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's multi_logloss: 0.783014\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116415\n",
      "[LightGBM] [Info] Number of data points in the train set: 34567, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\tvalid_0's multi_logloss: 0.732336\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116260\n",
      "[LightGBM] [Info] Number of data points in the train set: 33360, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 0.808594\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116269\n",
      "[LightGBM] [Info] Number of data points in the train set: 36110, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098668\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "[LightGBM] [Info] Start training from score -1.098585\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's multi_logloss: 0.790825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116463\n",
      "[LightGBM] [Info] Number of data points in the train set: 39028, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098638\n",
      "[LightGBM] [Info] Start training from score -1.098561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's multi_logloss: 0.823556\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116212\n",
      "[LightGBM] [Info] Number of data points in the train set: 31240, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's multi_logloss: 0.805455\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116237\n",
      "[LightGBM] [Info] Number of data points in the train set: 27818, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098684\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.80026\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116346\n",
      "[LightGBM] [Info] Number of data points in the train set: 35848, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's multi_logloss: 0.789729\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116301\n",
      "[LightGBM] [Info] Number of data points in the train set: 34305, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[310]\tvalid_0's multi_logloss: 0.784039\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116221\n",
      "[LightGBM] [Info] Number of data points in the train set: 23421, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's multi_logloss: 0.822761\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116210\n",
      "[LightGBM] [Info] Number of data points in the train set: 30144, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.772503\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116278\n",
      "[LightGBM] [Info] Number of data points in the train set: 34041, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.804454\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 34711, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 0.785683\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116273\n",
      "[LightGBM] [Info] Number of data points in the train set: 34833, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.782094\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116210\n",
      "[LightGBM] [Info] Number of data points in the train set: 26685, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's multi_logloss: 0.848616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116174\n",
      "[LightGBM] [Info] Number of data points in the train set: 30079, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's multi_logloss: 0.8143\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116244\n",
      "[LightGBM] [Info] Number of data points in the train set: 36736, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098558\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.778301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116231\n",
      "[LightGBM] [Info] Number of data points in the train set: 36108, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.76977\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116233\n",
      "[LightGBM] [Info] Number of data points in the train set: 27002, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098686\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's multi_logloss: 0.80947\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116249\n",
      "[LightGBM] [Info] Number of data points in the train set: 28780, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098543\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's multi_logloss: 0.81473\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116242\n",
      "[LightGBM] [Info] Number of data points in the train set: 31080, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.792712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 37375, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098639\n",
      "[LightGBM] [Info] Start training from score -1.098559\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tvalid_0's multi_logloss: 0.842236\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116378\n",
      "[LightGBM] [Info] Number of data points in the train set: 34327, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098641\n",
      "[LightGBM] [Info] Start training from score -1.098554\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.773532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116265\n",
      "[LightGBM] [Info] Number of data points in the train set: 30715, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098645\n",
      "[LightGBM] [Info] Start training from score -1.098547\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 0.814948\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116314\n",
      "[LightGBM] [Info] Number of data points in the train set: 33158, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098673\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "[LightGBM] [Info] Start training from score -1.098582\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.860823\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116209\n",
      "[LightGBM] [Info] Number of data points in the train set: 30696, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.789354\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116148\n",
      "[LightGBM] [Info] Number of data points in the train set: 32860, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.863064\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116243\n",
      "[LightGBM] [Info] Number of data points in the train set: 28540, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098647\n",
      "[LightGBM] [Info] Start training from score -1.098542\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 0.833617\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116264\n",
      "[LightGBM] [Info] Number of data points in the train set: 30624, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.847161\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116173\n",
      "[LightGBM] [Info] Number of data points in the train set: 30093, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.839982\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116290\n",
      "[LightGBM] [Info] Number of data points in the train set: 29472, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.806302\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116343\n",
      "[LightGBM] [Info] Number of data points in the train set: 35702, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098668\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's multi_logloss: 0.833276\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116218\n",
      "[LightGBM] [Info] Number of data points in the train set: 26848, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098650\n",
      "[LightGBM] [Info] Start training from score -1.098538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's multi_logloss: 0.803731\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116248\n",
      "[LightGBM] [Info] Number of data points in the train set: 30890, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098677\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 0.772189\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116215\n",
      "[LightGBM] [Info] Number of data points in the train set: 29028, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's multi_logloss: 0.802769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116322\n",
      "[LightGBM] [Info] Number of data points in the train set: 33148, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.845516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116204\n",
      "[LightGBM] [Info] Number of data points in the train set: 26592, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's multi_logloss: 0.793729\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116262\n",
      "[LightGBM] [Info] Number of data points in the train set: 31202, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098676\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's multi_logloss: 0.73946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116245\n",
      "[LightGBM] [Info] Number of data points in the train set: 28298, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098683\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "[LightGBM] [Info] Start training from score -1.098577\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.842262\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116399\n",
      "[LightGBM] [Info] Number of data points in the train set: 43641, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 0.809152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116203\n",
      "[LightGBM] [Info] Number of data points in the train set: 30518, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098678\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "[LightGBM] [Info] Start training from score -1.098580\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 0.812228\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116176\n",
      "[LightGBM] [Info] Number of data points in the train set: 29988, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's multi_logloss: 0.723498\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116314\n",
      "[LightGBM] [Info] Number of data points in the train set: 35054, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098669\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "[LightGBM] [Info] Start training from score -1.098584\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's multi_logloss: 0.793152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116179\n",
      "[LightGBM] [Info] Number of data points in the train set: 28629, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.848267\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116268\n",
      "[LightGBM] [Info] Number of data points in the train set: 31356, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.798251\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116022\n",
      "[LightGBM] [Info] Number of data points in the train set: 20630, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098709\n",
      "[LightGBM] [Info] Start training from score -1.098564\n",
      "[LightGBM] [Info] Start training from score -1.098564\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's multi_logloss: 0.796659\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 33292, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098552\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.75845\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116282\n",
      "[LightGBM] [Info] Number of data points in the train set: 32342, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098674\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's multi_logloss: 0.75477\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116376\n",
      "[LightGBM] [Info] Number of data points in the train set: 37857, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.720182\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 35472, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's multi_logloss: 0.749878\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116160\n",
      "[LightGBM] [Info] Number of data points in the train set: 32414, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098674\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "[LightGBM] [Info] Start training from score -1.098581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[195]\tvalid_0's multi_logloss: 0.791636\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116425\n",
      "[LightGBM] [Info] Number of data points in the train set: 39986, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098662\n",
      "[LightGBM] [Info] Start training from score -1.098587\n",
      "[LightGBM] [Info] Start training from score -1.098587\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's multi_logloss: 0.704908\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116315\n",
      "[LightGBM] [Info] Number of data points in the train set: 31243, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098644\n",
      "[LightGBM] [Info] Start training from score -1.098548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's multi_logloss: 0.823042\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116234\n",
      "[LightGBM] [Info] Number of data points in the train set: 26532, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's multi_logloss: 0.778351\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116230\n",
      "[LightGBM] [Info] Number of data points in the train set: 25999, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098651\n",
      "[LightGBM] [Info] Start training from score -1.098651\n",
      "[LightGBM] [Info] Start training from score -1.098535\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's multi_logloss: 0.785382\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116390\n",
      "[LightGBM] [Info] Number of data points in the train set: 35587, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's multi_logloss: 0.805448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116166\n",
      "[LightGBM] [Info] Number of data points in the train set: 24760, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098653\n",
      "[LightGBM] [Info] Start training from score -1.098532\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 0.839951\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116216\n",
      "[LightGBM] [Info] Number of data points in the train set: 33616, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098642\n",
      "[LightGBM] [Info] Start training from score -1.098553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's multi_logloss: 0.889726\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116278\n",
      "[LightGBM] [Info] Number of data points in the train set: 35587, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098640\n",
      "[LightGBM] [Info] Start training from score -1.098556\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's multi_logloss: 0.761624\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116205\n",
      "[LightGBM] [Info] Number of data points in the train set: 27434, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098685\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "[LightGBM] [Info] Start training from score -1.098576\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 0.755575\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116319\n",
      "[LightGBM] [Info] Number of data points in the train set: 34449, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's multi_logloss: 0.813515\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116390\n",
      "[LightGBM] [Info] Number of data points in the train set: 42256, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098636\n",
      "[LightGBM] [Info] Start training from score -1.098636\n",
      "[LightGBM] [Info] Start training from score -1.098565\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[411]\tvalid_0's multi_logloss: 0.720304\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 36204, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.730971\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116219\n",
      "[LightGBM] [Info] Number of data points in the train set: 38241, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's multi_logloss: 0.725925\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116388\n",
      "[LightGBM] [Info] Number of data points in the train set: 40406, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098662\n",
      "[LightGBM] [Info] Start training from score -1.098588\n",
      "[LightGBM] [Info] Start training from score -1.098588\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.807942\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116280\n",
      "[LightGBM] [Info] Number of data points in the train set: 26277, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.813273\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116320\n",
      "[LightGBM] [Info] Number of data points in the train set: 32380, number of used features: 475\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's multi_logloss: 0.766532\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116177\n",
      "[LightGBM] [Info] Number of data points in the train set: 27624, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's multi_logloss: 0.812062\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116182\n",
      "[LightGBM] [Info] Number of data points in the train set: 27393, number of used features: 477\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.774363\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116364\n",
      "[LightGBM] [Info] Number of data points in the train set: 32644, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098643\n",
      "[LightGBM] [Info] Start training from score -1.098551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's multi_logloss: 0.801536\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116176\n",
      "[LightGBM] [Info] Number of data points in the train set: 26786, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098687\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "[LightGBM] [Info] Start training from score -1.098575\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's multi_logloss: 0.687394\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116257\n",
      "[LightGBM] [Info] Number of data points in the train set: 31224, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.847265\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116211\n",
      "[LightGBM] [Info] Number of data points in the train set: 29791, number of used features: 476\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098646\n",
      "[LightGBM] [Info] Start training from score -1.098545\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's multi_logloss: 0.793988\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116020\n",
      "[LightGBM] [Info] Number of data points in the train set: 22156, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098657\n",
      "[LightGBM] [Info] Start training from score -1.098657\n",
      "[LightGBM] [Info] Start training from score -1.098522\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.805242\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 116299\n",
      "[LightGBM] [Info] Number of data points in the train set: 34437, number of used features: 474\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.848715\n"
     ]
    }
   ],
   "source": [
    "experiment_base_name = 'Tsfresh_InflCovidNC'\n",
    "experiment_name = 'InflCovidNC'\n",
    "experiment_dir = resultdir / experiment_base_name / experiment_name\n",
    "os.makedirs(experiment_dir, exist_ok=True) \n",
    "\n",
    "pid_random_states = range(0, 500)  # 500 random states for PID sampling\n",
    "us_random_state = 0  # Random state for under-sampling\n",
    "tv_random_state = 0  # Random state for train/validation split\n",
    "evalfunc = partial(f1_score, average='macro')  # Evaluation function\n",
    "n_pid_split_dict = {'infl': [20, 20], 'covid': [20, 20], 'nc': [20, 20]}  # Number of train/test samples per class\n",
    "labels = list(n_pid_split_dict.keys())  # Class labels\n",
    "num_class = len(n_pid_split_dict)  # Number of classes\n",
    "le = LabelEncoder()  # Label encoder\n",
    "le.fit(labels)\n",
    "label_column = 'label'\n",
    "\n",
    "for i, (df_X, df_y, splitted_pids, splitted_pidlabels) \\\n",
    "    in enumerate(kentai.generate_dfxypidspidlabels(\n",
    "            n_pid_split_dict, random_states=pid_random_states, label_column=label_column)):\n",
    "\n",
    "    outputdirname = 'ex-division' + str(i).zfill(2)  # Name of the directory where results will be saved\n",
    "    outputdir = experiment_dir / outputdirname       # Directory where results will be saved\n",
    "    os.makedirs(outputdir, exist_ok=True)           # Create it if it does not exist\n",
    "\n",
    "    # Save PIDs used in the experiment\n",
    "    splitted_pidsfilepath = outputdir / 'splitted_pids.csv'\n",
    "    with open(splitted_pidsfilepath, mode='w') as f:\n",
    "        for pids in splitted_pids:\n",
    "            # Without reshape, values are written line by line instead of comma-separated\n",
    "            np.savetxt(f, np.array(pids).reshape(1, -1), delimiter=',', fmt='%d')\n",
    "\n",
    "    # Save PID labels used in the experiment\n",
    "    splitted_pidlabelsfilepath = outputdir / 'splitted_pidlabels.csv'  # File to store PIDs used in the experiment\n",
    "    with open(splitted_pidlabelsfilepath, mode='w') as f:\n",
    "        for pidlabels in splitted_pidlabels:\n",
    "            # Without reshape, values are written line by line instead of comma-separated\n",
    "            np.savetxt(f, np.array(pidlabels).reshape(1, -1), delimiter=',', fmt='%s')\n",
    "\n",
    "    df_X_train, df_X_test = df_X  # Feature vectors for each instance\n",
    "    df_y_train, df_y_test = df_y  # Labels for each instance\n",
    "    pids_train, pids_test = splitted_pids  # PIDs used for train/test\n",
    "    pidlabels_train, pidlabels_test = splitted_pidlabels  # Labels of PIDs used for train/test\n",
    "\n",
    "    # RandomUnderSampler without NR\n",
    "    rus = RandomUnderSampler(random_state=us_random_state)\n",
    "    df_X_train_resampled, y_train_resampled = rus.fit_resample(df_X_train, df_y_train[label_column])\n",
    "    df_y_train_resampled = df_y_train.loc[df_X_train_resampled.index]\n",
    "\n",
    "    # Split validation data for early_stopping_rounds\n",
    "    df_X_train_resampled_train, df_X_train_resampled_valid, \\\n",
    "    df_y_train_resampled_train, df_y_train_resampled_valid = \\\n",
    "        train_test_split(df_X_train_resampled, df_y_train_resampled, test_size=0.2,\n",
    "                         random_state=tv_random_state,\n",
    "                         stratify=df_y_train_resampled[label_column])\n",
    "\n",
    "    # Set parameters\n",
    "    if len(n_pid_split_dict) == 2:\n",
    "        objective = 'binary'\n",
    "        metric = 'binary_logloss'\n",
    "        num_class = 1  # Number of classes (1 in the binary case)\n",
    "        eval_metric = 'binary_logloss'\n",
    "    else:\n",
    "        objective = 'multiclass'\n",
    "        metric = 'multi_logloss'\n",
    "        num_class = len(n_pid_split_dict)  # Number of classes\n",
    "        eval_metric = 'multi_logloss'\n",
    "\n",
    "    lgb_params = {\n",
    "        'n_estimators': 10000,\n",
    "        'objective': objective,\n",
    "        'metric': metric,\n",
    "        'num_class': num_class,  # Number of classes\n",
    "        'seed': 0\n",
    "    }\n",
    "        \n",
    "    fit_params = {\n",
    "        'eval_metric': eval_metric,  # Metric used for early_stopping_rounds\n",
    "        'eval_set': [(df_X_train_resampled_valid.to_numpy(),\n",
    "                      df_y_train_resampled_valid[label_column])],\n",
    "        'callbacks': [lgb.early_stopping(stopping_rounds=100, verbose=True)]\n",
    "    }\n",
    "\n",
    "    # Train classifier\n",
    "    clf = lgb.LGBMClassifier(**lgb_params)\n",
    "    clf.fit(df_X_train_resampled_train.values,\n",
    "            df_y_train_resampled_train[label_column],\n",
    "            **fit_params)\n",
    "\n",
    "    # Instance-level results\n",
    "    y_pred_probs = clf.predict_proba(df_X_test)  # Predicted probabilities for each label\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)     # Predicted label indices\n",
    "    y_pred = le.inverse_transform(y_pred)        # Decode labels\n",
    "\n",
    "    # Save instance-level results\n",
    "    case_pred_probs_path = outputdir / 'case_nonr_pred_probs.csv'  # File to save predicted probabilities per instance\n",
    "    df_case_nonr_pred_probs = pd.DataFrame(y_pred_probs, columns=labels)\n",
    "    df_case_nonr_pred_probs.to_csv(case_pred_probs_path, index=None)\n",
    "\n",
    "    case_nonr_true_pred_path = outputdir / 'case_nonr_true_pred.csv'  # File to save true and predicted labels per instance\n",
    "    df_case_nonr_true_pred = pd.DataFrame(\n",
    "        np.array([df_y_test[label_column], y_pred]).T,\n",
    "        columns=(['true', 'pred'])\n",
    "    )\n",
    "    df_case_nonr_true_pred.to_csv(case_nonr_true_pred_path, index=None)\n",
    "    lgbmtools.save_clrep_confmat(df_y_test[label_column], y_pred, labels,\n",
    "                                 filenamehead='case_nonr', outputdir=outputdir)\n",
    "\n",
    "    # PID-level results\n",
    "\n",
    "    # Compute predicted probabilities aggregated by PID\n",
    "    # pidlabels_pred_probs = pred_ratio_bypid(pids_test, df_y_test['pid'], y_pred, labels)  # Prediction ratio per PID\n",
    "    pidlabels_pred_probs = lgbmtools.pred_probsum_bypid(\n",
    "        pids_test,\n",
    "        df_y_test['pid'].to_numpy(),\n",
    "        y_pred_probs,\n",
    "        labels\n",
    "    )  # Sum of predicted probabilities per PID\n",
    "\n",
    "    df_pidlabels_pred_probs = pd.DataFrame(pidlabels_pred_probs, columns=labels)\n",
    "    # Save\n",
    "    pid_pred_probs_path = outputdir / 'pid_nonr_pred_probs.csv'  # File to save predicted probabilities per PID\n",
    "    df_pidlabels_pred_probs.to_csv(pid_pred_probs_path, index=None)            \n",
    "        \n",
    "    # Predicted labels per PID\n",
    "    pidlabels_pred = np.argmax(pidlabels_pred_probs, axis=1)  # Predicted label indices\n",
    "    pidlabels_pred = le.inverse_transform(pidlabels_pred)     # Decode labels\n",
    "    df_pids_pidlabels_pidpred = pd.DataFrame(\n",
    "        np.array([pids_test, pidlabels_test, pidlabels_pred]).T,\n",
    "        columns=(['pid', 'true', 'pred'])\n",
    "    )\n",
    "    # Save\n",
    "    pids_pidlabels_pidpred_path = outputdir / 'pid_nonr_true_pred.csv'  # File to save true and predicted labels per PID\n",
    "    df_pids_pidlabels_pidpred.to_csv(pids_pidlabels_pidpred_path, index=None)\n",
    "\n",
    "    # Evaluation metrics (PID-level)\n",
    "    lgbmtools.save_clrep_confmat(\n",
    "        pidlabels_test,\n",
    "        pidlabels_pred,\n",
    "        labels,\n",
    "        filenamehead='pid_nonr',\n",
    "        outputdir=outputdir\n",
    "    )\n",
    "\n",
    "    # Predictions on validation data\n",
    "    y_pred_prob1 = clf.predict_proba(df_X_train_resampled_valid)\n",
    "    y_pred1 = np.argmax(y_pred_prob1, axis=1)\n",
    "    y_pred1 = le.inverse_transform(y_pred1)\n",
    "\n",
    "    # Save classification report and confusion matrix for validation data\n",
    "    lgbmtools.save_clrep_confmat(\n",
    "        df_y_train_resampled_valid[label_column],\n",
    "        y_pred1,\n",
    "        labels,\n",
    "        filenamehead='case_nonr_valid',\n",
    "        outputdir=outputdir\n",
    "    )\n",
    "\n",
    "    # Save validation instances\n",
    "    y_pred_prob1_path = outputdir / 'case_nonr_valid_pred_probs.csv'\n",
    "    df_case_nonr_pred_prob1 = pd.DataFrame(y_pred_prob1, columns=labels)\n",
    "    df_case_nonr_pred_prob1.to_csv(y_pred_prob1_path, index=None)\n",
    "\n",
    "    case_nonr_true_pred1_path = outputdir / 'case_nonr_valid_true_pred.csv'\n",
    "    df_case_nonr_true_pred1 = pd.DataFrame(\n",
    "        np.array([df_y_train_resampled_valid[label_column], y_pred1]).T,\n",
    "        columns=(['true', 'pred'])\n",
    "    )\n",
    "    df_case_nonr_true_pred1.to_csv(case_nonr_true_pred1_path, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4bae12a-5142-42f3-8023-b1654b7cfbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_3class.calc_save_ave_3class(experiment_dir=experiment_dir, labels=labels, base_names=(\"case_nonr\", \"pid_nonr\"), target_label=\"macro avg\", save_hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b5bf0-eb4f-4d52-b01b-29f533addfae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
